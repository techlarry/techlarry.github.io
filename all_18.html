<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">HomePage</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="wiki">WIKI</a></li>
        
        <li id=""><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        <li id=""><a target="_blank" href="note">NOTE</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">HomePage</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="wiki">WIKI</a></li>
        
        <li><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        
        <li><a target="_blank" href="note">NOTE</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="programming_language.html">编程语言</a></li>
        
            <li><a href="data_structure_and_algorithm.html">数据结构和算法</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">文献阅读</a></li>
        
            <li><a href="Tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15041905263785.html">
                
                  <h1>cross-entropy</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>\[<br/>
L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}<br/>
\]</p>

<p>where we are using the notation \(f_j\) to mean the j-th element of the vector of class scores \(f\). As before, the full loss for the dataset is the mean of \(L_i\) over all training examples together with a regularization term \(R(W)\). The function \(f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}} \) is called the <strong>softmax function</strong>: It takes a vector of arbitrary real-valued scores (in \(z\)) and squashes it to a vector of values between zero and one that sum to one. The full cross-entropy loss that involves the softmax function might look scary if you&#39;re seeing it for the first time but it is relatively easy to motivate.</p>

<p><strong>Information theory view</strong>. The <em>cross-entropy</em> between a &quot;true&quot; distribution \(p\) and an estimated distribution \(q\) is defined as:</p>

<p>\[<br/>
H(p,q) = - \sum_x p(x) \log q(x)<br/>
\]</p>

<p>The Softmax classifier is hence minimizing the cross-entropy between the estimated class probabilities ( \(q = e^{f_{y_i}}  / \sum_j e^{f_j} \) as seen above) and the &quot;true&quot; distribution, which in this interpretation is the distribution where all probability mass is on the correct class (i.e. \(p = [0, \ldots 1, \ldots, 0]\) contains a single 1 at the \(y_i\) -th position.). Moreover, since the cross-entropy can be written in terms of entropy and the Kullback-Leibler divergence as \(H(p,q) = H(p) + D_{KL}(p\|\|q)\), and the entropy of the delta function \(p\) is zero, this is also equivalent to minimizing the KL divergence between the two distributions (a measure of distance). In other words, the cross-entropy objective <em>wants</em> the predicted distribution to have all of its mass on the correct answer.</p>

<p><strong>Probabilistic interpretation</strong>. Looking at the expression, we see that</p>

<p>\[<br/>
P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }<br/>
\]</p>

<p>can be interpreted as the (normalized) probability assigned to the correct label \(y_i\) given the image \(x_i\) and parameterized by \(W\). To see this, remember that the Softmax classifier interprets the scores inside the output vector \(f\) as the unnormalized log probabilities. Exponentiating these quantities therefore gives the (unnormalized) probabilities, and the division performs the normalization so that the probabilities sum to one. In the probabilistic interpretation, we are therefore minimizing the negative log likelihood of the correct class, which can be interpreted as performing <em>Maximum Likelihood Estimation</em> (MLE). A nice feature of this view is that we can now also interpret the regularization term \(R(W)\) in the full loss function as coming from a Gaussian prior over the weight matrix \(W\), where instead of MLE we are performing the <em>Maximum a posteriori</em> (MAP) estimation. We mention these interpretations to help your intuitions, but the full details of this derivation are beyond the scope of this class.</p>

<p><strong>Practical issues: Numeric stability</strong>. When you&#39;re writing code for computing the Softmax function in practice, the intermediate terms \(e^{f_{y_i}}\) and \(\sum_j e^{f_j}\) may be very large due to the exponentials. Dividing large numbers can be numerically unstable, so it is important to use a normalization trick. Notice that if we multiply the top and bottom of the fraction by a constant \(C\) and push it into the sum, we get the following (mathematically equivalent) expression:</p>

<p>\[<br/>
\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}<br/>
= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}<br/>
= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}<br/>
\]</p>

<p>We are free to choose the value of \(C\). This will not change any of the results, but we can use this value to improve the numerical stability of the computation. A common choice for \(C\) is to set \(\log C = -\max_j f_j \). This simply states that we should shift the values inside the vector \(f\) so that the highest value is zero. In code:</p>

<pre><code class="language-python">f = np.array([123, 456, 789]) # example with 3 classes and each having large scores
p = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup

# instead: first shift the values of f so that the highest number is 0:
f -= np.max(f) # f becomes [-666, -333, 0]
p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answer

</code></pre>

<p><strong>Possibly confusing naming conventions</strong>. To be precise, the <em>SVM classifier</em> uses the <em>hinge loss</em>, or also sometimes called the <em>max-margin loss</em>. The <em>Softmax classifier</em> uses the <em>cross-entropy loss</em>. The Softmax classifier gets its name from the <em>softmax function</em>, which is used to squash the raw class scores into normalized positive values that sum to one, so that the cross-entropy loss can be applied. In particular, note that technically it doesn&#39;t make sense to talk about the &quot;softmax loss&quot;, since softmax is just the squashing function, but it is a relatively commonly used shorthand.</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/31</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Deep%20Learning.html'>Deep Learning</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15037532856914.html">
                
                  <h1>K-means clustering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Optimization objective:<br/>
\[J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)=\frac{1}{m}\sum^m_{i=1}\rVert x^{(i)}-\mu_{c^{(i)}}\rVert^2\]</p>

<p>Randomly initialize \(K\) cluster centroid \(\mu_1, \mu_2,...,\mu_k\)</p>

<p>Repeat{<br/>
    for \(i=1\) to \(m\)<br/>
    \( c^{(i)}=\) index (from 1 to \(K\) of cluster centroid closest to \(x^{(i)}\)</p>

<h3 id="toc_0">Random initialization</h3>

<p>Randomly pick \(K\) training examples, and set \(\mu_1, \mu_2,...,\mu_k\) equal to these \(K\) examples.</p>

<p>\[\text{For }i = 1 \text{  to  } 100 {\\<br/>
\text{    Randomly initialize K cluster centroid } \mu_1, \mu_2,...,\mu_k\\<br/>
\text{    Run K-means}\\<br/>
\text{    Compute cost function (distortion)}\\<br/>
}\\<br/>
\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/26</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15036679491914.html">
                
                  <h1>Feature Engineering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>As the saying goes: garbage in, garbage out. Your system will only be capable of learn‐ ing if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. This process, called feature engineering, involves:</p>

<ul>
<li><code>Feature selection</code>: selecting the most useful features to train on among existing features.</li>
<li><code>Feature extraction</code>: combining existing features to produce a more useful one (as we saw earlier, dimensionality reduction algorithms can help).</li>
<li><code>Creating new features</code> by gathering new data.</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/25</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15035712266178.html">
                
                  <h1>Python `set`, `tuple`</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0"><code>set</code></h2>

<p>A <code>set</code> is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like <code>union</code>, intersection, difference, and symmetric difference.</p>

<p>Curly braces or the <code>set()</code> function can be used to create sets. Note: to create an empty set you have to use <code>set()</code>, not {}; the latter creates an empty dictionary, a data structure that we discuss in the next section.</p>

<pre><code class="language-python">&gt;&gt;&gt; basket = {&#39;apple&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;pear&#39;, &#39;orange&#39;, &#39;banana&#39;}
&gt;&gt;&gt; print(basket)                      # show that duplicates have been removed
{&#39;orange&#39;, &#39;banana&#39;, &#39;pear&#39;, &#39;apple&#39;}
&gt;&gt;&gt; &#39;orange&#39; in basket                 # fast membership testing
True
&gt;&gt;&gt; &#39;crabgrass&#39; in basket
False

&gt;&gt;&gt; # Demonstrate set operations on unique letters from two words
...
&gt;&gt;&gt; a = set(&#39;abracadabra&#39;)
&gt;&gt;&gt; b = set(&#39;alacazam&#39;)
&gt;&gt;&gt; a                                  # unique letters in a
{&#39;a&#39;, &#39;r&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;}
&gt;&gt;&gt; a - b                              # letters in a but not in b
{&#39;r&#39;, &#39;d&#39;, &#39;b&#39;}
&gt;&gt;&gt; a | b                              # letters in either a or b
{&#39;a&#39;, &#39;c&#39;, &#39;r&#39;, &#39;d&#39;, &#39;b&#39;, &#39;m&#39;, &#39;z&#39;, &#39;l&#39;}
&gt;&gt;&gt; a &amp; b                              # letters in both a and b
{&#39;a&#39;, &#39;c&#39;}
&gt;&gt;&gt; a ^ b                              # letters in a or b but not both
{&#39;r&#39;, &#39;d&#39;, &#39;b&#39;, &#39;m&#39;, &#39;z&#39;, &#39;l&#39;}
</code></pre>

<h2 id="toc_1"><code>tuple</code></h2>

<p>A <code>tuple</code> is an (<code>immutable</code>) ordered list of values. A <code>tuple</code> is in many ways similar to a list; one of the most important differences is that <code>tuple</code> can be used as keys in dictionaries and as elements of sets, while <code>list</code> cannot. Here is a trivial example:</p>

<pre><code class="language-python">d = {(x, x + 1): x for x in range(10)}  # Create a dictionary with tuple keys
t = (5, 6)        # Create a tuple
print(type(t))    # Prints &quot;&lt;class &#39;tuple&#39;&gt;&quot;
print(d[t])       # Prints &quot;5&quot;
print(d[(1, 2)])  # Prints &quot;1&quot;
</code></pre>

<p>A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example:</p>

<pre><code class="language-python">&gt;&gt;&gt; empty = ()
&gt;&gt;&gt; singleton = &#39;hello&#39;,    # &lt;-- note trailing comma
&gt;&gt;&gt; len(empty)
0
&gt;&gt;&gt; len(singleton)
1
&gt;&gt;&gt; singleton
(&#39;hello&#39;,)
</code></pre>

<p>The tuple syntax is simple, if you separate some values with commas, you automatically have a tuple(called <code>tuple packing</code>),</p>

<pre><code class="language-text">&gt;&gt;&gt; 1,2,3
(1, 2, 3)
</code></pre>

<h3 id="toc_2"><code>tuple</code> function</h3>

<p>The <code>tuple</code> function works in pretty much the same way as <code>list</code>: it takes one sequence argument and converts it to a <code>tuple</code>.</p>

<pre><code class="language-text">&gt;&gt;&gt; tuple([1,2,3])
(1, 2, 3)
</code></pre>

<h3 id="toc_3">Performance</h3>

<p>Instantiation is almost an order of magnitude faster for the tuple, but item access is actually somewhat faster for the list! So if you&#39;re creating a few tuples and accessing them many many times, it may actually be faster to use lists instead.</p>

<pre><code class="language-python">$ python -m timeit &quot;x=(1,2,3,4,5,6,7,8)&quot;
10000000 loops, best of 3: 0.0388 usec per loop

$ python -m timeit &quot;x=[1,2,3,4,5,6,7,8]&quot;
1000000 loops, best of 3: 0.363 usec per loop

$ python -m timeit -s &quot;x=(1,2,3,4,5,6,7,8)&quot; &quot;y=x[3]&quot;
10000000 loops, best of 3: 0.0938 usec per loop

$ python -m timeit -s &quot;x=[1,2,3,4,5,6,7,8]&quot; &quot;y=x[3]&quot;
10000000 loops, best of 3: 0.0649 usec per loop
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/24</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Python%E7%89%B9%E6%80%A7.html'>Python特性</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="greedy_algorithm_huffman_coding.html">
                
                  <h1>Greedy Algorithm(3): Huffman Coding</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Concepts and Background</a>
<ul>
<li>
<a href="#toc_1">variable-length code</a>
</li>
<li>
<a href="#toc_2">prefix code</a>
</li>
<li>
<a href="#toc_3">full binary tree</a>
</li>
<li>
<a href="#toc_4">cost of tree</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_5">Problem Statement</a>
<ul>
<li>
<a href="#toc_6">Idea</a>
</li>
<li>
<a href="#toc_7">Implementation</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_8">Complexity</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_9">Reference</a>
</li>
</ul>


<p>A <code>Huffman code</code> is a particular type of <code>optimal prefix code</code> that is commonly used for <code>lossless data compression</code>. The process of finding and/or using such a code proceeds by means of <code>Huffman coding</code>, an algorithm developed by <code>David A. Huffman</code>.</p>

<h3 id="toc_0">Concepts and Background</h3>

<h4 id="toc_1">variable-length code</h4>

<p>A <code>variable-length code</code> , which contrasts with <code>fixed-length code</code>, can do considerably better than a <code>fixed-length code</code>, by giving frequent characters short codewords and infrequent characters long codewords.</p>

<h4 id="toc_2">prefix code</h4>

<p><code>prefix code</code> are codes in which <em>no</em> codeword is a prefix of some other codeword. Prefix codes are desirable because they simplify decoding. Since no codeword is a prefix of any other, the codeword that begins an encoded file is unambiguous.</p>

<h4 id="toc_3">full binary tree</h4>

<p>An optimal code for a file is always represented by a <code>full binary tree</code>, in which every non-leaf node has two children.</p>

<h4 id="toc_4">cost of tree</h4>

<p>Given a <code>full binary tree</code> corresponding to a <code>prefix code</code>, we can easily compute the number of bits required to encode a file. For each character \(c\), let the attribute \(c.freq\) denote the frequency of \(c\) in the file and let \(d_T(c)\) denotes the depth of \(c\)&#39;s leaf in the tree. Note that \(d_T(c)\) is also the length of the codeword for character \(c\). The number of bits required to encode a file is thus the <code>cost</code> of the tree \(T\) is </p>

<p>\[B(T) = \sum_{c\in C}c.freq \cdot d_T(c)\] </p>

<h2 id="toc_5">Problem Statement</h2>

<p><strong>Given</strong>: A set of symbols and their probabilities.</p>

<p><strong>Return</strong>: A <code>prefix-free</code> binary code (a set of codewords) with minimum expected codeword length (equivalently, a tree with minimum weighted path length from the root).</p>

<h2 id="toc_6">Idea</h2>

<p>The idea is to assign <code>variable-length codes</code> to input characters, lengths of the assigned codes are based on the frequencies of corresponding characters. The most frequent character gets the smallest code and the least frequent character gets the largest code.</p>

<h2 id="toc_7">Implementation</h2>

<p>There are mainly two major parts in Huffman Coding</p>

<ul>
<li>Build a Huffman Tree from input characters.</li>
<li>Traverse the Huffman Tree and assign codes to characters.</li>
</ul>

<pre><code class="language-python">from queue import PriorityQueue

class HuffmanNode:
    def __init__(self, left, right):
        self.left_child = left
        self.right_child = right


def huffman_coding(freqs):
    pq = PriorityQueue()
    for value in freqs:
        pq.put(value)

    while pq.qsize() &gt; 1:
        l, r = pq.get(), pq.get()
        node = HuffmanNode(l, r)
        pq.put((l[0]+r[0], node))
    return pq.get()


def walk_tree(node, prefix=&quot;&quot;, code={}):
    if isinstance(node[1], HuffmanNode):
        walk_tree(node[1].left_child, prefix + &quot;0&quot;, code)
        walk_tree(node[1].right_child, prefix + &quot;1&quot;, code)
    else:
        code[node[1]] = prefix

    return code


freq = [ (8.167, &#39;a&#39;), (1.492, &#39;b&#39;), (2.782, &#39;c&#39;), (4.253, &#39;d&#39;),
    (12.702, &#39;e&#39;), (2.228, &#39;f&#39;), (2.015, &#39;g&#39;), (6.094, &#39;h&#39;),
    (6.966, &#39;i&#39;), (0.153, &#39;j&#39;), (0.747, &#39;k&#39;), (4.025, &#39;l&#39;),
    (2.406, &#39;m&#39;), (6.749, &#39;n&#39;), (7.507, &#39;o&#39;), (1.929, &#39;p&#39;),
    (0.095, &#39;q&#39;), (5.987, &#39;r&#39;), (6.327, &#39;s&#39;), (9.056, &#39;t&#39;),
    (2.758, &#39;u&#39;), (1.037, &#39;v&#39;), (2.365, &#39;w&#39;), (0.150, &#39;x&#39;),
    (1.974, &#39;y&#39;), (0.074, &#39;z&#39;)]

root_node = huffman_coding(freq)
code = walk_tree(root_node)
for i in sorted(freq, reverse=True):
    print(i[1], &#39;{:6.2f}&#39;.format(i[0]), code[i[1]])
</code></pre>

<pre><code class="language-text">e  12.70 100
t   9.06 000
a   8.17 1110
o   7.51 1101
i   6.97 1011
n   6.75 1010
s   6.33 0111
h   6.09 0110
r   5.99 0101
d   4.25 11111
l   4.03 11110
c   2.78 01001
u   2.76 01000
m   2.41 00111
w   2.37 00110
f   2.23 00100
g   2.02 110011
y   1.97 110010
p   1.93 110001
b   1.49 110000
v   1.04 001010
k   0.75 0010111
j   0.15 001011011
x   0.15 001011010
q   0.10 001011001
z   0.07 001011000
</code></pre>

<h4 id="toc_8">Complexity</h4>

<p>Time complexity: \(O(n \log n)\) where \(n\) is the number of unique characters.</p>

<h2 id="toc_9">Reference</h2>

<ul>
<li><a href="http://www.geeksforgeeks.org/greedy-algorithms-set-3-huffman-coding/">Greedy Algorithms | Set 3 (Huffman Coding)</a></li>
<li></li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/6</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Greedy.html'>Greedy</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_17.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_19.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="programming_language.html"><strong>编程语言</strong></a>
        
            <a href="data_structure_and_algorithm.html"><strong>数据结构和算法</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>文献阅读</strong></a>
        
            <a href="Tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15046649572570.html">Pandas</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="exceptional_control_flow.html">CSAPP - 异常控制流</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="introduction_to_computer_system_CMU.html">CMU 15-213 Introduction to Computer Systems</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concepts-os-structures.html">Operating System Concepts 2 - Operating System structures</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concets-processes.html">Operating System Concepts 3 - Processes</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
