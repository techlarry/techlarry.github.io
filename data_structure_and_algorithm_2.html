<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  数据结构和算法 - techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">HomePage</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="wiki">WIKI</a></li>
        
        <li id=""><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">HomePage</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="wiki">WIKI</a></li>
        
        <li><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="programming_language.html">编程语言</a></li>
        
            <li><a href="data_structure_and_algorithm.html">数据结构和算法</a></li>
        
            <li><a href="Course.html">Course</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html">Python科学计算三维可视化</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">文献阅读</a></li>
        
            <li><a href="Tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="greedy_algorithm_huffman_coding.html">
                
                  <h1>Greedy Algorithm(3): Huffman Coding</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Concepts and Background</a>
<ul>
<li>
<a href="#toc_1">variable-length code</a>
</li>
<li>
<a href="#toc_2">prefix code</a>
</li>
<li>
<a href="#toc_3">full binary tree</a>
</li>
<li>
<a href="#toc_4">cost of tree</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_5">Problem Statement</a>
<ul>
<li>
<a href="#toc_6">Idea</a>
</li>
<li>
<a href="#toc_7">Implementation</a>
<ul>
<li>
<ul>
<li>
<a href="#toc_8">Complexity</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_9">Reference</a>
</li>
</ul>


<p>A <code>Huffman code</code> is a particular type of <code>optimal prefix code</code> that is commonly used for <code>lossless data compression</code>. The process of finding and/or using such a code proceeds by means of <code>Huffman coding</code>, an algorithm developed by <code>David A. Huffman</code>.</p>

<h3 id="toc_0">Concepts and Background</h3>

<h4 id="toc_1">variable-length code</h4>

<p>A <code>variable-length code</code> , which contrasts with <code>fixed-length code</code>, can do considerably better than a <code>fixed-length code</code>, by giving frequent characters short codewords and infrequent characters long codewords.</p>

<h4 id="toc_2">prefix code</h4>

<p><code>prefix code</code> are codes in which <em>no</em> codeword is a prefix of some other codeword. Prefix codes are desirable because they simplify decoding. Since no codeword is a prefix of any other, the codeword that begins an encoded file is unambiguous.</p>

<h4 id="toc_3">full binary tree</h4>

<p>An optimal code for a file is always represented by a <code>full binary tree</code>, in which every non-leaf node has two children.</p>

<h4 id="toc_4">cost of tree</h4>

<p>Given a <code>full binary tree</code> corresponding to a <code>prefix code</code>, we can easily compute the number of bits required to encode a file. For each character \(c\), let the attribute \(c.freq\) denote the frequency of \(c\) in the file and let \(d_T(c)\) denotes the depth of \(c\)&#39;s leaf in the tree. Note that \(d_T(c)\) is also the length of the codeword for character \(c\). The number of bits required to encode a file is thus the <code>cost</code> of the tree \(T\) is </p>

<p>\[B(T) = \sum_{c\in C}c.freq \cdot d_T(c)\] </p>

<h2 id="toc_5">Problem Statement</h2>

<p><strong>Given</strong>: A set of symbols and their probabilities.</p>

<p><strong>Return</strong>: A <code>prefix-free</code> binary code (a set of codewords) with minimum expected codeword length (equivalently, a tree with minimum weighted path length from the root).</p>

<h2 id="toc_6">Idea</h2>

<p>The idea is to assign <code>variable-length codes</code> to input characters, lengths of the assigned codes are based on the frequencies of corresponding characters. The most frequent character gets the smallest code and the least frequent character gets the largest code.</p>

<h2 id="toc_7">Implementation</h2>

<p>There are mainly two major parts in Huffman Coding</p>

<ul>
<li>Build a Huffman Tree from input characters.</li>
<li>Traverse the Huffman Tree and assign codes to characters.</li>
</ul>

<pre><code class="language-python">from queue import PriorityQueue

class HuffmanNode:
    def __init__(self, left, right):
        self.left_child = left
        self.right_child = right


def huffman_coding(freqs):
    pq = PriorityQueue()
    for value in freqs:
        pq.put(value)

    while pq.qsize() &gt; 1:
        l, r = pq.get(), pq.get()
        node = HuffmanNode(l, r)
        pq.put((l[0]+r[0], node))
    return pq.get()


def walk_tree(node, prefix=&quot;&quot;, code={}):
    if isinstance(node[1], HuffmanNode):
        walk_tree(node[1].left_child, prefix + &quot;0&quot;, code)
        walk_tree(node[1].right_child, prefix + &quot;1&quot;, code)
    else:
        code[node[1]] = prefix

    return code


freq = [ (8.167, &#39;a&#39;), (1.492, &#39;b&#39;), (2.782, &#39;c&#39;), (4.253, &#39;d&#39;),
    (12.702, &#39;e&#39;), (2.228, &#39;f&#39;), (2.015, &#39;g&#39;), (6.094, &#39;h&#39;),
    (6.966, &#39;i&#39;), (0.153, &#39;j&#39;), (0.747, &#39;k&#39;), (4.025, &#39;l&#39;),
    (2.406, &#39;m&#39;), (6.749, &#39;n&#39;), (7.507, &#39;o&#39;), (1.929, &#39;p&#39;),
    (0.095, &#39;q&#39;), (5.987, &#39;r&#39;), (6.327, &#39;s&#39;), (9.056, &#39;t&#39;),
    (2.758, &#39;u&#39;), (1.037, &#39;v&#39;), (2.365, &#39;w&#39;), (0.150, &#39;x&#39;),
    (1.974, &#39;y&#39;), (0.074, &#39;z&#39;)]

root_node = huffman_coding(freq)
code = walk_tree(root_node)
for i in sorted(freq, reverse=True):
    print(i[1], &#39;{:6.2f}&#39;.format(i[0]), code[i[1]])
</code></pre>

<pre><code class="language-text">e  12.70 100
t   9.06 000
a   8.17 1110
o   7.51 1101
i   6.97 1011
n   6.75 1010
s   6.33 0111
h   6.09 0110
r   5.99 0101
d   4.25 11111
l   4.03 11110
c   2.78 01001
u   2.76 01000
m   2.41 00111
w   2.37 00110
f   2.23 00100
g   2.02 110011
y   1.97 110010
p   1.93 110001
b   1.49 110000
v   1.04 001010
k   0.75 0010111
j   0.15 001011011
x   0.15 001011010
q   0.10 001011001
z   0.07 001011000
</code></pre>

<h4 id="toc_8">Complexity</h4>

<p>Time complexity: \(O(n \log n)\) where \(n\) is the number of unique characters.</p>

<h2 id="toc_9">Reference</h2>

<ul>
<li><a href="http://www.geeksforgeeks.org/greedy-algorithms-set-3-huffman-coding/">Greedy Algorithms | Set 3 (Huffman Coding)</a></li>
<li></li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/6</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Greedy.html'>Greedy</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="Dynamic_Programming_Optimal_Binary_Search_Tree.html">
                
                  <h1>Dynamic Programming (4): Optimal Binary Search Tree</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>An <code>Optimal Binary Search Tree (Optimal BST)</code> is a binary search tree which provides the smallest possible search time for a given sequence of access probabilities. The cost of a BST node is the level of that node plus one multiplied by its frequency.</p>

<p><strong>Problem Statement</strong>: Given a sorted array \(keys[0.. n-1]\) of search keys and an array \(freq[0.. n-1]\) of frequency counts, where \(freq[i]\) is the number of searches to \(keys[i]\). Construct a binary search tree of all keys such that the total cost of all the searches is as small as possible.</p>

<h2 id="toc_0">Optimal Substructure</h2>

<p>The optimal cost of node \(i,...,j\) can be recursively calculated using the following formula.</p>

<p>\(Cost(i,j) = \sum \limits^{j}_{k=i}freq[k] + \min \limits_{r=i}^j[Cost(i,r-1)+Cost(r+1,j)]\)</p>

<p>We try all nodes one by one as root (\(r\) varies from \(i\) to \(j\)). When we make \(r\)th node as root, we recursively calculate optimal cost from \(i\) to \(r-1\) and \(r+1\) to \(j\). </p>

<h3 id="toc_1">Implementation: top-down with memoization</h3>

<pre><code class="language-python">def optimal_bst(freq):
    def opt_cost(hash_table, freq, i, j):
        &quot;&quot;&quot;
        Optimal Binary Search Tree
        Recursive Method used here
        &quot;&quot;&quot;

        # base case: only 0~1 element
        if j &lt; i:
            return 0
        if j == i:
            return freq[i]

        # if already exists
        if (i, j) in hash_table:
            return hash_table[(i, j)]

        min_cost = sys.maxsize
        for r in range(i, j + 1):
            cost = opt_cost(hash_table, freq, i, r - 1) + opt_cost(hash_table, freq, r + 1, j)
            if cost &lt; min_cost:
                min_cost = cost

        hash_table[(i, j)] = sum(freq[i:j + 1]) + min_cost
        return hash_table[(i, j)]

    return opt_cost({}, freq, 0, len(freq) - 1)
</code></pre>

<h2 id="toc_2">Reference</h2>

<ul>
<li><a href="http://ac.els-cdn.com/S0304397596003209/1-s2.0-S0304397596003209-main.pdf?_tid=1505980e-7cd4-11e7-83de-00000aacb361&amp;acdnat=1502263778_53b76d131a06906e9fe3adfadc778677">Optimal Binary Search Tree</a></li>
<li><a href="http://www.geeksforgeeks.org/dynamic-programming-set-24-optimal-binary-search-tree/">Optimal Binary Search Tree GeeksforGeeks</a></li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/9</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.html'>动态规划</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="tree_2.html">
                
                  <h1>Python树(二)：二叉树的实现</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">嵌套列表表示树</a>
</li>
<li>
<a href="#toc_1">节点和引用</a>
</li>
<li>
<a href="#toc_2">优先队列和二叉堆</a>
<ul>
<li>
<a href="#toc_3">列表与完全二叉树</a>
</li>
<li>
<a href="#toc_4">二叉堆的操作与实现</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">分析树</a>
</li>
<li>
<a href="#toc_6">树的遍历</a>
</li>
</ul>


<p>树可以具有以下方法：</p>

<ul>
<li><code>BinaryTree()</code> creates a new instance of a binary tree.</li>
<li><code>get_left_child()</code> returns the binary tree corresponding to the left child of the current node</li>
<li><code>get_right_child()</code> return the binary tree corresponding to the right child of the current node</li>
<li><code>set_root_val(val)</code> stores the object stored in the current node</li>
<li><code>get_root_val()</code> returns the object stored in the current node</li>
<li><code>insert_left(val)</code> creates a new binary tree and installs it as the left child of the current node</li>
<li><code>insert_right(val)</code> creates a new binary tree and installs it as the right child of the current node</li>
</ul>

<h2 id="toc_0">嵌套列表表示树</h2>

<p>在列表实现树时，我们将存储根节点作为列表的第一个元素的值。列表的第二个元素的本身是一个表示左子树的列表。这个列表的第三个元素表示在右子树的另一个列表。</p>

<pre><code class="language-python"># coding: utf-8


def BinaryTree(r):
    &quot;&quot;&quot;
    creates a new instance of a binary tree.
    &quot;&quot;&quot;
    return [r,[],[]]


def get_left_child(root):
    &quot;&quot;&quot;
    returns the binary tree corresponding to the left child of the current node
    &quot;&quot;&quot;
    return root[1]


def get_right_child(root):
    &quot;&quot;&quot;
    return the binary tree corresponding to the right child of the current node
    &quot;&quot;&quot;
    return  root[2]


def set_root_val(root, val):
    &quot;&quot;&quot;stores the object stored in the current node
    &quot;&quot;&quot;
    root[0] = val



def get_root_val(root):
    &quot;&quot;&quot;
    returns the object stored in the current node
    &quot;&quot;&quot;
    return root[0]

def insert_left(root, new_branch):
    &quot;&quot;&quot;
    creates a new binary tree and installs it as the left child of the current node

    插入一个左子节点，首先获取对应于当前左子节点的列表（可能是空的）。
    然后，添加新的左子节点，将原来的左子节点作为新节点的左子节点。
    这使我们能够将新节点插入到树中的任何位置.
    &quot;&quot;&quot;
    if root[1]:
        root[1] = [new_branch,root[1], []]
    else:
        root[1] = [new_branch, [], []]
    return root



def insert_right(root, new_branch):
    &quot;&quot;&quot;
    creates a new binary tree and installs it as the right child of the current node
    &quot;&quot;&quot;
    if root[2]:
        root[2] = [new_branch, [], root[2]]
    else:
        root[2] = [new_branch, [], []]
    return root


if __name__ == &quot;__main__&quot;:
    r = BinaryTree(3)
    insert_left(r,4)
    insert_left(r,5)
    insert_right(r,6)
    insert_right(r,7)
    l = get_left_child(r)
    print(l)

    set_root_val(l,9)
    print(r)
    insert_left(l,11)
    print(r)
    print(get_right_child(get_right_child(r)))

# result
#[5, [4, [], []], []]
#[3, [9, [4, [], []], []], [7, [], [6, [], []]]]
#[3, [9, [11, [4, [], []], []], []], [7, [], [6, [], []]]]
#[6, [], []]

</code></pre>

<h2 id="toc_1">节点和引用</h2>

<p>节点和引用方法，定义一个类，具有根、以及左、右子树属性。这种表示更紧密地结合了面向对象的方式。树的结构类似于下图所示。</p>

<p><img src="media/14973171257726/14974056999880.jpg" alt="binary tree"/></p>

<p>左右子树是其他二叉树实例的引用。例如，当插入一个新的左子节点到树上时，即创建了二叉树的另一个实例，并修改了根节点的<code>self.left_child</code>使之指向新的树。</p>

<pre><code class="language-python">
import doctest


class BinaryTree(object):
    &quot;&quot;&quot;
    &gt;&gt;&gt; r = BinaryTree(&#39;a&#39;)
    &gt;&gt;&gt; r.get_root_val()
    &#39;a&#39;
    &gt;&gt;&gt; r.get_left_child()

    &gt;&gt;&gt; r.insert_left(&#39;b&#39;)
    &gt;&gt;&gt; r.get_left_child().get_root_val()
    &#39;b&#39;
    &gt;&gt;&gt; r.insert_right(&#39;c&#39;)
    &gt;&gt;&gt; r.get_right_child().get_root_val()
    &#39;c&#39;
    &gt;&gt;&gt; r.get_right_child().set_root_val(&#39;hello&#39;)
    &gt;&gt;&gt; r.get_right_child().get_root_val()
    &#39;hello&#39;
    &quot;&quot;&quot;
    
    def __init__(self, root):
        self.key = root
        self.left_child = None
        self.right_child = None

    def insert_left(self, item):
        &quot;&quot;&quot;
        creates a new binary tree and installs it as the left child of the current node
        &quot;&quot;&quot;
        if self.left_child:
            self.left_child = BinaryTree(item)
        else:
            t = self.left_child
            self.left_child = BinaryTree(item)
            self.left_child.left_child = t

    def insert_right(self, item):
        &quot;&quot;&quot;
        creates a new binary tree and installs it as the right child of the current node
        &quot;&quot;&quot;
        if self.right_child:
            self.right_child = BinaryTree(item)
        else:
            t = self.right_child
            self.right_child = BinaryTree(item)
            self.right_child.right_child = t

    def get_right_child(self):
        &quot;&quot;&quot;
        return the binary tree corresponding to the right child of the current node
        &quot;&quot;&quot;
        return self.right_child

    def get_left_child(self):
        &quot;&quot;&quot;
        return the binary tree corresponding to the left child of the current node
        &quot;&quot;&quot;
        return self.left_child

    def set_root_val(self, root):
        &quot;&quot;&quot;
        stores the object stored in the current node
        &quot;&quot;&quot;
        self.key = root

    def get_root_val(self):
        &quot;&quot;&quot;
        returns the object stored in the current node
        &quot;&quot;&quot;
        return self.key

    def pre_order(self, root):
        &quot;&quot;&quot;
        preorder traversal
        &quot;&quot;&quot;
        print(root.key, end=&#39; &#39;)
        if root.left_child:
            root.pre_order(root.left_child)
        if root.right_child:
            root.pre_order(root.right_child)

    def post_order(self, root):
        &quot;&quot;&quot;
        postorder traversal
        &quot;&quot;&quot;
        if root is not None:
            self.post_order(root.left_child)
            self.post_order(root.right_child)
            print(root.key, end=&#39; &#39;)

    def pre_order(self, root):
        &quot;&quot;&quot;
        Preorder traversal
        &quot;&quot;&quot;
        print(root.key, end=&#39; &#39;)
        if root.left_child:
            self.pre_order(root.left_child)
        if root.right_child:
            self.pre_order(root.right_child)

    def in_order(self, root):
        &quot;&quot;&quot;
        postorder traversal
        &quot;&quot;&quot;
        if root is not None:
            self.in_order(root.left_child)
            print(root.key, end=&#39; &#39;)
            self.in_order(root.right_child)

if __name__ == &quot;__main__&quot;:
    doctest.testmod(verbose=True)

</code></pre>

<h2 id="toc_2">优先队列和二叉堆</h2>

<p><strong>优先队列</strong>(Priority Queues)是一类抽象数据类型。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。在优先队列的内部，元素的次序是由“优先级”来决定：高优先级的元素排在队首，而低优先级的元素则排在后面。</p>

<p>实现优先队列的经典方法是采用<strong>二叉堆</strong>(Binary Heap)。因为使用二叉堆能将优先队列的入队和出队复杂度都保持在\(O(\log n)\)。 二叉堆有两种：键值总是最小的排在队首称为<strong>最小堆</strong>(min heap)，反之，键值总是最大的排在队首称为<strong>最大堆</strong>(max heap)。</p>

<p>储存元素要满足<strong>堆次序</strong>，即堆中任何一个节点\(x\)，其父节点\(p\)的键值均小于或等于\(x\)的键值。下图所示是具备堆次序性质的完全二叉树。</p>

<h3 id="toc_3">列表与完全二叉树</h3>

<p><strong>不需要使用节点，引用或嵌套列表，用单个列表就能代表完全二叉树</strong>。因为对于完全二叉树，如果节点在列表中的下标为\(p\)，那么其左子节点下标为\(2p\)，右节点为\(2p+1\)。当我们要找任何节点的父节点时，可以直接使用 python 的整除。如果节点在列表中下标为\(n\)，那么父节点下标为\(n//2\)（参考下图）。使用列表, 能够使用简单的数学方法高效地遍历一棵完全二叉树，这也导致了二叉堆的高效实现。</p>

<p><img src="media/14973171257726/14974117374605.jpg" alt=""/></p>

<h3 id="toc_4">二叉堆的操作与实现</h3>

<ul>
<li><code>BinaryHeap()</code>：创建一个新的、空的二叉堆对象</li>
<li><code>insert(k)</code>：把新元素加入到堆中</li>
<li><code>findMin()</code>：返回堆中的最小项，最小项仍保留在堆中</li>
<li><code>delMin()</code>：返回堆中的最小项，同时从堆中删除</li>
<li><code>isEmpty()</code>：返回堆是否为空</li>
<li><code>size()</code>：返回堆中元素的个数</li>
<li><code>buildHeap(list)</code>：从一个包含元素的列表创建新堆</li>
</ul>

<p>有两个关键的操作：</p>

<ol>
<li><code>insert</code>方法。首先，为了满足“完全二叉树”的性质，新键值应该添加到列表的末尾。然而新键值简单地添加在列表末尾，显然无法满足堆次序。所以要通过比较父节点和新加入的元素的方法来重新满足堆次序。如果新加入的元素比父节点要小，可以与父节点互换位置；不断交换，直到到达树的顶端。下图所示一系列交换操作来使新加入元素“上浮”到正确的位置。</li>
</ol>

<p><img src="media/14973171257726/14974156268132.jpg" alt=""/></p>

<p>2.<code>delMin</code>方法 移走根节点的元素后如何保持堆结构和堆次序: 首先，用最后一个节点来代替根节点, 移走最后一个节点保持了堆结构的性质。这么简单的替换，还是会破坏堆次序。第二步，将新节点“下沉”来恢复堆次序。下图所示的是一系列交换操作来使新节点“下沉”到正确的位置。</p>

<p><img src="media/14973171257726/14974156980805.jpg" alt=""/></p>

<pre><code class="language-python">class BinHeap(object):
    &quot;&quot;&quot;
    创建一个新的、空的二叉堆对象
    &quot;&quot;&quot;
    def __init__(self):
        self.list = [0]
        self.size = 0

    def perc_up(self,i):
        &quot;&quot;&quot;
        Percolate the new node into proper position
        &quot;&quot;&quot;
        while i//2&gt;0: 
            if self.list[i] &lt; self.list[i//2]:
                self.list[i], self.list[i//2] = self.list[i//2], self.list[i]
            i = i//2
    
    def insert(self, item):
        &quot;&quot;&quot;把新元素加入到堆中&quot;&quot;&quot;
        self.list.append(item)
        self.size += 1
        self.perc_up(self.size)

    def findMin(self):
        &quot;&quot;&quot;返回堆中的最小项，最小项仍保留在堆中&quot;&quot;&quot;
        return self.list[1]

    def delMin(self):
        &quot;&quot;&quot;返回堆中的最小项，同时从堆中删除&quot;&quot;&quot;
        retval = self.list[1]
        self.list[1] = self.list[-1]
        self.size -=1
        self.list.pop()
        self.perc_down(1)

        return retval


    def perc_down(self, i):
        &quot;&quot;&quot;
        Percolate the root node  down the tree
        &quot;&quot;&quot;
        while (i * 2) &lt;= self.currentSize:
            mc = self.minChild(i)
            if self.heapList[i] &gt; self.heapList[mc]:
                tmp = self.heapList[i]
                self.heapList[i] = self.heapList[mc]
                self.heapList[mc] = tmp
            i = mc
            
    def minChild(self, i):
        &quot;&quot;&quot;
        find the min child
        &quot;&quot;&quot;
        if i * 2 + 1 &gt; self.currentSize:
            return i * 2
        else:
            if self.heapList[i * 2] &lt; self.heapList[i * 2 + 1]:
                return i * 2
            else:
                return i * 2 + 1

    def isEmpty(self):
        &quot;&quot;&quot;返回堆是否为空&quot;&quot;&quot;
        return self.size == 0

    def __len__(self):
        &quot;&quot;&quot;返回堆中元素的个数&quot;&quot;&quot;
        return self.size

    def buildHeap(self,alist):
        &quot;&quot;&quot;从一个包含元素的列表创建新堆&quot;&quot;&quot;
        self.size = len(alist)
        self.list.extend(alist)
        i = self.size//2
        while i &gt;0:
            self.perc_down(i)
            i -= 1

</code></pre>

<h2 id="toc_5">分析树</h2>

<p><strong>分析树</strong>(Parse Tree)是一个反映某种形式语言字符串的语法关系的有根有序树, 常常用于真实世界的结构表示，例如句子或数学表达式。</p>

<p>下图是\( ((7+3)*(5−2))\) 的分析树, 树的层级结构帮我们理解了整个表达式的运算顺序。在计算最顶上的乘法运算前，我们先要计算子树中的加法和减法运算。左子树的加法运算结果为\(10\)，右子树的减法运算结果为\(3\)。利用树的层级结构，一旦我们计算出了子节点中表达式的结果，我们能够将整个子树用一个节点来替换。</p>

<p><img src="media/14973171257726/14974242592531.jpg" alt=""/></p>

<p>建立分析树的第一步是将表达式字符串分解成符号保存在列表里。有四种符号需要考虑：<strong>左括号</strong>，<strong>右括号</strong>，<strong>操作符</strong>和<strong>操作数</strong>。当读到一个左括号时，将开始一个新的表达式，因此需要创建一个子树来对应这个新的表达式。相反，每当读到一个右括号，就得结束这个表达式。另外，操作数将成为叶节点和他们所属的操作符的子节点。最后，每个操作符都应该有一个左子节点和一个右子节点。通过上面的分析我们定义以下四条规则：</p>

<ul>
<li>如果当前读入的字符是<code>(</code>，添加一个新的节点作为当前节点的左子节点，并下降到左子节点处。</li>
<li>如果当前读入的字符在列表[<code>+</code>, <code>-</code>, <code>/</code>, <code>*</code>]中，将当前节点的根值设置为当前读入的字符。添加一个新的节点作为当前节点的右子节点，并下降到右子节点处。</li>
<li>如果当前读入的字符是一个数字，将当前节点的根值设置为该数字，并返回到它的父节点。</li>
<li>如果当前读入的字符是<code>)</code>，返回当前节点的父节点。</li>
</ul>

<p>利用<code>get_left_child</code>和<code>get_right_child</code>方法可以获得子节点的方法。<strong>利用栈跟踪父节点</strong>：当要下降到当前节点的子节点时，将当前节点压入栈；当要返回当前节点的父节点时，从栈中弹出该父节点。</p>

<p>所以使用栈和二叉树来创建分析树，代码如下：</p>

<pre><code class="language-python">from stack import Stack
from binary_tree2 import BinaryTree
import operator

def build_parse_tree(fp_exp):
    fp_list = fp_exp.split()
    p_stack = Stack()
    e_tree = BinaryTree(&#39;&#39;)
    p_stack.push(e_tree)
    current_tree = e_tree

    for i in fp_list:
        if i == &#39;(&#39;:
            current_tree.insert_left(&#39;&#39;)
            p_stack.push(current_tree)
            current_tree = current_tree.get_left_child()
        elif i not in [&#39;+&#39;,&#39;-&#39;,&#39;*&#39;,&#39;/&#39;,&#39;)&#39;]:
            current_tree.set_root_val(int(i))
            parent = p_stack.pop()
            current_tree = parent
        elif i in [&#39;+&#39;,&#39;-&#39;,&#39;*&#39;,&#39;/&#39;]:
            current_tree.set_root_val(i)
            current_tree.insert_right(&#39;&#39;)
            p_stack.push(current_tree)
            current_tree = current_tree.get_right_child()
        elif i == &#39;)&#39;:
            current_tree = p_stack.pop()
        else:
            raise ValueError

    return e_tree

def postorder_eval(tree):
    opers = {&#39;+&#39;:operator.add, &#39;-&#39;:operator.sub, &#39;*&#39;:operator.mul, &#39;/&#39;: operator.truediv}
    res1 = None
    res2 = None

    if tree:
        res1 = postorder_eval(tree.get_left_child())
        res2 = postorder_eval(tree.get_right_child())
        if res1 and res2:
            return opers[tree.get_root_val()](res1, res2)
        else:
            return tree.get_root_val()

pt = build_parse_tree(&quot;( ( 10 + 5 ) * 3 )&quot;)

print(&#39;result = %d&#39; %postorder_eval(pt))
</code></pre>

<h2 id="toc_6">树的遍历</h2>

<p>对树中所有节点的访问称为<strong>遍历</strong>(traversal)。按照节点的访问方式不同，树的遍历模式可分为 3 种。这三种方式常被用于访问树的节点，它们之间的不同在于访问每个节点的次序不同。这三种遍历分别叫做<strong>先序遍历</strong>(preorder)，<strong>中序遍历</strong>(inorder)和<strong>后序遍历</strong>(postorder)。具体定义为：</p>

<ul>
<li><p><strong>先序遍历</strong> 先访问根节点，然后递归使用先序遍历访问左子树，再递归使用先序遍历访问右子树。</p></li>
<li><p><strong>中序遍历</strong> 递归使用中序遍历访问左子树，然后访问根节点，最后再递归使用中序遍历访问右子树。</p></li>
<li><p><strong>后序遍历</strong> 先递归使用后序遍历访问左子树和右子树，最后访问根节点。</p></li>
</ul>

<p>三种遍历模式的代码已经包括在<code>BinaryTree</code>类中（参见<code>节点和引用</code>一节）。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/7/19</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Tree.html'>Tree</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="clustering%20on%20big%20graph.html">
                
                  <h1>Clustering on big graph</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p><strong>Question</strong>: what is the largest value of k such that there is a <code>k-clustering</code> with spacing at least 3?  That is, how many clusters are needed to ensure that no pair of nodes with all but 2 bits in common get split into different clusters?</p>

<p><strong>Input</strong>: <br/>
[first bit of node 1] … [last bit of node 1]<br/>
[first bit of node 2] … [last bit of node 2]</p>

<p>For example, the third line of the file “0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1″ denotes the 24 bits associated with node #2.</p>

<p><strong>Background</strong>:<br/>
The distance between two nodes \(u\) and \(v\) in this problem is defined as the <code>Hamming distance</code>--- the number of differing bits --- between the two nodes&#39; labels. </p>

<p><strong>Note</strong>: NOTE: The graph implicitly defined by the data file is so big that you probably can&#39;t write it out explicitly, let alone sort the edges by cost. So you will have to be a little creative to complete this part of the question. For example, is there some way you can identify the smallest distances without explicitly looking at every pair of nodes?</p>

<h2 id="toc_0">METHOD</h2>

<ul>
<li>We put all the nodes into a hash table, which of size is \(2^n\), where \(n=24\) is the length of input bits. </li>
</ul>

<p><strong>Detail</strong>: We use <code>list</code> to represent the hash table in python, of which index will be the numerical value of the input, and value will be the node number index. The node number index also denotes where each node is own cluster (i.e index of cluster).</p>

<ul>
<li>In order to find a \(k\)-clustering with spacing at least 3, we just need to find neighbors that the distance between neighbors and nodes are 1 or 2.</li>
</ul>

<p><strong>Detail</strong>: We use bit manipulation to find potential   neighbors of a node. According to <code>Hamming distance</code>, the distance means the number of differing bits. Since the distance should be 1 or 2, neighbor of node are such points that differ  from node in no more than 2 bits. Total number of potential neighbor is \(C^2_{24}+C^1_{24} = 300\) . The property of XOR is used to compute its neighbors directly: </p>

<pre><code class="language-python">if x ^ y == z: 
    x ^ z = y 
</code></pre>

<p>Hence, In order to find neighbors \(y\), we just compute <code>x^z</code>, where \(z\) is no more than 3 1s in the 24-bit binary integer.</p>

<ul>
<li>In order to keep track of connected clusters, the <code>disjoint-set</code> data structure is used here.</li>
</ul>

<h2 id="toc_1">Procedure</h2>

<pre><code class="language-python">for each node in Graph (200K iterations):
    for each code that is 0 or 1 or 2 units apart from this vertex:
        Add these 2 vertexes to a cluster.
</code></pre>

<h2 id="toc_2">Implementation</h2>

<pre><code class="language-python">class HashTable:
    def __init__(self, size):
        self.size = size
        self.slots = [None for i in range(self.size)]

    def add(self, key, value):
        if self.slots[key]:
            self.slots[key].append(value)
        else:
            self.slots[key] = [value]

    def values(self):
        key = 1
        for val in self.slots:
            if val:
                yield (key, val)
        key += 1


class BigClustring:

    def __init__(self):
        self.hash_table = None
        self.num = None
        self.len_bit = None
        self.disjoint_set = DisjointSet()
        self.val = []

    def read_from_file(self, file_name):
        with open(file_name) as infile:
            line = infile.readline()
            line = line.strip(&#39;\n&#39;)
            self.num, self.len_bit = [int(num) for num in line.split()]
            self.hash_table = HashTable(2 ** self.len_bit)

            node = 1
            for line in infile.readlines():
                line = line.strip(&#39;\n&#39;)
                line = line.replace(&#39; &#39;, &#39;&#39;)
                val = int(line, 2)
                self.hash_table.add(val, node)
                self.disjoint_set.make_set(node)
                self.val.append(val)
                node += 1

        if self.num + 1 != node:
            raise ValueError

    def hamming(self):
        &quot;&quot;&quot;
        return binary integer at hamming distance 1 or 2
        &quot;&quot;&quot;
        self.hamm = []
        for i in range(self.len_bit):
            for j in range(self.len_bit):
                self.hamm.append(1 &lt;&lt; i | 1 &lt;&lt; j)

    def neighbors(self, val):
        &quot;&quot;&quot;
        return node_index of neighbors for val
        &quot;&quot;&quot;
        for key in self.hamm:
            if self.hash_table.slots[key ^ val] is not None:
                yield self.hash_table.slots[key ^ val][0]

    def cluster(self):
        &quot;&quot;&quot;
        cluster nodes with 0-1-2 distances
        &quot;&quot;&quot;

        # first cluster the 0 distance nodes
        for key, val in self.hash_table.values():
            if len(val) &gt; 1:
                # union
                for val1 in val:
                    for val2 in val:
                        if val1 != val2:
                            self.disjoint_set.union(val1, val2)

        # second cluster the 1-2 distance nodes
        node = 1
        for val in self.val:
            neighbors = self.neighbors(val)
            for neighbor in neighbors:
                self.disjoint_set.union(node, neighbor)
            node += 1
        return len(self.disjoint_set)
</code></pre>

<h2 id="toc_3">Reference</h2>

<ol>
<li><a href="https://rstudio-pubs-static.s3.amazonaws.com/72033_dcd43db591574873aac22be4cde29af6.html">Clustering on big graph, python</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming Distance WIKIPEDIA</a></li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='data_structure_and_algorithm.html'>数据结构和算法</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="minimum_spanning_tree_prim_kruskal.html">
                
                  <h1>Minimum Spanning Tree: Prim's, Kruskal's Algorithm and Clustering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Concepts</a>
</li>
<li>
<a href="#toc_1">Prim&#39;s algorithm</a>
<ul>
<li>
<a href="#toc_2">Implementation</a>
</li>
<li>
<a href="#toc_3">Prim&#39;s v.s. Dijkstra&#39;s</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">Kruskal&#39;s Algorithm</a>
<ul>
<li>
<a href="#toc_5">Implementation</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_6">Clustering</a>
<ul>
<li>
<a href="#toc_7">Implementation</a>
</li>
</ul>


<p>Let \(G=(V, E)\) be a connected, undirected graph with a real-valued weight function \(w\) defined on \(E\). If an acyclic subset \(T\in E\) that connects all of the vertices and whose total weight \(w(T)=\sum_{(u,v)\in T}w(u,v)\) is minimized, \(T\) forms a <code>Minimum Spanning Tree</code>.</p>

<h2 id="toc_0">Concepts</h2>

<ul>
<li><code>safe edge</code>: An edge that may be added to \(A\) without violating the invariant that \(A\) is a subset of some <code>minimum spanning tree</code>.</li>
<li><code>cut</code>: A <code>cut</code> \((S, V-S)\) of an undirected graph \(G=(V,E)\) is a partition of \(V\).</li>
<li><code>cross</code>: We say that an edge \((u,v)\in E\) <code>crosses</code> the cut \((S,V-S)\) if one of its endpoints is in \(S\) and the other is in \(V-S\).</li>
<li><code>respect</code>: If no edge in \(A\) (a subset of some <code>minimum spanning tree</code>) <code>crosses</code> the cut, the cut <code>respects</code> a set \(A\) of edges.</li>
<li><code>light edge</code>: An edge is a <code>light edge</code> crossing a cut if its weight is the minimum of any edge crossing the cut. </li>
</ul>

<h2 id="toc_1">Prim&#39;s algorithm</h2>

<p>In <code>Prim&#39;s algorithm</code>, each step adds a light edge to minimum spanning tree. The running time of the Prim&#39;s algorithm is \(O(E \log(V))\)</p>

<h3 id="toc_2">Implementation</h3>

<pre><code class="language-python">def prim(agraph, start):
    &quot;&quot;&quot;
    Prim&#39;s algorithm for minimum spanning tree
    Using min-heap data structure

    return a minimum spanning tree
    &quot;&quot;&quot;
    # vertex of minimun spanning tree
    mst_vertex = []
    pq = PriorityQueue()
    for v in agraph:
        v.setDistance(sys.maxsize)
        v.setPred(None)
    start.setDistance(0)
    pq.buildHeap([(v.getDistance(), v) for v in agraph])
    while not pq.isEmpty():
        u = pq.delMin()
        mst_vertex.append(u)
        for adjacent in u.getConnections():
            newcost = u.getWeight(adjacent)
            if adjacent in pq and newcost &lt; adjacent.getDistance():
                adjacent.setPred(u)
                adjacent.setDistance(newcost)
                pq.decreaseKey(adjacent, newcost)

    # edges of minimum spanning tree
    mst = []
    for i in range(1, len(mst_vertex)):
        # u, v, cost
        mst.append((mst_vertex[i-1], mst_vertex[i],  mst_vertex[i].getDistance()))

    return mst
</code></pre>

<h3 id="toc_3">Prim&#39;s v.s. Dijkstra&#39;s</h3>

<p><code>Prim&#39;s algorithm</code> are similar to <code>Dijkstra&#39;s algorithm</code>, both of which use a <code>priority queue</code>. And  each of them belongs to <code>greedy algorithm</code>. There is trivial difference when implementing:</p>

<p>\[\text{Prim&#39;s} p(v) = \min_{(u,v): u\in S} w(u,v)\]<br/>
\[\text{Dijkstra&#39;s} s(v) = \min_{(u,v): u\in S} \text{dist(su,u)} w(u,v)\]</p>

<h2 id="toc_4">Kruskal&#39;s Algorithm</h2>

<p>In <code>Kruskal&#39;s algorithm</code>, always add edges in increasing weight, skipping those whose addition would create a cycle.</p>

<p>In order to keep track of the connected components of a minimum spanning tree when implementing Kruskal&#39;s algorithm, a disjoint-set data structure should be used. The pseudo code for <code>MST-KRUSKAL</code>:</p>

<pre><code class="language-python">mst = []
for each vertex in G:
    make-set(vertex)
sort the edges of G into nondecreasing order by weight of edges
for each edge (u,v) in G:
    if find-set(u) != find_set(v):
        mst = mst + (u,v)
        union(u,v)
return mst
</code></pre>

<p>If we use <code>union-by-rank</code> and <code>path-compression</code> heuristics in <code>disjoint-set</code> data structure, the running time of <code>Kruskal&#39;s algorithm</code> is \(O(E\lg V)\).</p>

<h3 id="toc_5">Implementation</h3>

<pre><code class="language-python">def kruskal_mst(agraph):
    &quot;&quot;&quot;
    Return a minimum spanning tree using kruskal&#39;s algorithm
    &quot;&quot;&quot;
    # minimum spanning tree
    mst = []

    # disjoint set
    disjoint_set = DisjointSet()

    # make set
    for vertex in agraph.Vertices():
        disjoint_set.make_set(vertex)

    # edges of the graph
    edges = agraph.edges()
    edges.sort(key=lambda tup: tup[2])

    for u, v, cost in edges:
        if disjoint_set.find_set(u) != disjoint_set.find_set(v):
            mst.append((u, v, cost))
            disjoint_set.union(u, v)
    return mst
</code></pre>

<h1 id="toc_6">Clustering</h1>

<p><strong>Max-Spacing k clustering</strong>: Given a set of objects \(p_1, . . . , p_n\), a distance function \(d(p_i,p_j)\) specifies their similarity.  \(d(p_i,p_j)\) may be an actual distance, or some abstract representation of how dissimilar of two things are. </p>

<p><strong>OUR GOAL</strong>: Divide the \(n\) items up into \(k\) groups so that the minimum distance between items in different groups is maximized.</p>

<p><strong>IDEA</strong>: </p>

<ul>
<li>we maintain clusters as a set of connected components of a graph. </li>
<li>And Iteratively combine the clusters containing the two closest items by adding an edge between them.</li>
<li>Stop when there are \(k\) clusters.</li>
</ul>

<p>You&#39;ll find this is exactly <code>Kruskal&#39;s algorithm</code>.</p>

<h3 id="toc_7">Implementation</h3>

<pre><code class="language-python">def clustering(agraph, k):
    &quot;&quot;&quot;
    Max-Spacing k clustering

    Return maximum spacing of a k-clustering
    and corresponding mst.
    &quot;&quot;&quot;
    # minimum spanning tree
    mst = []

    # disjoint set
    disjoint_set = DisjointSet()

    # make set
    for vertex in agraph.Vertices():
        disjoint_set.make_set(vertex)

    # edges of the graph
    edges = agraph.edges()
    edges.sort(key=lambda tup: tup[2])

    for u, v, cost in edges:
        if len(disjoint_set) &gt;= k:

            if disjoint_set.find_set(u) != disjoint_set.find_set(v):
                mst.append((u, v, cost))
                max_cost = cost
                disjoint_set.union(u, v)
        else:
            break


    return max_cost, mst
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/4</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Tree.html'>Tree</a></span>
          				  
          					    <span class="posted-in"><a href='Graph.html'>Graph</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="data_structure_and_algorithm_1.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="data_structure_and_algorithm_3.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="programming_language.html"><strong>编程语言</strong></a>
        
            <a href="data_structure_and_algorithm.html"><strong>数据结构和算法</strong></a>
        
            <a href="Course.html"><strong>Course</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>Python科学计算三维可视化</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>文献阅读</strong></a>
        
            <a href="Tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="diagrammatize_TCP/IP.html">图解TCP/IP</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="csapp-internet-programming.html">CSAPP - 网络编程</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="head-first_java_note.html">Head first Java</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15323640524161.html">Machine Learning with large datasets</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concets-processes.html">Operating System Concepts 3 - Processes</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
