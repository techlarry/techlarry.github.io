<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[techlarry]]></title>
  <link href="http://larryim.cc/atom.xml" rel="self"/>
  <link href="http://larryim.cc/"/>
  <updated>2018-07-24T15:18:19+08:00</updated>
  <id>http://larryim.cc/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Head first Java]]></title>
    <link href="http://larryim.cc/head-first_java_note.html"/>
    <updated>2018-07-21T10:13:18+08:00</updated>
    <id>http://larryim.cc/head-first_java_note.html</id>
    <content type="html"><![CDATA[
<p>Notes, Head first Java, 2nd Edition</p>

<ul>
<li>
<a href="#toc_0">1 Dive in A Quick Dip</a>
</li>
<li>
<a href="#toc_1">2 Classes and objects</a>
</li>
<li>
<a href="#toc_2">3 Primitives and references</a>
</li>
<li>
<a href="#toc_3">4 Methods use instance variables</a>
<ul>
<li>
<a href="#toc_4">4.1 Methods</a>
</li>
<li>
<a href="#toc_5">4.2 Getters and setters</a>
</li>
<li>
<a href="#toc_6">4.3 Encapsulation</a>
</li>
<li>
<a href="#toc_7">Instance variables.</a>
</li>
<li>
<a href="#toc_8">instance and local variables.</a>
</li>
<li>
<a href="#toc_9">Comparing variables</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">5 Writing a Program</a>
</li>
<li>
<a href="#toc_11">6  Get to know the Java API</a>
</li>
<li>
<a href="#toc_12">7 Inheritance and polymorphism</a>
<ul>
<li>
<a href="#toc_13">7.1 overriding</a>
</li>
<li>
<a href="#toc_14">7.2 polymorphism</a>
</li>
<li>
<a href="#toc_15">7.3 method overloading</a>
</li>
</ul>
</li>
<li>
<a href="#toc_16">8 interfaces and abstract classes</a>
<ul>
<li>
<a href="#toc_17">Abstract classes</a>
</li>
<li>
<a href="#toc_18">Abstract methods</a>
</li>
<li>
<a href="#toc_19">the ultimate superclass: Object</a>
</li>
<li>
<a href="#toc_20">Using polymorphic references of type Object has a price</a>
</li>
<li>
<a href="#toc_21">Interface</a>
</li>
</ul>
</li>
<li>
<a href="#toc_22">9 constructors and garbage collection</a>
</li>
</ul>


<h2 id="toc_0">1 Dive in A Quick Dip</h2>

<p>Java has friendly syntax, object-oriented features, memory management, and best of all - the promise of probability (write-one/run-anywhere).</p>

<p>You type a source code file(<code>.java</code>). compile it using the <code>javac</code> compiler, then run(<code>java</code>) the compiled bytecode(<code>.class</code>) on a java virtual machine.</p>

<p><img src="media/15321391987415/code_structure.png" alt="code_structure"/></p>

<p>Every Java application has to have at least one class, and at least one main method.</p>

<p>The main method <code>public static void main(String[] args){//your code goes here}</code>is where your program starts running.</p>

<p>Java has three standard looping constructs: <code>while</code>, <code>do-while</code>, and <code>for</code>.</p>

<p>A boolean and an integer are not compatible types in Java.</p>

<pre><code class="language-text">int x=1;
while (x) {} //wrong
</code></pre>

<p><code>System.out.println</code> inserts a newline, <code>System.out.print</code> keeps printing to the same line.</p>

<h2 id="toc_1">2 Classes and objects</h2>

<p>A class describes what an object <strong>knows</strong> and what an object <strong>does</strong>.</p>

<p>A class is the blueprint for an object.</p>

<h2 id="toc_2">3 Primitives and references</h2>

<p>Variables must always be declared with a name and a type. Variables come in two flavors: <strong>primitive</strong> and <strong>reference</strong>.(变量的生命必须有类型和名称。变量有两种：primitive和引用)</p>

<p><strong>primitive variable</strong>:</p>

<ul>
<li>A primitive variable value is the bits representing the value. primitive变量的值是表示该值的位。</li>
</ul>

<p><strong>Reference variable</strong></p>

<ul>
<li>A reference variable value is the bits representing a way to get to an object on the heap.引用变量的值是表示一种到达堆上的对象的方法的位。</li>
<li>A reference variable is like a remote control. Using the dot operator(<code>.</code>) on a reference variable is like pressing a button on the remote control to access a method or instance variables.</li>
<li>A reference variable has a value of <code>null</code> when it is not referencing any object.</li>
</ul>

<p><strong>Array</strong></p>

<ul>
<li>An array is always an object, even if the array is declared to hold primitives. </li>
<li>Every element in an array is just a variable.</li>
</ul>

<p>The 3 steps of <strong>object declaration, creation and assignment</strong><br/>
(e.g. <code>Dog myDog = new Dog()</code>);</p>

<ul>
<li><strong>declare</strong> a reference variable: tell the JVM to allocate space for a reference variable, and names that variable myDog</li>
<li><strong>create</strong> an object: tells the JCM to allocate space for a new Dog object on the heap.</li>
<li><strong>Link</strong> the object and the reference: Assigns the new Dog to the reference variable myDog.</li>
</ul>

<h2 id="toc_3">4 Methods use instance variables</h2>

<h3 id="toc_4">4.1 Methods</h3>

<p><strong>Class define what an object knows and what an object does.</strong> Things an object knows are its <em>instance variables</em>(state), things an object does are its <em>methods</em>(behavior).</p>

<p><strong>Methods</strong>:<br/>
<strong>A method uses parameters. A caller passes arguments.</strong></p>

<ul>
<li>Arguments are the things you pass into the methods.</li>
<li>If a method takes a parameters, you must pass it something.</li>
<li>Methods can return values. Every method is declared is declared with a return type.</li>
<li>If you declare a method to return a value, you <em>must</em> return a value of the declared type or a value that is <em>compatible</em> with the declared type.</li>
<li>Java is <strong>pass-by-value</strong>, which means <strong>pass-by-copy</strong>.</li>
</ul>

<h3 id="toc_5">4.2 Getters and setters</h3>

<p><strong>Getters</strong> and <strong>setters</strong> let you, well, <em>get and set things</em>.</p>

<ul>
<li>A Getter&#39;s sole purpose in life is to send back, as a return value, the value of whatever it is that particular Getter is supposed to be Getting.</li>
</ul>

<h3 id="toc_6">4.3 Encapsulation</h3>

<p>By forcing everybody to call a setter method, we can protect variables from unacceptable changes.</p>

<pre><code class="language-java">theCat.height = 0 //yikes! we can&#39;t let this happen

public void setHeight(int ht){
    if (ht&gt;9){ // we punt in checks to guarantee a minimum cat height.
        height=ht;
    }
}
</code></pre>

<p>An <strong>encapsulation</strong> <em>starter</em> rule of thumb: mark your instances variables <strong><em>private</em></strong>, and provide <strong><em>public</em></strong> getters and setters for access control.</p>

<ul>
<li>Encapsulations puts a force-field around my instance variables, so nobody can set them to something <em>inappropriate</em>.</li>
<li>The point to setters (and getters, too) is that <strong><em>you can change your mind later, without breaking anybody else’s code</em></strong>!</li>
</ul>

<pre><code class="language-java">class GoodDog {
    private int size; //Make the instance variable private
    public int getSize() { // make the getter methods public
        return size; 
    }

    public void setSize(int s) {  // make the setter methods public
        size = s; 
    }

    // even though the methods don&#39;t really add new functionality,
    // the cool thing is that you can change your mind later.
    // you can come back and make a method safer, faster, better
    void bark() {
        if (size &gt; 60) { 
            System.out.println(“Wooof! Wooof!”); 
        } else if (size &gt; 14) {
            System.out.println(“Ruff! Ruff!”); } 
        else {
            System.out.println(“Yip! Yip!”); 
        }
    }
}
</code></pre>

<h3 id="toc_7">Instance variables.</h3>

<p>You don&#39;t have to initialize instance variables, because they always have a default value.</p>

<ul>
<li>intergers: 0</li>
<li>floating points: 0.0</li>
<li>booleans: false</li>
<li>references: null</li>
</ul>

<h3 id="toc_8">instance and local variables.</h3>

<p>The difference between instance and local variables:</p>

<ul>
<li><strong>Instance</strong> variables are declared <u>inside a class</u> but not within a method.</li>
<li><strong>Local</strong> variables are declares <u>within a method</u> .</li>
<li><strong>Local</strong> variables <u>must be initialized</u> before use.</li>
</ul>

<h3 id="toc_9">Comparing variables</h3>

<p>If you want to know if two objects are <strong>equal</strong>, you need the <code>.equal()</code> method.</p>

<ul>
<li>whether two different objects should be treated as equal depends on what makes sense for that particular object type. (e.g. dog/string)</li>
</ul>

<pre><code class="language-java">String S = &quot;baby&quot;;
S.equal(another_string);
</code></pre>

<p>To see if two reference are the same (which means they refer to the same object on the heap) use the <code>==</code> operator.</p>

<pre><code class="language-text">Foo a = new Foo(); 
Foo b = new Foo(); 
Foo c = a; 
if (a == b) { // false } 
if (a == c) { // true } 
if (b == c) { // false }
</code></pre>

<p>To compare two primitives, use the <code>==</code> operator.</p>

<ul>
<li>Operator <code>==</code> doesn&#39;t care about the size of the variable, so all the extra zeros on the left end don&#39;t matter.</li>
</ul>

<pre><code class="language-java">int a = 3;
byte b = 3;
if (a==b){ //true}
</code></pre>

<h2 id="toc_10">5 Writing a Program</h2>

<ul>
<li><strong>prep code</strong>: a form of pseudocode, to help you focus on the logic without stressing about syntax. 一种伪代码</li>
<li><strong>test code</strong>: a class or methods that will test the real code and validate that it&#39;s doing the right thing. 测试代码</li>
<li><strong>real code</strong>: the actual implementation of the class. 真实代码</li>
</ul>

<p><strong>Extreme Programming</strong>（<a href="https://en.wikipedia.org/wiki/Extreme_programming">极限编程</a>):</p>

<ul>
<li>Write the test code first</li>
<li>Make small, but frequent, releases</li>
<li>Develop in iteration cycles.</li>
</ul>

<h2 id="toc_11">6  Get to know the Java API</h2>

<p><code>ArrayList</code> is a class in the core Java library (the API).</p>

<ul>
<li> <code>boolean add(Object elem)</code>: Adds the objects parameter to the list(return <code>true</code>).</li>
<li> <code>boolean remove(int index)</code>: Removes the object at the index parameter. Returns <code>true</code> if the element was in the list.</li>
<li> <code>boolean remove(Object elem)</code>: Removes this object(if it&#39;s in the ArrayList).</li>
<li> <code>boolean contains(Object elem)</code>: Returns <code>true</code> if there&#39;s a match for the object parameter.</li>
<li> <code>boolean isEmpty()</code>: Returns <code>true</code> if the list has no elements</li>
<li> <code>int indexOf(Object elem)</code>: Returns either the index of the object parameter, or -1</li>
<li> <code>size()</code>: Return the number of elements currently in the list.</li>
<li> <code>Object get(int index)</code>: Return the object currently at the index parameter.</li>
</ul>

<p>You have to know the full name of the class you want to use in your code. You have two options:</p>

<ul>
<li>Import: put an import statement at the top of your source code file:
<ul>
<li><code>import java.util.ArrayList</code></li>
</ul></li>
<li>Type: type the full name everywhere in your code. Each time you use it.
<ul>
<li><code>java.util.ArrayList&lt;Dog&gt; list = new java.util.ArrayList&lt;Dog&gt;();</code></li>
</ul></li>
</ul>

<h2 id="toc_12">7 Inheritance and polymorphism</h2>

<h3 id="toc_13">7.1 overriding</h3>

<p><strong>Overriding</strong>（重写) just means that a subclass redefines one of its inherited methods when it needs to change or extend the behavior of that method.</p>

<p>When one class inherits from another, the subclass inherits from the superclass. In Java, we say that the <strong>subclass extends the superclass</strong>.子类继承自父类。</p>

<p>Instance variables are not overridden because they don&#39;t need to be. They don&#39;t define any special behavior, so a subclass can give an inherited instance variable any value it chooses.实例变量无法被覆盖掉是因为不需要，它们并没有定义特殊的行为。</p>

<p>When you want to know if one thing should extend another, apply the IS-A test.若你想要知道某物是否应该要继承另一物时，则可以用IS-A(是一个)测试来检验。</p>

<p><strong>If class B extends class A, class B IS-A class A.</strong>   如果类B继承类A，那么类B是一个类A。</p>

<p>if your subclass overriding method, you can call the superclass version using the keyword <strong>super</strong>.</p>

<pre><code class="language-java">// this calls the inherited version on roam(),
// then comes back to do your own subclass-specific code
public void roam(){
    super.roam();
    //my own roam stuff
}
</code></pre>

<p>There are four access levels, moving from most restrictive to least, the four access levels are: 四种权限，左边是最受限制的，而越往右边限制程度越小：</p>

<p>prive, default, protected, public</p>

<ul>
<li>public members are inherited. public类型的成员会被继承</li>
<li>private members are not inherited. private类型的成员不会被继承</li>
</ul>

<p>Inheritances lets you guarantee that all classes grouped under a certain supertype have all the methods that the supertype has.In other words, you define a common protocol for a set of classes related through inheritance. 继承让你可以确保某个父类型之下的所有类都会有父类型所持有的全部方法。也就是说，你会通过继承来定义相关类间的共同协议。</p>

<p>when you define a supertype for a group of classes, any subclass of that supertype can be substituted where the supertype is expected.<br/>
当你定义出一组类的父型时，你可以用子型的任何类来填补任何需要或期待父型的位置。</p>

<h3 id="toc_14">7.2 polymorphism</h3>

<p>With polymorphism, the reference type can be a superclass of the actual object type. 运用多态时，引用类型可以是实际对象类型的父类。</p>

<pre><code class="language-java">Animal[] animals = new Animal[3];
animals [0] = new Dog();
animals [1] = new Cat();
animals [2] = new Lion();
for (int i=0; i&lt; animals.length; i++) {
    animals[i].eat();
    animals[i].roam();
}
</code></pre>

<p>You can have polymorphic arguments and return types. 参数和返回类型也可以多态。</p>

<pre><code class="language-java">class Vet {
    public void giveShot(Animal a) { 
    // do horrible things to the Animal at 
    // the other end of the ‘a’ parameter 
    a.makeNoise(); 
    }
}

class PetOwner {
    public void start() { 
        Vet v = new Vet(); 
        Dog d = new Dog(); 
        Hippo h = new Hippo(); 
        v.giveShot(d); 
        v.giveShot(h);
}
</code></pre>

<p>If I write my code using polymorphic arguments, where I declare the method parameter as a superclass type, I can pass in any subclass object at runtime. 如果我将程序代码编写使用多态参数，也就是说将参数声明为父类类型，我就可以在运行时传入任何的子类对象。</p>

<p>With polymorphism, you can write code that doesn&#39;t have to change when you introduce new subclass types into the program. 通过多态，你就可以编写出引进新型子类时也不必修改的程序。</p>

<p>There are three things that can prevent a class from being subclassed.</p>

<ul>
<li>a class can be non-public (if you don&#39;t declare the class as public. A non-public class can be subclassed only by classes in the same package as the class. 类可以是非公有的，非公有的类只能被同一个包的类作出子类。</li>
<li>Using keyword modifier <code>final</code> to stop  a class from being subclassed. 使用<code>final</code>修饰符阻止类被继承。</li>
<li>if a class has only <code>private</code> constructors, it can&#39;t be subclassed. 如果类只拥有<code>private</code>的构造程序，它不能被继承。</li>
</ul>

<p>if you want to protect a specific method from being overridden, mark the method with the <code>final</code> modifier. 如果你想要防止特定的方法被覆盖，可以将该方法标识成final表示没有任何的方法可以被覆盖。</p>

<p>Rules for overriding:</p>

<ul>
<li>Arguments must be the same, and return types must be compatible. 参数必须要一样，且返回类型必须要兼容</li>
<li>The method can&#39;t be less accessible. 不能降低方法的访问权限</li>
</ul>

<h3 id="toc_15">7.3 method overloading</h3>

<p><strong>Method overloading</strong>(方法重载) is nothing more than having two methods with the same name but different argument lists. 方法重载就是方法名称相同，但参数列表不同。 </p>

<ul>
<li>Purpose: overloading lets you make multiple versions of a method, with different argument lists, for convenience to the callers.  重载可以有同一方法的多个不同参数列表的版本，方便了调用者。</li>
<li>The return types can be different 返回类型可以不同</li>
<li>You can&#39;t change only the return type 不能只改变返回类型</li>
<li>You can vary the access levels in any direction 可以更改访问权限</li>
</ul>

<h2 id="toc_16">8 interfaces and abstract classes</h2>

<p>What&#39;s an interface? it&#39;s a 100% abstract class. <br/>
What&#39;s an abstract class? it&#39;s a class that can&#39;t be instantiated.</p>

<h3 id="toc_17">Abstract classes</h3>

<p>Here&#39;s where it gets weird:</p>

<pre><code class="language-text">Animal anim = new Animal(); 
</code></pre>

<p>There two are the same type, but what the heck does an Animal object look like?</p>

<p><strong>Some classes just should not be instantiated!</strong><br/>
How?  By marking the class as <strong>abstract</strong>, the compiler will stop any code, anywhere, from ever creating an instance of that type. i.e. prevent a class from ever being instantiated.</p>

<p>Making a class abstract before the class declaration:</p>

<pre><code class="language-java">abstract class Caine extends Animal {
    public void roam() {}
}
</code></pre>

<p>When you&#39;re designing your class inheritance structure, you have to decide which classes are <em>abstract</em> and which are <em>concrete</em>. </p>

<ul>
<li><strong>Concrete</strong> classes are those that are specific enough to be instantiated. </li>
<li>A <strong>concrete</strong> class just means that it&#39;s OK to make objects of that type.</li>
<li>An <strong>abstract class</strong> has virtually no use, no value, no purpose in life, unless it is extended.</li>
</ul>

<h3 id="toc_18">Abstract methods</h3>

<p>An <strong>abstract method</strong> means the method must be overriden, whereas an abstract class means the class must be extended.</p>

<ul>
<li>there isn&#39;t any code that would make sense in the abstract method, you won&#39;t put in a method body. e.g. <code>public abstract void eat()</code>.</li>
<li>If you declare an abstract method, you must mark the class abstract as well. You can&#39;t have an abstract method in a non-abstract class.</li>
<li>You must implement all abstract methods.</li>
</ul>

<h3 id="toc_19">the ultimate superclass: Object</h3>

<p>Every class in Java extends class Object. Class Object is the mother of all classes; it&#39;s the superclass of everything. Java中的每个类都是从Object这个类继承出来的。Object类是所有类的妈妈，他是所有类的父类。</p>

<ul>
<li>Any class that doesn&#39;t <em>explicitly</em> extend another class, <em>implicitly</em> extends Object.</li>
</ul>

<p>Methods of Object class:</p>

<ul>
<li><code>equals()</code>: tell you if two objects are considered equal.</li>
<li><code>getClass()</code>: Gives you back the class that object was instantiated from.</li>
<li><code>hashCode()</code>: Prints out a hashcode for the object</li>
<li><code>toString()</code>: Prints out a String message with the name of the class and some other number we rarely care about.</li>
</ul>

<p>Object is a <strong>non-abstract</strong> class because it&#39;s got method implementation code that all classes can inherit and use out-of-box, without having to override the methods.</p>

<p>The Object class serves two main purpose:</p>

<ul>
<li>to act as a polymorphic type for methods that need to work on any class that you or anyone else makes 作为方法的多态类型</li>
<li>to provide real method code that all objects in Java need at runtime (and putting them in class Object means all other classes inherit them).提供Java在执行期堆任何对象都有需要的实现方法代码。</li>
</ul>

<h3 id="toc_20">Using polymorphic references of type Object has a price</h3>

<p>When you put an object into an <code>ArrayList&lt;Dog&gt;</code>, it goes in as a Dog, and coms out as a Dog:</p>

<pre><code class="language-java">// Make an ArrayList declared to hold Dog objects.
ArrayList&lt;Dog&gt; myDogArrayList = new ArrayList&lt;Dog&gt;();
// Make a Dog
Dog aDog = new Dog();
// Add the Dog to the list
myDogArrayList.add(aDog);
//Assign the Dog from the list to a new Dog reference variable
Dog d = myDogArrayList.get(0);
</code></pre>

<p><strong>Everything comes out of an <code>ArrayList&lt;Object&gt;</code> as a reference of type Object, regardless of what the actual object is.</strong> 任何从<code>ArrayList&lt;Object&gt;</code>取出的东西都会被当作Object类型的引用，而不管它原来是什么。</p>

<pre><code class="language-java">// make an ArrayList declared to hold any type of Object
ArrayList&lt;Object&gt; myDogArrayList = new ArrayList&lt;object&gt;()
// make a Dog
Dog aDog = new Dog();
// Add the Dog to the list
myDogArrayList.add(aDog);
// No!! Won&#39;t compile!! the get() method returns type Object.
// The compiler knows only that the object inherits from Object,
// but it doesn&#39;t know it&#39;s a Dog!!
Dog d = myDogArrayList.get(0)
</code></pre>

<p><strong>The compiler decides whether you can call a method based on the reference type, not the actual object type.</strong>:</p>

<pre><code class="language-java">Object o = al.get(index);
// Class Object has a hashCode() method
// so you can call that method on any object in Java
int i = o.hashCode();
// Can&#39;t do this!! the Object class  has no idea what it means to bark().
o.bark();
</code></pre>

<p><img src="media/15321391987415/method%20based%20on%20the%20reference%20type.png" alt="method based on the reference type"/></p>

<p>If you&#39;re sure the object is really a Dog, you can make a new Dog reference to it by copying the Object reference, and forcing that copy to go into a Dog reference variable, using a cast (Dog).</p>

<pre><code class="language-java">Object o = al.get(index);
// cast the Object back to a Dog we know is there.
Dog d = (Dog) o;
d.roam();
</code></pre>

<p>If you&#39;re not sure it&#39;s a Dog, you can use the <code>instanceof</code> operator to check.</p>

<pre><code class="language-java">if (o instanceof Dog) {
    Dog d = (Dog) o;
}
</code></pre>

<h3 id="toc_21">Interface</h3>

<p>Questions: what if you want to add Dog some Pet behaviors?</p>

<ul>
<li><p>Option one: We take the easy path, and put pet method in class Animal.</p>
<ul>
<li>Pros: All the Animals will instantly inherit the pet behaviors. We won&#39;t have to touch the existing Animal subclasses at all.</li>
<li>Cons: Some animals like lion, wolf are not a pet. Non-pet Animals running around with pet methods.</li>
</ul></li>
<li><p>Option two: We start with option one, putting the pet methods in class Animal, but we make the methods abstract.</p>
<ul>
<li>Pros: All classes must override the methods, but they can make the methods &quot;do-nothings&quot;.</li>
<li>Cons: Waste a lot of time to implement every concrete Animal subclasses.</li>
</ul></li>
<li><p>Options three: Put the pet methods Only in the classes where they belong.</p>
<ul>
<li>Pros: The methods are where they belong, and only where they belong.</li>
<li>Cons: Firstly, you&#39;d have to agree to a protocol, and all programmers of pet Animal classes now and in the future would have to know about the protocol. Secondly, you don&#39;t get to use polymorphism for the pet methods </li>
</ul></li>
</ul>

<p>It looks like we need two superclasses at the top.<br/>
<img src="media/15321391987415/it%20looks%20like%20we%20need%20two%20superclasses%20at%20the%20top.png" alt="it looks like we need two superclasses at the top"/></p>

<p>It’s called &quot;<strong>multiple inheritance</strong>&quot;(多重继承) and it can be a Really Bad Thing. Because multiple inheritance has a problem known as <strong>The Deadly Diamond of Death</strong>(致命的死亡砖石)</p>

<p><img src="media/15321391987415/deadly_diamond_of_death.png" alt="deadly_diamond_of_death"/></p>

<p>Java的方案: Interface!!!</p>

<ul>
<li>A Java <strong>interface</strong>(接口) solves multiple inheritance problem by giving you much of the polymorphic benefits of multiple inheritance without the pain and suffering from the Deadly Diamond of Death.</li>
</ul>

<p>How?</p>

<ul>
<li>surprisingly simple: <strong><em>make all the methods abstract</em></strong></li>
<li>A Java interface is like a 100% pure abstract class.</li>
</ul>

<p>To define an interface:</p>

<pre><code class="language-java">//use the keyword &quot;interface&quot; instead of &quot;class&quot;
public interface Pet {}
</code></pre>

<p>To implement an interface:</p>

<pre><code class="language-java">// Use the keyword &quot;implements&quot; followed by the interface name.
public class Dog extends Canine implements Pet {}
</code></pre>

<p>A class can implement <em>multiple</em> interfaces!</p>

<pre><code class="language-java">public class Dog extends Animal implements Pet, Saveable, Paintable {}
</code></pre>

<p>Classes from <em>different</em> inheritance trees can implement the <em>same</em> interface.</p>

<p><img src="media/15321391987415/Classes%20from%20different%20inheritance%20trees%20can%20implement%20the%20same%20interface..png" alt="Classes from different inheritance trees can implement the same interface."/></p>

<p>How do you know whether to make a class, subclass, an abstract class, or an interface?</p>

<ul>
<li>Make a class that doesn’t extend anything (other than Object) when your new class doesn’t pass the IS-A test for any other type.</li>
<li>Make a subclass (in other words, extend a class) only when you need to make a <strong><em>more specific</em></strong> version of a class and need to override or add new behaviors.</li>
<li>Use an abstract class when you want to define a <strong><em>template</em></strong> for a group of subclasses, and you have at least some implementation code that all subclasses could use. Make the class abstract when you want to guarantee that nobody can make objects of that type.</li>
<li>Use an interface when you want to define a <strong><em>role</em></strong> that other classes can play, regardless of where those classes are in the inheritance tree.</li>
</ul>

<h2 id="toc_22">9 constructors and garbage collection</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[图解TCP/IP]]></title>
    <link href="http://larryim.cc/diagrammatize_TCP/IP.html"/>
    <updated>2018-01-22T14:01:39+08:00</updated>
    <id>http://larryim.cc/diagrammatize_TCP/IP.html</id>
    <content type="html"><![CDATA[
<p>在计算机通信中，事先达成一个详细的约定，并遵循这一约定进行处理，这种约定其实就是<strong>协议</strong>。</p>

<p><strong>计算机网络体系结构</strong>将网络协议进行了系统的归纳。TCP/IP就是IP、TCP、HTTP等协议的集合。除此之外，还有很多其他类型的网络体系结构。</p>

<p><img src="media/15166008990128/15322220890961.jpg" alt=""/></p>

<h2 id="toc_0">OSI模型</h2>

<p><em><u>开放式系统互联通信参考模型</u></em>(Open System Interconnection Reference Model， 简称<strong>OSI模型</strong>)。在这一模型中，每个分层都接收由它下一层所提供的特定服务，并且负责为自己的上一层提供特定的服务。上下层之间进行交互时所遵循的约定叫做接口。统一层之间的交互所遵循的约定叫做协议。</p>

<ul>
<li>分层可以将每个独立使用，即使系统中某些分层发生变化，也不会波及整个系统</li>
<li>分层能够细分通信功能，更易于单独实现每个分层的协议，并界定各个分层的具体责任和义务。</li>
</ul>

<p><img src="media/15166008990128/15322230855436.jpg" alt=""/></p>

<ul>
<li>应⽤层：为应⽤程序提供服务并规定应⽤程序中通信相关的细节。包括⽂件传输、电⼦邮件、远程登录（虚拟终端）等协议。 </li>
<li>表⽰层：将应⽤处理的信息转换为适合⽹络传输的格式，或将来⾃下⼀层的数据转换为上层能够处理的格式。因此它主要负责数据格式的转换。具体来说，就是将设备固有的数据格式转换为⽹络标准传输格式。不同设备对同⼀⽐特流解释的结果可能会不同。因此，使它们保持⼀致是这 ⼀层的主要作⽤。 </li>
<li>会话层： 负责建⽴和断开通信连接（数据流动的逻辑通路），以及数据的分割等数据传输相关的管理。 </li>
<li>传输层： 起着可靠传输的作⽤。只在通信双⽅节点上进⾏处理，⽽⽆需在路由器上处理。 </li>
<li>⽹络层：将数据传输到⽬标地址。⽬标地址可以是多个⽹络通过路由器连接⽽成的某⼀个地址。因此这⼀层主要负责寻址和路由选择。 </li>
<li>数据链路层：负责物理层⾯上互连的、节点之间的通信传输。例如与1个以太⽹相连的2个节点之间的通信。 将0、1序列划分为具有意义的数据帧传送给对端（数据帧的⽣成与接收）。 </li>
<li>物理层：负责0、1⽐特流（0、1序列）与电压的⾼低、光的闪灭之间的互换。</li>
</ul>

<h2 id="toc_1">TCP/IP协议</h2>

<p><img src="media/15166008990128/15322239071091.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 网络编程]]></title>
    <link href="http://larryim.cc/csapp-internet-programming.html"/>
    <updated>2018-07-20T01:02:55+08:00</updated>
    <id>http://larryim.cc/csapp-internet-programming.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 客户端-服务器编程模型</a>
</li>
<li>
<a href="#toc_1">2 网络</a>
<ul>
<li>
<a href="#toc_2">2.1 网络层次系统</a>
</li>
<li>
<a href="#toc_3">2.2 网络协议</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">3 全球IP因特网</a>
<ul>
<li>
<a href="#toc_5">3.1 IP地址</a>
</li>
<li>
<a href="#toc_6">3.2 域名</a>
</li>
<li>
<a href="#toc_7">3.3 因特网连接</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">4 套接字接口</a>
<ul>
<li>
<a href="#toc_9">4.1 Echo客户端和服务器示例</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">5 Web服务器</a>
<ul>
<li>
<a href="#toc_11">5.1 Web基础</a>
</li>
<li>
<a href="#toc_12">5.2 Web内容</a>
</li>
<li>
<a href="#toc_13">5.3 HTTP事务</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">1 客户端-服务器编程模型</h2>

<p>每个网络应用都是基于<strong>客户端-服务器</strong>模型的。</p>

<p>客户端-服务器模型中的基本操作是<strong>事务</strong>(transaction)。一个客户端-服务器事务由以下四步组成：</p>

<ol>
<li>当一个客户端需要服务时，它向服务器发送一个请求，发起一个事务。</li>
<li>服务器收到请求后，解释它，并以适当的方式操作它的资源。</li>
<li>服务器给客户端发送一个响应，并等待下一个请求。</li>
<li>客户端收到响应并处理它。</li>
</ol>

<p><img src="media/15320197756867/client-server%20model.png" alt="client-server mode"/></p>

<p><strong>客户端和服务器是进程</strong>，而不是常提到的机器或者主机。</p>

<ul>
<li>一台主机可以同时运行许多不同的客户端和服务器</li>
<li>一个客户端和服务器的事务可以在同一台或是不同的主机上。</li>
</ul>

<h2 id="toc_1">2 网络</h2>

<p>对主机而言，网络只是又一种I/O设备，是数据源和数据接收方。物理上而言，网络是一个按照地理远近组成的层次系统。</p>

<h3 id="toc_2">2.1 网络层次系统</h3>

<p>(1) 最底层：以太网段<br/>
<strong>局域网</strong>(LAN, Local Area Network)的范围一般限制在一个建筑或者校园内。最流行的局域网技术是<strong>以太网</strong>(Ethernet)，由电缆和集线器(hub)组成一个以太网段。</p>

<p><img src="media/15320197756867/ethernet%20segment.png" alt="ethernet segment"/></p>

<p>(2) 桥接以太网<br/>
<strong>桥接以太网</strong>(bridged Ethernet)是将以太网段用电缆和网桥(bridge)连接成的较大的局域网。<br/>
<img src="media/15320197756867/bridged%20ethernet%20segment.png" alt="bridged ethernet segment"/></p>

<p>(3) 互联网络<br/>
多个不兼容的局域网可以通过路由器(routers)连接成互联网络(internets)。</p>

<p><img src="media/15320197756867/last_level_internets.png" alt="last_level_internets"/></p>

<h3 id="toc_3">2.2 网络协议</h3>

<p>互联网络是由各种局域网和广域网组成，它们采用完全不同且不兼容的技术。那么如何能让某台主机跨过所有不兼容的网络发送数据位到另一台目的主机呢？</p>

<p>解决方法：一层运行在每台主机和路由器上的<strong>协议</strong>软件，它消除了不同网络之间的差异。协议提供了两种基本能力：</p>

<ul>
<li>提供了命名机制
<ul>
<li>定义一致的<strong>主机地址</strong>(host adress)格式</li>
<li>每台主机会被分配至少一个<strong>互联网络地址</strong>(internet address)，地址唯一地标识了主机</li>
</ul></li>
<li><p>提供了传送机制</p>
<ul>
<li>定义了统一的基本传送单位-<strong>包</strong>(packet)</li>
<li>包由<strong>包头</strong>(header)和<strong>有效载荷</strong>(payload)组成
<ul>
<li>包头包括包的大小以及源主机和目的主机的地址</li>
<li>有效载荷包括从源主机发出的数据位</li>
</ul></li>
</ul>
<p><img src="media/15320197756867/Transferring%20Internet%20Data%20Via%20Encapsulation.png" alt="Transferring Internet Data Via Encapsulation"/></p></li>
</ul>

<p>PH: Internet packet header, 互联网络包头<br/>
FH: LAN frame header, 局域网帧头</p>

<h2 id="toc_4">3 全球IP因特网</h2>

<p>全球IP因特网(Global IP Internet)是最著名和最成功的互联网络(internet)实现。每台因特网主机都运行实现TCP/IP协议的软件，使用套接字接口(sockets interface)函数和Unix I/O函数来通信。</p>

<p><img src="media/15320197756867/hardware%20and%20software%20organization%20of%20an%20internet%20application.png" alt="hardware and software organization of an internet application"/></p>

<p>从程序员的角度：</p>

<ul>
<li>主机被映射为一组32位的<strong>IP地址</strong>(IP addresses)
<ul>
<li>128.2.203.179</li>
</ul></li>
<li>IP地址被映射为一组标识符，叫做<strong>域名</strong>(domain name)</li>
<li>因特网主机上的进程能够通过<strong>连接</strong>和任何其他因特网主机上的进程通信。</li>
</ul>

<h3 id="toc_5">3.1 IP地址</h3>

<p>32位IP地址存在一个IP地址结构(<code>in_addr</code>)中</p>

<ul>
<li>IP地址在内存中是以<strong>网络字节顺序</strong>(network byte order, 大端法)存放的</li>
</ul>

<pre><code class="language-c">/* Internet address structure */ 
struct in_addr { 
    uint32_t s_addr; /* network byte order (big-endian) */ 
};
</code></pre>

<h3 id="toc_6">3.2 域名</h3>

<p><strong>域名</strong>(domain names)是一串用句点分隔的单词(字母、数字和破折号)。域名集合形成了一个层次结构，可以表示为一棵树。</p>

<p><img src="media/15320197756867/Internet%20Domain%20Names.png" alt="Internet Domain Names"/></p>

<p><strong>域名系统</strong>(Domain Naming System, DNS)是映射IP地址和域名的数据库。可以把DNS数据库视为上百万的<strong>主机条目结构</strong>(host entry structure)的集合，其中每条定义了一组域名和一组IP地址之间的映射。</p>

<ul>
<li>DNS映射，可以通过<code>nsloopup</code>查看</li>
<li>在最简单的情况中，一个域名和一个IP地址之间是一一映射
<ul>
<li><code>nslookup whaleshark.ics.cs.cmu.edu</code> - <code>Address: 128.2.210.175</code></li>
</ul></li>
<li>然而，在某些情况下，多个域名可以映射为同一个IP地址
<ul>
<li><code>nslookup cs.mit.edu/ nslookup eecs.mit.edu</code> - <code>Address: 18.62.1.6</code></li>
</ul></li>
<li>在最通常的情况下，多个域名可以映射到同一组的多个IP地址
<ul>
<li><code>nslookup www.twitter.com</code> - <code>Address: 199.16.156.6</code>, <code>Address:199.16.156.70</code></li>
</ul></li>
</ul>

<h3 id="toc_7">3.3 因特网连接</h3>

<p>客户端和服务器通过<strong>连接</strong>(connections)发送字节流来通信，每一个连接都有如下特点：</p>

<ul>
<li>点对点(point-to-point)：连接一对进程</li>
<li>全双工(full-duplex)：数据可以同时在两个方向传送</li>
<li>可靠性(reliable)：发送和接收的字节流顺序相同</li>
</ul>

<p>套接字(sockets)是连接的端点，套接字地址用 “地址：端口”来表示。</p>

<ul>
<li>端口(port)是一个16位整数，标识了一个进程。
<ul>
<li>临时端口：当可会淡发起连接请求时，内核自动分配的端口</li>
<li>知名端口：和服务器提供的服务有短的端口 (
<ul>
<li>Web服务器使用端口80</li>
<li>ssh服务器使用端口22</li>
<li>email服务器使用端口25</li>
</ul></li>
</ul></li>
</ul>

<p>一个连接是由它两端的套接字地址唯一确定的（套接字对, socket pair）。</p>

<p><img src="media/15320197756867/socket%20pair.png" alt="socket pai"/></p>

<p>使用端口来识别服务</p>

<p><img src="media/15320197756867/using%20ports%20to%20identify%20services.png" alt="using ports to identify services"/></p>

<h2 id="toc_8">4 套接字接口</h2>

<p>什么是套接字？</p>

<ul>
<li>对于内核来说，套接字是通信的端点。 To the kernel, a socket is an endpoint of communication</li>
<li>对于应用来说，套接字是让应用从网络读写的文件描述符。 To an application, a socket is a file descriptor that lets the application read/write from/to the network.</li>
</ul>

<p>客户端和服务器通过对套接字描述符读写进行通信：</p>

<p><img src="media/15320197756867/client%20and%20servers%20communicate%20%20via%20socket%20descriptors.png" alt="client and servers communicate  via socket descriptors"/></p>

<p>(1) 通用套接字地址(generic socket address)：</p>

<ul>
<li>以套接字地址作为<code>connect()</code>, <code>bind()</code>, <code>accept</code>的实参</li>
<li>仅仅因为那时的C不存在<code>void *</code>指针，所以套接字接口被设计成这样。</li>
</ul>

<pre><code class="language-c">struct sockaddr { 
    uint16_t sa_family; /* Protocol family */
    char sa_data[14]; }; /* Address data. */
</code></pre>

<p>(2) 因特网的套接字地址</p>

<ul>
<li>必须将<code>struct sockaddr_in *</code> 转换为 <code>struct sockaddr *</code>才能以套接字地址作为函数实参</li>
</ul>

<pre><code class="language-c">struct sockaddr_in {
    uint16_t sin_family;
    uint16_t sin_port;
    struct in_addr sin_addr;
    unsigned char sin_zero[8];
    };
</code></pre>

<p><img src="media/15320197756867/sockets%20interface.png" alt="sockets interface"/></p>

<ol>
<li>开启服务器(start server)
<ul>
<li><code>getaddrinfo</code>: 把主机名(hostname）、主机地址(host addresses)、端口(ports)和服务名(service names)转换为套接字地址结构。</li>
<li><code>socket</code>: 创建一个套接字描述符(socket descriptor)，也就是之后用来读写的 file descriptor</li>
<li><code>bind</code>: 请求内核把套接字地址和套接字描述符绑定</li>
<li><code>listen</code>: 将套接字描述符从一个主动套接字转换为监听套接字(listening socket)，该套接字可以接受来自客户端的连接请求</li>
<li><code>accept</code>: 等待来自客户端的连接请求</li>
</ul></li>
<li>开启客户端(start client)
<ul>
<li><code>getaddrinfo</code>, <code>socket</code>与开启服务器相同</li>
<li><code>connect</code>: 试图与服务器建立连接</li>
</ul></li>
</ol>

<h3 id="toc_9">4.1 Echo客户端和服务器示例</h3>

<p>在和服务器建立连接之后，客户端进入一个循环，反复从标准输入读取文本行，发送文本行给服务器，从服务器读取回送的行，并输出结果到接准输出。</p>

<pre><code class="language-c">#include &quot;csapp.h&quot;
int main (int argc, char **argv) {
    int clientfd;
    char *host, *port, buf[MAXLINE];
    rio_t rio;
    
    host = argv[1];
    port = argv[2];
    
    //和服务器建立连接
    clientfd = Open_clientfd(host, port);
    Rio_readinitb(&amp;rio, clientfd);
    
    while (Fgets(buf, MAXLINE, stdin) != NULL) {
        // 写入，也就是向服务器发送信息
        Rio_writen(clientfd, buf, strlen(buf));
        // 读取，也就是从服务器接收信息
        Rio_readlineb(&amp;rio, buf, MAXLINE);
        // 把从服务器接收的信息显示在输出中
        Fputs(buf, stdout);
    }
    Close(clientfd);
    exit(0);
}
</code></pre>

<p>服务器在打开监听描述符后，进入一个无限循环。每次循环都等待一个来自客户端的连接请求，输出已连接客户端的域名和IP地址，并调用echo函数为这些客户端服务。在echo程序返回后，主程序关闭已连接描述符。</p>

<pre><code class="language-c">#include &quot;csapp.h&quot;
void echo(int connfd);
int main(int argc, char **argv){
    int listenfd, connfd;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr; // Enough room for any addr
    char client_hostname[MAXLINE], client_port[MAXLINE];
    
    // 开启监听端口，注意只开这么一次
    listenfd = Open_listenfd(argv[1]);
    while (1) {
        // 需要具体的大小
        clientlen = sizeof(struct sockaddr_storage); // Important!
        // 等待连接
        connfd = Accept(listenfd, (SA *)&amp;clientaddr, &amp;clientlen);
        // 获取客户端相关信息
        Getnameinfo((SA *) &amp;clientaddr, clientlen, client_hostname,
                     MAXLINE, client_port, MAXLINE, 0);
        printf(&quot;Connected to (%s, %s)\n&quot;, client_hostname, client_port);
        // 服务器具体完成的工作
        echo(coonfd);
        Close(connfd);
    }
    exit(0);
}
void echo(int connfd) {
    size_t n;
    char buf[MAXLINE];
    rio_t rio;
    
    // 读取从客户端传输过来的数据
    Rio_readinitb(&amp;rio, connfd);
    while((n = Rio_readlineb(&amp;rio, buf, MAXLINE)) != 0) {
        printf(&quot;server received %d bytes\n&quot;, (int)n);
        // 把从 client 接收到的信息再写回去
        Rio_writen(connfd, buf, n);
    }
}
</code></pre>

<h2 id="toc_10">5 Web服务器</h2>

<h3 id="toc_11">5.1 Web基础</h3>

<p>Web客户端和服务器之间的交互用的是<strong>HTTP协议</strong>(超文本传输协议)，交互的基本过程为：</p>

<ul>
<li>客户端和服务器建立TCP连接</li>
<li>客户端请求内容</li>
<li>服务器响应请求的内容</li>
<li>服务器和客户端最终关闭 连接</li>
</ul>

<p><img src="media/15320197756867/web%20server%20basics.png" alt="web server basics"/></p>

<h3 id="toc_12">5.2 Web内容</h3>

<p>Web服务器返回内容给客户端，内容是与一个<strong>MIME</strong>类型相关的字节序列。(MIME -  Multipurpose Internet Mail Extensions)</p>

<p>HTTP响应返回的类型可以是静态的，也可以是动态的：</p>

<ul>
<li>静态内容：内容存储在文件中，响应HTTP请求后返回给客户端
<ul>
<li>例如HTML文件，图片，声音</li>
</ul></li>
<li>动态内容：运行一个可执行文件产生输出，返回给客户端</li>
</ul>

<h3 id="toc_13">5.3 HTTP事务</h3>

<p>一个HTTP请求(request)是一个请求行(request line)，后面跟随着零个或多个请求报头(request header)，再跟随一个终止报头的空行。</p>

<p>请求行的格式是<code>&lt;method&gt; &lt;uri&gt; &lt;version&gt;</code>。</p>

<ul>
<li><code>&lt;method&gt;</code>可以是GET, POST, OPTIONS, HEAD, PUT, DELETE, TRAXE</li>
<li><code>&lt;uri&gt;</code>是响应的URL的后缀，包括文件名和可选的参数</li>
<li><code>&lt;version&gt;</code>是该请求遵循的HTTP的版本(HTTP/1.0或者HTTP/1.1)</li>
</ul>

<p>请求报头的格式是<code>&lt;header name&gt;:&lt;header data&gt;</code></p>

<ul>
<li>为服务器提供额外信息，例如浏览器的商标名</li>
</ul>

<p>HTTP响应与HTTP请求类似，是一个响应行(response line),后面跟着零个或者多个响应报头(response header)，再跟随一个终止报头的空行，再跟随一个响应主体(response body)。</p>

<p>响应行的格式是<code>&lt;version&gt; &lt;status code&gt; &lt;status message&gt;</code></p>

<ul>
<li><code>&lt;version&gt;</code>是响应所遵循的HTTP版本</li>
<li><code>&lt;status-code&gt;</code>是一个3位的正整数，指明对请求的处理</li>
<li><code>&lt;status-message&gt;</code> 英文描述</li>
</ul>

<p>响应报头的格式是<code>&lt;header name&gt;:&lt;header data&gt;</code></p>

<p>下面是HTTP请求的一个实例<br/>
<img src="media/15320197756867/example%20HTTP%20transaction.png" alt="example HTTP transaction"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning with large datasets]]></title>
    <link href="http://larryim.cc/15323640524161.html"/>
    <updated>2018-07-24T00:40:52+08:00</updated>
    <id>http://larryim.cc/15323640524161.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1 overview</h2>

<p>Why use big data?</p>

<ul>
<li>Simple learning methods with large data sets can outperform complex learners with smaller datasets</li>
<li>The ordering of learning methods, best-to-worst, can be different for small datasets than from large datasets</li>
<li>The best way to improve performance for a learning system is often to collect more data</li>
<li>Large datasets often imply large classifiers</li>
</ul>

<p>Asymptotic analysis</p>

<ul>
<li>It measures number of operations as function of problem size</li>
<li>Different operations (eg disk seeking, scanning, memory access) can have very very different costs</li>
<li>Disk access is cheapest when you scan sequentially</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 3 - Processes]]></title>
    <link href="http://larryim.cc/os-concets-processes.html"/>
    <updated>2018-07-17T00:28:20+08:00</updated>
    <id>http://larryim.cc/os-concets-processes.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 Process concept</a>
<ul>
<li>
<a href="#toc_1">1.1 The process</a>
</li>
<li>
<a href="#toc_2">1.2 Process state 进程状态</a>
</li>
<li>
<a href="#toc_3">1.3 Process control block</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">2 Process scheduling 进程调度</a>
<ul>
<li>
<a href="#toc_5">2.1 Scheduling Queues</a>
</li>
<li>
<a href="#toc_6">2.2 context switch</a>
</li>
</ul>
</li>
<li>
<a href="#toc_7">3 Operating on Processes</a>
<ul>
<li>
<a href="#toc_8">3.1 Process creation</a>
</li>
<li>
<a href="#toc_9">3.2 Process termination</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">4 Interprocess communication</a>
</li>
<li>
<a href="#toc_11">5 IPC in shared-memory system</a>
</li>
<li>
<a href="#toc_12">6 IPC in message-passing system</a>
<ul>
<li>
<a href="#toc_13">6.1 Direct/Indirect communication</a>
<ul>
<li>
<a href="#toc_14">(1) Direct Communication</a>
</li>
<li>
<a href="#toc_15">(2) Indirect Communication</a>
</li>
</ul>
</li>
<li>
<a href="#toc_16">6.2 Synchronization</a>
</li>
<li>
<a href="#toc_17">6.3 Buffering</a>
</li>
</ul>
</li>
<li>
<a href="#toc_18">7 Examples of IPC</a>
<ul>
<li>
<a href="#toc_19">7.1 Mach Message Passing</a>
</li>
<li>
<a href="#toc_20">7.2 Pipes</a>
<ul>
<li>
<a href="#toc_21">(1) Ordinary pipes</a>
</li>
<li>
<a href="#toc_22">(2) Named pipes</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_23">8 Communication in Client-server system</a>
<ul>
<li>
<a href="#toc_24">8.1 Sockets</a>
</li>
<li>
<a href="#toc_25">8.2 Remote procedure calls</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">1 Process concept</h2>

<h3 id="toc_1">1.1 The process</h3>

<p><strong>Process</strong> (进程) is a program in execution.</p>

<ul>
<li>Process is the unit of work in a modern computing system</li>
</ul>

<p>The status of the <strong>current</strong> activity of a process is represented by the value of the <strong>program counter</strong> and the contents of the processor&#39;s <strong>registers</strong>.</p>

<p>A program by itself is not a process.</p>

<ul>
<li>A program is a <strong>passive</strong> entity, such as a file containing a list of instructions stored on disk</li>
<li>A process is an <strong>active</strong> entity, with a program counter specifying the next instruction to execute</li>
</ul>

<h3 id="toc_2">1.2 Process state 进程状态</h3>

<p>A process may be in one of the following states:</p>

<ul>
<li><strong>New</strong>(新建). The process is being created. 进程正在被创建</li>
<li><strong>Running</strong>(运行). Instructions are being executed.指令正在被执行</li>
<li><strong>Waiting</strong>(等待). The process is waiting for some event to occur(such as an I/O completion or reception of a signal). 进程等待某些事件发生</li>
<li><strong>Ready</strong>(就绪). The process is waiting to be assigned to a processor.进程等待分配处理器</li>
<li><strong>Terminated</strong>(终止). The process has finished execution.进程执行完毕</li>
</ul>

<p>Diagram of process state:<br/>
<img src="media/15317585001692/diagramofprocessstate.png" alt="Diagram of process state"/></p>

<h3 id="toc_3">1.3 Process control block</h3>

<p>Each process is represented by a <strong>process control block</strong>(PCB, 进程控制块), it contains</p>

<ul>
<li><strong>Process state</strong>(进程状态)</li>
<li><strong>Program counter</strong>(程序计数器)</li>
<li><strong>CPU registers</strong>(CPU寄存器)</li>
<li><strong>CPU-scheduling information</strong>(CPU调度信息): a process priority, pointers to scheduling queues, and any other scheduling parameters.</li>
<li><strong>Memory-management information</strong>(内存管理信息)</li>
<li><strong>Accounting information</strong>(记账信息): the amount of CPU and real time used, time limits, account numbers, process numbers and so on.</li>
<li><strong>I/O status information</strong>(I/O状态信息): the list of I/O devices allocated to the process, a list of open files</li>
</ul>

<p>Process Control Block:<br/>
<img src="media/15317585001692/processcontrolblock.png" alt="process control block"/></p>

<p>The process control block in Linux is represented by the C structure <code>task_struct</code> (&#39;include/linux/sched.h&#39;)， <a href="https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L592">CODE LINK</a></p>

<ul>
<li>Within the Linux kernel, all active processes are represented using a <strong>doubly linked list</strong> of task struct.</li>
</ul>

<p>Task_strut:<br/>
<img src="media/15317585001692/task_strcut%20in%20Linux.png" alt="task_strcut in Linux"/></p>

<h2 id="toc_4">2 Process scheduling 进程调度</h2>

<p>The <strong>process scheduler</strong>(进程调度程序) selects an available process for program execution on a core.</p>

<ul>
<li>Each CPU core can run one process at a time.</li>
<li>The number of processes currently in memory is known as the <strong>degree of multiprogramming</strong>.</li>
</ul>

<h3 id="toc_5">2.1 Scheduling Queues</h3>

<p><strong>Ready queue</strong>(就绪队列): the status of processes are ready.</p>

<ul>
<li>generally stored as a linked list, its header contains pointers to the first PCB in the list, each PCB includes a pointer field that points to next PCB in the ready queue.</li>
</ul>

<p><strong>Wait Queue</strong>(等待队列): the status of processes are waiting.</p>

<p>Queueing-diagram representation of process scheduling: <br/>
<img src="media/15317585001692/Queueing-diagram%20representation%20of%20process%20scheduling.png" alt="Queueing-diagram representation of process scheduling"/></p>

<h3 id="toc_6">2.2 context switch</h3>

<p>Here the <strong><em>context</em></strong> of a process is represented in the PCB of the process, including the value of the CPU registers, the process state, and memory-management information.</p>

<p>An operating system performs a <strong>context switch</strong>（上下文切换) when it switches from running one process to running another.</p>

<ul>
<li>The kernel <strong>saves</strong> the context of the old process into its PCB and <strong>restore</strong> the saved context of the new process scheduled to run.</li>
<li>Context-switch time is overhead; the system does no useful work while switching. 
<ul>
<li>A typical speed is a several microseconds. </li>
</ul></li>
<li>Context-switch times are <strong>highly</strong> dependent on hardware support.</li>
</ul>

<p>Context switch from an old process to a new process:<br/>
<img src="media/15317585001692/context%20switch%20from%20process%20to%20process.png" alt="context switch from process to process"/></p>

<h2 id="toc_7">3 Operating on Processes</h2>

<h3 id="toc_8">3.1 Process creation</h3>

<p>A process may <strong>create</strong> several new processes.</p>

<ul>
<li>the creating process is called a <strong>parent process</strong>.</li>
<li>the new process is called a <strong>child process</strong> .</li>
</ul>

<p><img src="media/15317585001692/process%20creating%20using%20the%20fork--%20system%20call.png" alt="process creating using the fork-- system cal"/></p>

<h3 id="toc_9">3.2 Process termination</h3>

<p>A process <strong>terminates</strong> when it finishes executing its final statement and asks the operating system to delete it by using the <code>exit()</code> system call.</p>

<ul>
<li><strong>cascading termination</strong>(级联终止):  if a process terminates (either normally or abnormally), then all its children must also be terminated. </li>
<li>A process that has terminated, but whose parent has not yet called <code>wait()</code>, is known as a <strong>zombie process</strong>(僵尸进程).</li>
<li>if a parent did not invoke <code>wait()</code> and instead terminated, then leaving its child processes as <strong>orphan processes</strong>(孤儿进程).
<ul>
<li>Unix system may assign the <code>init</code> process as the new parent to orphan processes, and the <code>init</code> process periodically invokes <code>wait()</code>.</li>
</ul></li>
</ul>

<h2 id="toc_10">4 Interprocess communication</h2>

<p>Processes may be either <strong>independent processes</strong>(独立进程) or <strong>cooperating processes</strong>(协同进程).</p>

<ul>
<li>A process is <strong><em>independent</em></strong> if it does not share data with any other processes executing in the system.</li>
<li>A process is <strong><em>cooperating</em></strong> if it can affect or be affected by the other processes executing in the system.</li>
</ul>

<p>Advantages of  process cooperation:</p>

<ul>
<li>Information sharing 信息共享</li>
<li>Computation speedup 加速运算</li>
<li>Modularity 模块化</li>
</ul>

<p>Cooperating process require an <strong>interprocess communication</strong> (IPC，进程间通信) mechanism that will allow them to <strong>exchange</strong> data. There are two fundamental models of IPC:</p>

<ul>
<li><strong>shared memory</strong>（共享内存）: a region of memory is shared by cooperating process. Process can exchange information by reading and writing data to the shared region.
<ul>
<li>Shared memory can be <strong>faster</strong> than message passing.</li>
</ul></li>
<li><strong>message passing</strong>(消息传递)： communication takes place by means of messages exchanged between the cooperating processes.
<ul>
<li>Message passing is useful for exchanging <strong>smaller</strong> amounts of data, because no conflicts need be avoided.</li>
<li>Message passing is easier to implement in a distributed system than shared memory.</li>
</ul></li>
</ul>

<p><img src="media/15317585001692/sharedmemory%20and%20message%20passing.png" alt="sharedmemory and message passing"/></p>

<h2 id="toc_11">5 IPC in shared-memory system</h2>

<p>Here, we explore the POSIX API for shared memory. POSIX shared memory is organized using <strong>memory-mapped files</strong> (内存映射文件), which associate the region of shared memory with a file. A process must first create a shared-memory object using the <code>shm_open()</code> system call, as follows:</p>

<pre><code class="language-c">fd = shm_open(name, O_CREAT | O_RDWR, 0666);
ftruncate(fd, 4096);
mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
</code></pre>

<ul>
<li>A successful call to <code>shm_open()</code> returns an integer file descriptor for the shared-memory object.</li>
<li>Once the object is established, the <code>ftruncate</code> function is used to configure the size of the object in bytes.</li>
<li>Finally, the <code>mmap()</code> function establishes a memory-mapped file containing the shared-memory object. It returns a pointer to the shared</li>
</ul>

<h2 id="toc_12">6 IPC in message-passing system</h2>

<p>A message-passing facility provides at least two operations:</p>

<ul>
<li>send(message)</li>
<li>receive(message)</li>
</ul>

<p>If P and Q wish to communicate, they need to</p>

<ul>
<li>establish a <strong>communication link</strong>(通信连接) between them</li>
<li>exchange messages via send/receive </li>
</ul>

<p>Here are several methods for logically implementing a <em>communication link</em> between processes:</p>

<ul>
<li>Direct or indirect communication 直接/间接通信</li>
<li>Synchronous or asynchronous communication 同步/异步同步</li>
<li>Automatic or explicit buffering 自动/显式缓冲</li>
</ul>

<h3 id="toc_13">6.1 Direct/Indirect communication</h3>

<h4 id="toc_14">(1) Direct Communication</h4>

<p>Under <strong>direct communication</strong>, each process that wants to communicate must explicitly name the recipient or sender of the communication.</p>

<ul>
<li>send(P, message) - send a message to process P.</li>
<li>receive(Q, message) - receive a message from process Q</li>
</ul>

<p>A communication link in this scheme has the following properties:</p>

<ul>
<li>A link is established <strong>automatically</strong> between every pair of processes that want to communicate.</li>
<li>A link is associated with <strong>exactly two</strong> processes.</li>
<li>Between each pair of processes, there exists exactly one link.</li>
</ul>

<p>Cons:</p>

<ul>
<li>limited modularity of the resulting process definitions. Changing the identifier of a process may necessinate examining all other process definitions.</li>
<li>any such hard-coding techniques, are less desirable.</li>
</ul>

<h4 id="toc_15">(2) Indirect Communication</h4>

<p>With <strong>indirect communication</strong>, the message are sent to and receive from <strong>mailboxes</strong>, or <strong>ports</strong>.</p>

<ul>
<li>send(A, message) - send a message to mailbox A</li>
<li>receive(A, message) - receive a message from mailbox A</li>
</ul>

<p>A mailbox can be viewed abstractly as an object into which messages can be placed by processes and from which messages can be removed.</p>

<ul>
<li>Each mailbox has an <strong>unique</strong> identification.</li>
<li>Two processes can communicate only if they have a shared mailbox.</li>
</ul>

<p>In this scheme, a communication link has the following properties:</p>

<ul>
<li>A link is established between a pair of processes only if both members of the pair have a shared mailbox.</li>
<li>A link may be associated with more than two processes.</li>
<li>Between each pair of communicating processes, a number of different links may exist, with each link corresponding to one mailbox.</li>
</ul>

<p>A mailbox may be owned either by a process or by the operating system.</p>

<p>If the mailbox is owned by a process</p>

<ul>
<li>We distinguish between the <strong>owner</strong> (which can only receive messages through his mailbox) and the <strong>user</strong> (which can only send messages to the mailbox)</li>
<li>Each mailbox has a unique owner.</li>
<li>When a process that owns a mailbox terminates, the mailbox disappears.</li>
<li>The process that creates a new mailbox is that mailbox&#39;s owner by default.</li>
</ul>

<h3 id="toc_16">6.2 Synchronization</h3>

<p>Message passing may be either <strong>blocking</strong> or <strong>nonblocking</strong> - also known as <strong>synchronous</strong> and <strong>asynchronous</strong>.</p>

<h3 id="toc_17">6.3 Buffering</h3>

<p>Messages exchanged by communicating processes reside in a temporary queue, whether communication is direct or indirect. Basically, it can be implemented in three ways:</p>

<ul>
<li>Zero capacity（零容量）-- no buffering
<ul>
<li>The link cannot have any messages waiting in it.</li>
<li>The sender must block until the recipient receives the message. </li>
</ul></li>
<li>Bounded capacity（有界容量）-- automatic buffering
<ul>
<li>The queue has finite length n, at most n message can reside in it.<br/></li>
<li>The sender must block until space is available in the queue if the link is full.<br/></li>
</ul></li>
<li>Unbounded capacity （无界容量） -- automatic buffering
<ul>
<li>Any number of messages can wait in it.</li>
<li>The sender never blocks. </li>
</ul></li>
</ul>

<h2 id="toc_18">7 Examples of IPC</h2>

<h3 id="toc_19">7.1 Mach Message Passing</h3>

<p>Mach was especially designed for distributed systems. Its kernel supports the creation and destruction of multiple <strong>tasks</strong>, which are similar to processes but have multiple threads of control and fewer associated resources.  </p>

<p>Messages are sent to, and received from, mailboxes, which are called <strong>ports</strong> in Mach. </p>

<ul>
<li>Ports are <strong>finite in size</strong> and <strong>unidirectional</strong>.</li>
<li>For two-way communication, a message is sent to one port, and a response is sent to a separate <strong>reply</strong> port.</li>
<li>Associated with each port is a collection of <strong>port rights</strong>, which  identify the capabilities necessary for a task to interact with the port.</li>
</ul>

<p>Functions:</p>

<ul>
<li><code>mach_port_allocate()</code> creates a new port and allocates space for its queue of messages.</li>
<li><code>mach_msg()</code> is the standard API for both sending and receiving messages.</li>
</ul>

<pre><code class="language-c">#include &lt;mach/mach.h&gt;

struct message {
    mach_msg_header_t header;
    int data;
};

mach_port_t client;
mach_port_t server;

/* Client Code */

struct message message;

// construct the header
message.header.msgh_size = sizeof(message);
message.header.msgh_remote_port = server;
message.header.msgh_local_port = client;

// send the message
mach msg(&amp;message.header, // message header
         MACH_SEND_MSG, // sending a message
         sizeof(message), // size of message sent
         0, // maximum size of received message - unnecessary
         MACH_PORT_NULL, // name of receive port - unnecessary
         MACH_MSG_TIMEOUT_NONE, // no time outs MACH PORT NULL // no notify port
);

/* Server Code */

struct message message;

// receive the message
mach_msg(&amp;message.header, // message header
  MACH_RCV_MSG, // sending a message  0, // size of message sent
  sizeof(message), // maximum size of received message
  server, // name of receive port
  MACH_MSG_TIMEOUT_NONE, // no time outs
  MACH_PORT_NULL // no notify port
);
</code></pre>

<h3 id="toc_20">7.2 Pipes</h3>

<p>A <strong>pipe</strong> acts as a conduit allowing two processes to communicate. Pipes were one of the first IPC mechanisms in early UNIX systems. There are two common types of pipes used on both UNIX and Windows systems: <strong>ordinary pipes</strong> and <strong>named pipes</strong>.</p>

<h4 id="toc_21">(1) Ordinary pipes</h4>

<p><strong>Ordinary pipes</strong> allow two processes to communicate in standard producer-consumer fashion: the producer writes to one end of the pipe (the <strong>write end</strong>) and the consumer reads from the other end (the <strong>read end</strong>).</p>

<ul>
<li>Ordinary pipes are <strong>unidirectional</strong>, allowing only one-way communication.</li>
<li>Function <code>pipe(int fd[])</code> constructs an ordinary pipe, where <code>fd</code> is a file descriptor.</li>
<li>UNIX treats a pipe as <em>a special type of file</em>. Pipes can be accessed using ordinary <code>read()</code> and <code>write()</code> system calls.</li>
<li>Ordinary pipes <strong>exit only</strong> while the processes are communicating with each other.</li>
</ul>

<p><img src="media/15317585001692/file%20descriptors%20for%20an%20ordinary%20pipes.png" alt="file descriptors for an ordinary pipes"/></p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;

#define BUFFER_SIZE 25
#define READ_END 0
#define WRITE_END 1

int main(void)
{
        char write_msg[BUFFER_SIZE] = &quot;Greetings&quot;;
        char read_msg[BUFFER_SIZE];
        int fd[2];
        pid_t pid;

        /* create the pipe */
        if (pipe(fd) == -1){
                fprintf(stderr, &quot;Pipe failed&quot;);
                return 1;
        }

        /* fork a child process */
        pid = fork();

        if (pid&gt;0){ /* parent process */
                close(fd[READ_END]);/* close the unused end of the pipe */
                write(fd[WRITE_END], write_msg, strlen(write_msg)+1); /* write to the pipe */
                close(fd[WRITE_END]);  /* close the write end of the pipe */
        }
        else if (pid==0){ /* child process */
                close(fd[WRITE_END]); /* close the unused end of the pipe */
                read(fd[READ_END], read_msg, BUFFER_SIZE); /* read from the pipe */
                printf(&quot;read: %s\n&quot;, read_msg);
                close(fd[READ_END]); /* close the read end of the pipe */
        }
        return 0;

}
</code></pre>

<h4 id="toc_22">(2) Named pipes</h4>

<p><strong>Named pipes</strong>（命名管道） can be <strong>bidirectional</strong>, and no parent-child relationship is required.</p>

<ul>
<li>Named pipes are referred to as <strong>FIFOs</strong> in UNIX system.</li>
<li>The communicating processes for named pipes must reside on the same machine.</li>
</ul>

<p>创建命名管道：</p>

<pre><code class="language-c">int mkfifo(const char *filename, mode_t mode);
</code></pre>

<h2 id="toc_23">8 Communication in Client-server system</h2>

<p>In this section, we explore two other strategies for communication in client-server system: <strong>sockets</strong> and <strong>remote procedure calls</strong>(RPCs)</p>

<h3 id="toc_24">8.1 Sockets</h3>

<p>A <strong>socket</strong>（套接字）is defined as an endpoint for communication. A socket is identified by an IP address concatenated with a port number.</p>

<p>Communication using sockets：<br/>
<img src="media/15317585001692/communication%20using%20sockets.png" alt="communication using sockets"/></p>

<p>Servers implementing specific services (such as SSH, FTP, and HTTP) listen to well-known ports. Once a request is received, the server accepts a connection from the client socket to complete the connection.</p>

<h3 id="toc_25">8.2 Remote procedure calls</h3>

<p><strong>Remote Procedure Call</strong>（远程过程调用）allows programs on different machines to interact using simple procedure call/return semantics, just as if the two programs were in the same computer。</p>

<p>RPC between a client and a serve：<br/>
<img src="media/15317585001692/RPC%20between%20a%20client%20and%20a%20server.png" alt="RPC between a client and a serve"/></p>

<p>RPC hides all the network code into the stub procedures. This prevents the application programs, the client and the server, from having to worry about details such as sockets, network byte order, and the like.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 4 - Threads & Concurrency]]></title>
    <link href="http://larryim.cc/os_concepts_threads_and_concurrency.html"/>
    <updated>2018-07-19T17:40:56+08:00</updated>
    <id>http://larryim.cc/os_concepts_threads_and_concurrency.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 Overview</a>
<ul>
<li>
<a href="#toc_1">1.1 Motivation</a>
</li>
<li>
<a href="#toc_2">1.2 Benefits</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">2 Multicore Programming</a>
<ul>
<li>
<a href="#toc_4">2.1 Programming Challenges</a>
</li>
<li>
<a href="#toc_5">2.2 Types of Parallelism</a>
</li>
</ul>
</li>
<li>
<a href="#toc_6">3 Multithreading Models</a>
<ul>
<li>
<a href="#toc_7">3.1 Many-to-One Model</a>
</li>
<li>
<a href="#toc_8">3.2 One-to-One Model</a>
</li>
<li>
<a href="#toc_9">3.3 Many-to-Many Model</a>
</li>
<li>
<a href="#toc_10">3.4 User/Kernel-Level threads</a>
</li>
</ul>
</li>
<li>
<a href="#toc_11">4 Thread Libraries</a>
</li>
<li>
<a href="#toc_12">5 Implicit threading</a>
<ul>
<li>
<a href="#toc_13">5.1 Thread Pools</a>
</li>
<li>
<a href="#toc_14">5.4 Grand Central Dispatch</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">6 Threading Issues</a>
<ul>
<li>
<a href="#toc_16">6.1 Light Weight Process</a>
</li>
<li>
<a href="#toc_17">6.2 Scheduler activation</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">1 Overview</h2>

<p>A <strong>thread</strong> is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack.</p>

<p>线程是一个CPU利用的基本单元，它由线程ID，程序计数器、寄存器集合和栈组成。</p>

<p>A traditional process has a single thread of control. If a process has <strong>multiple threads of control</strong>, it can perform more than one task at a time. <br/>
一个传统的进程只有单个控制线程，如果进程有多个控制线程，那么它能一次处理多个任务。</p>

<p>The figure below illustrates the difference between a traditional <strong>single-threaded</strong> process and a <strong>multithreaded</strong> process.</p>

<p><img src="media/15319932561412/single%20threaded%20and%20multithreaded%20processes.png" alt="single threaded and multithreaded processes"/></p>

<h3 id="toc_1">1.1 Motivation</h3>

<p>Process creation is <strong>time consuming</strong> and <strong>resource intensive</strong>. It is generally more efficient to use one process that contains multiple threads.</p>

<h3 id="toc_2">1.2 Benefits</h3>

<p>The benefits of  multithreaded programming can be broken down into four major categories:</p>

<ol>
<li><p><strong>Responsiveness</strong></p>
<ul>
<li>It allows a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user.</li>
<li>响应度高：即使程序部分阻塞或执行较冗长操作，该程序仍能继续执行，从而增加了对用户的相应程度。</li>
</ul></li>
<li><p><strong>Resource sharing</strong></p>
<ul>
<li>Processes can share resources only through techniques such as shared memory and message. Such techniques must be explicitly arranged by the programmer.</li>
<li>Threads share the memory and the resources of the process to which they belong by default.</li>
<li>资源共享：线程默认共享它们所属进程的内存和资源。代码和数据共享的优点是它允许一个应用程序在同一地址空间有多个不同的活动线程。</li>
</ul></li>
<li><p><strong>Economy</strong></p>
<ul>
<li>Allocating memory and resources for process creation is costly. Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads.</li>
<li>经济：进程创建所需要的内存和资源的分配比较昂贵。由于线程能共享它们所属进程的资源，所以创建和切换线程会更为经济。</li>
</ul></li>
<li><p><strong>Scalability</strong></p>
<ul>
<li>The benefits of multithreading can be even greater in a multiprocessor architecture, where threads may be running in parallel on different processing cores.</li>
<li>可扩展性: 多线程的优点之一是能充分使用多处理器体系结构。以便每个进程能并行运行在不同的处理器上。</li>
</ul></li>
</ol>

<h2 id="toc_3">2 Multicore Programming</h2>

<p>On a system with a <strong>single</strong> computing core, concurrency merely means that the execution of the threads will be <strong>interleaved</strong> over time, because the processing core is capable of executing only one thread at a time.</p>

<p>On a system with <strong>multiple</strong> cores, however, concurrency means that some threads can run in <strong>parallel</strong>, because the system can assign a separate thread to each core.</p>

<p><img src="media/15319932561412/concurrency%20of%20single%20and%20multiple%20core.png" alt="concurrency of single and multiple core"/></p>

<p>Note: <strong><em>Concurrency</em></strong> v.s. <strong><em>Parallelism</em></strong></p>

<ul>
<li>Concurrency: supports more than one task by allowing all the tasks to make progress.</li>
<li>Parallelism: perform more than one task simultaneously.</li>
</ul>

<h3 id="toc_4">2.1 Programming Challenges</h3>

<ol>
<li><strong>Identifying tasks</strong>. This involves examining applications to find areas that can be divided into separate, concurrent tasks.</li>
<li><strong>Balance</strong>. Programmer must ensure that the tasks perform equal work of equal value.</li>
<li><strong>Data splitting</strong>. The data accessed and manipulated by the tasks must be divided to run on separate cores.</li>
<li><strong>Data dependency</strong>. The data accessed by the tasks must be examined for dependencies between two or more tasks.</li>
<li><strong>Testing and debugging</strong>. Testing and debugging such concurrent programs is inherently more difficult than testing and debugging single-threaded applications.</li>
</ol>

<h3 id="toc_5">2.2 Types of Parallelism</h3>

<p>In general, there are two types of parallelism: data parallelism and task parallelism.</p>

<ul>
<li><strong>Data parallelism</strong> focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core. </li>
<li><strong>Task parallelism</strong> involves distributing not data but tasks (threads) across multiple computing cores.</li>
<li>However, data and task parallelism are not mutually exclusive, and an application may in fact use a hybrid of these two strategies.</li>
</ul>

<p>Data and task parallelism<br/>
<img src="media/15319932561412/data%20and%20task%20parallellism.png" alt="data and task parallelism"/></p>

<h2 id="toc_6">3 Multithreading Models</h2>

<p>Support for threads may be provided either at the user level, for <strong><em>user threads</em></strong>, or by the kernel, for <strong><em>kernel threads</em></strong>. </p>

<ul>
<li>User threads are supported above the kernel and are managed without kernel support.</li>
<li>Kernel threads are supported and managed directly by the operating system.</li>
</ul>

<p>有两种不同的方法来提供线程支持：用户层的用户级线程和内核层的内核级线程。用户级线程受内核支持，而无需内核管理；而内核级线程由操作系统直接支持和管理。事实上所有当代操作系统都支持内核级线程。</p>

<p>Ultimately, a relationship must exist between user threads and kernel threads. There are three common ways of establishing such a relationship: the many-to-one model, the one-to-one model, and the many-to-many model.<br/>
在用户级线程和内核级线程之间必然存在一种关系。有三种普遍建立这种关系的方法：多对一模型、一对一模型、多对多模型。</p>

<h3 id="toc_7">3.1 Many-to-One Model</h3>

<p>The <strong><u>many-to-one model</u></strong> maps many user-level threads to one kernel thread. 多对一模型将许多用户级线程映射到一个内核线程。</p>

<ul>
<li>Thread management is done by the thread library in user space, so it is efficient. 线程管理由线程库在用户空间进行的，因而效率比较高。</li>
<li>Also, because only one thread can access the kernel at a time, multiple threads are unable to run in parallel on multicore systems. 因为任意时刻只能有一个线程能够访问内核，多个线程不能并行运行在多处理器上。</li>
</ul>

<p><img src="media/15319932561412/many_to_one_model.png" alt="many_to_one_mode"/></p>

<h3 id="toc_8">3.2 One-to-One Model</h3>

<p>The <strong>one-to-one model</strong> maps each user thread to a kernel thread. 一对一模型每个用户线程映射到一个内核线程。</p>

<ul>
<li>It provides more concurrency by allowing another thread to run when a thread makes a blocking system call. 该模型在一个线程执行阻塞系统调用时，能允许另一个线程继续执行，提供了更高的并发性。</li>
<li>It also allows multiple threads to run in parallel on multiprocessors. 它也允许多个线程能并行运行在多处理器系统上。</li>
<li>The only drawback to this model is that creating a user thread requires creating the corresponding kernel thread, and a large number of kernel threads may burden the performance of a system. 这种模型的唯一缺点是每创建一个用户线程就会创建一个相应的内核线程, 大量内核线程会影响系统性能。</li>
</ul>

<p><img src="media/15319932561412/one_to_one_model.png" alt="one_to_one_mode"/></p>

<h3 id="toc_9">3.3 Many-to-Many Model</h3>

<p>The <strong>many-to-many model</strong> multiplexes many user-level threads to a smaller or equal number of kernel threads. 多对多模型多路复用了许多用户线程到同样数量或更小数量的内核线程上。</p>

<ul>
<li>Developers can create as many user threads as necessary. 开发人员可创建任意多的用户线程。</li>
<li>The corresponding kernel threads can run in parallel on a multiprocessor. 相应内核线程能在多处理器系统上并发执行。</li>
<li>Also, when a thread performs a blocking system call, the kernel can schedule another thread for execution. 而且当一个线程执行阻塞系统调用时，内核能调度另一个线程来执行。</li>
<li>In practice it is <strong>difficult to implement</strong>. 实际上难以实施。</li>
</ul>

<p><img src="media/15319932561412/many_to_many_model.png" alt="many_to_many_mode"/></p>

<p><u><strong><em>Most operating systems now use the one-to-one model.</em></strong></u></p>

<h3 id="toc_10">3.4 User/Kernel-Level threads</h3>

<p><a href="https://cs.nyu.edu/rgrimm/teaching/sp07-os/activations.pdf">ref: Scheduler Activations</a></p>

<p>(1) <strong>User-Level Threads</strong>(用户级线程)</p>

<p>Advantages</p>

<ul>
<li>Common operations can be implemented <strong>efficiently</strong> </li>
<li>Interface can be tailored to application needs</li>
</ul>

<p>Issues:</p>

<ul>
<li>A blocking system call blocks all user-level threads. 阻塞系统调用能够阻塞所有用户级线程。</li>
<li>Asynchronous system calls can provide partial work-around. 非同步系统调用能提供部分work-around. <a href="https://en.wikipedia.org/wiki/Workaround">view the definition of work-around here</a></li>
<li>A page fault blocks all user-level threads. 缺页异常阻塞所有用户级线程。</li>
<li>Matching threads to CPUs in a multiprocessor is hard：
<ul>
<li>No knowledge about the numbers of CPUs available to address space </li>
<li>No knowledge when a thread blocks</li>
</ul></li>
</ul>

<p>(2) <strong>Kernel-Level Threads</strong> (内核级线程)</p>

<p>Primary advantage</p>

<ul>
<li>Blocking system calls and page faults handled correctly</li>
</ul>

<p>Issues</p>

<ul>
<li>Cost of performing thread operations</li>
<li>Create, exit, lock, signal, wait all require user/kernel crossings</li>
</ul>

<p><strong>NOTE</strong>: The term <strong><u>virtual processor</u></strong> is often used instead of kernel thread.</p>

<h2 id="toc_11">4 Thread Libraries</h2>

<p>A thread library provides the programmer with an API for creating and managing threads. 线程库为程序员提供了创建和管理线程的API。</p>

<p><strong>Pthreads</strong>, the threads extension of the POSIX standard, may be provided as either a user-level or a kernel-level library. Pthread作为POSIX标准扩展，可以提供用户级或内核级的库。</p>

<ul>
<li><code>pthread_t tid</code>: declares the identifier for the thread</li>
<li><code>pthread attr_t attr</code>: declares the attributes for the thread</li>
<li><code>pthread_attr_init(&amp;attr)</code>: initialize thread attributes object</li>
<li><code>pthread_create()</code>: create a new thread</li>
<li><code>pthread_join()</code>:  join with a terminated thread<br/></li>
<li><code>pthread_exit()</code>:  terminate calling thread<br/></li>
</ul>

<p>Note: Compile and link with <code>-pthread</code>.</p>

<p><code>pthread</code>详细用法和实例, 见<a href="https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html">POSIX thread (pthread) libraries</a></p>

<h2 id="toc_12">5 Implicit threading</h2>

<p><strong>Implicit threading</strong>(隐式线程): Transfers the creation and management of threading from application developers to compilers and run-time libraries.</p>

<ul>
<li>One way to address difficulties and better support the design of concurrent and parallel applications</li>
<li>The advantage of this approach is that developers <strong><em><u>only need to identify parallel tasks</u></em></strong>, and the libraries determine the specific details of thread creation and management.</li>
</ul>

<p>In this section, we explore four alternative approaches to designing applications that can take advantage of multicore processors through implicit threading:</p>

<ul>
<li>Thread Pools</li>
<li>Fork Join</li>
<li>OpemMP</li>
<li>Grand Central Dispatch</li>
</ul>

<h3 id="toc_13">5.1 Thread Pools</h3>

<p>Two main issues exist:</p>

<ul>
<li>The thread will be <strong>discarded</strong> once it has completed its work. 线程在完成工作之后就要被丢弃</li>
<li><strong>Unlimited</strong> threads could exhaust system resources. 无限制的线程会耗尽系统资源</li>
</ul>

<p>Solution -&gt; <strong>thread pool</strong>(线程池)</p>

<ul>
<li>It creates a number of threads at start-up, and places them into a pool, where they sit and wait for work.</li>
<li>When a server receives a request, it submits the request to the thread pool and resumes waiting for additional requests.</li>
<li>If there is an available thread in the pool, it is awakened, and the request is serviced immediately. </li>
<li>If the pool contains no available thread, the task is queued until one becomes free. </li>
</ul>

<p>线程池的思想是在进程开始时创建一定数量的线程，并放入到池中以等待工作。当服务器收到请求时，它会唤醒线程池中的一个线程，并将要处理的请求传递给它，一旦线程完成了服务，它会返回到池中在等待工作。如果池中没有可用的线程，那么服务器会一直等待直到有空线程为止。</p>

<p>Thread pools offer these benefits:</p>

<ol>
<li>Servicing a request with an existing thread is often <strong>faster</strong> than waiting to create a thread. 通常用现有线程处理请求要比等待创建新的线程要快.</li>
<li>A thread pool <strong>limits</strong> the number of threads that exist at any one point.  线程池限制了在任何时候可用线程的数量.</li>
<li>Separating the task to be performed from the mechanics of creating the task allows us to use different strategies for running the task.</li>
</ol>

<p>Java线程库的一个例子：</p>

<pre><code class="language-java">import java.util.concurrent.*; 
public class ThreadPoolExample 
{ 
    public static void main(String[] args) {
        int numTasks = Integer.parseInt(args[0].trim()); 
        
        /* Create the thread pool */ 
        ExecutorService pool = Executors.newCachedThreadPool(); 
        /* Run each task using a thread in the pool */ 
        for (int i = 0; i &lt; numTasks; i++) 
            pool.execute(new Task()); 
        
         /* Shut down the pool once all threads have completed */            
        pool.shutdown();
}
</code></pre>

<h3 id="toc_14">5.4 Grand Central Dispatch</h3>

<p><strong>Grand Central Dispatch</strong> (GCD) is a technology for Apple&#39;s Mac OS X and iOS operating systems. It is a combination of extensions to the C languages, an API, and a run-time library that allows application developers identify sections of code to run in parallel.</p>

<ul>
<li>GCD identifies two types of dispatch queues: serial and concurrent.</li>
</ul>

<h2 id="toc_15">6 Threading Issues</h2>

<h3 id="toc_16">6.1 Light Weight Process</h3>

<p>Many systems implementing either the many-to-many or the two-level model place an <em>intermediate</em> data structure between the user and kernel threads. This data structure—typically known as a <strong><u><em>lightweight process</em></u></strong>（轻量级进程）, or <strong>LWP</strong>.</p>

<ul>
<li>To the user-thread library, the LWP appears to be a <strong>virtual</strong> processor on which the application can schedule a user thread to run.</li>
<li>Each LWP is attached to a kernel thread.</li>
<li>If a kernel thread blocks, the LWP blocks as well. Up the chain, the user-level thread attached to the LWP also blocks.</li>
</ul>

<p><img src="media/15319932561412/light-weight%20process.png" alt="light-weight process"/></p>

<p><img src="media/15319932561412/15320591793590.jpg" alt=""/></p>

<p>where K denotes kernel threads and  P denotes Process.</p>

<p>下面是一个测试LINUX中LWP的C程序</p>

<pre><code class="language-c">/* filename: test_LWP.c */
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int* thread(void* arg)
{
    pthread_t tid; // the ID of a thread
    tid = pthread_self();//get the current thread&#39;s id
 
    printf(&quot;The ID of new thread is =%lu\n&quot;, tid);
    sleep(500); //sleep for 500 seconds
    return NULL; 
}
  
int main()
{
    pthread_t tid;
    printf(&quot;The ID of main thread is %lu\n&quot;, pthread_self()); //get the main thread&#39;s id
  if (pthread_create(&amp;tid, NULL, (void *) thread, NULL) !=0) 
    {
       printf(&quot;Thread creation failed\n&quot;);
        exit(1);
    }
      
    printf(&quot;my Id is %lu, new thread ID is %lu\n&quot;, pthread_self(), tid);
    sleep(1000);
    return 0;
}
</code></pre>

<p>运行<code>ps -efL</code> 可以看到, <code>test_LWP</code>进程(PID=1953)有两个LWP，即NLWP(number of light weight process)=2。</p>

<pre><code class="language-text">UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD
vagrant   1953  1644  1953  0    2 04:16 pts/0    00:00:00 ./test_LWP
vagrant   1953  1644  1954  0    2 04:16 pts/0    00:00:00 ./test_LWP
vagrant   2028  1839  2028  0    1 04:18 pts/1    00:00:00 ps -efL
</code></pre>

<h3 id="toc_17">6.2 Scheduler activation</h3>

<p><strong>Problems</strong>:<br/>
内核线程在各方面都比较灵活，但是性能不高，经常会出现请求在用户空间和内核空间的传递。那么如何在拥有内核空间线程的灵活性的同时又提高性能呢?</p>

<p><strong>Solution</strong>:</p>

<p><strong>Scheduler activation</strong>（调度器激活）are a threading mechanism that, when implemented in an operating system&#39;s process scheduler, provide <em><u>kernel-level</u></em> thread functionality with <u><em>user-level</em></u> thread flexibility and performance [<a href="https://en.wikipedia.org/wiki/Scheduler_activations">ref</a>]. </p>

<p>It works as follows: </p>

<ul>
<li>The kernel provides an application with a set of virtual processors (LWPs), and the application can <strong>schedule</strong> user threads onto an available virtual processor. </li>
<li>Furthermore, the kernel must inform an application about certain events. This procedure is known as an <strong>upcall</strong>(向上调用). </li>
<li>Upcalls are handled by the thread library with an upcall handler, and upcall handlers must run on a virtual processor.</li>
<li>While the user threading library will schedule user threads, the kernel will schedule the underlying LWPs.</li>
</ul>

<p><strong>Example</strong> [<a href="http://www.it.uu.se/education/course/homepage/os/vt18/module-4/implementing-threads/">ref</a>]: </p>

<p>Let’s study an example of how scheduler activations can be used. The kernel has allocated one kernel thread (1) to a process with three user-level threads (2). The three user level threads take turn executing on the single kernel-level thread.</p>

<p><img src="media/15319932561412/scheduler-activations-1-2.png" alt="scheduler-activations-1-2"/></p>

<ul>
<li>(3) The executing thread makes a <strong>blocking system call</strong>.</li>
<li>(4) And the the kernel blocks the calling user-level thread and the kernel-level thread used to execute the user-level thread .</li>
<li>(5) Scheduler activation: the kernel decides to allocate a new kernel-level thread to the process . </li>
<li>(6) Upcall: the kernel notifies the user-level thread manager which user-level thread that is now blocked and that a new kernel-level thread is available. </li>
<li>(7) The user-level thread manager move the other threads to the new kernel thread and resumes one of the ready threads.</li>
</ul>

<p><img src="media/15319932561412/scheduler-activations-3-7.png" alt="scheduler-activations-3-7"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[NOTE] C++ By Dissection]]></title>
    <link href="http://larryim.cc/cpp_by_diessection.html"/>
    <updated>2018-07-21T12:02:43+08:00</updated>
    <id>http://larryim.cc/cpp_by_diessection.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Chapter 1 Writing an ANSI C++ Program</h2>

<h2 id="toc_1">Chapter 2 Native Types and Statements</h2>

<h2 id="toc_2">Chapter 3 Functions, Pointers, and Arrays</h2>

<h2 id="toc_3">Chapter 4 Classes and Abstract Data Types</h2>

<h2 id="toc_4">Chapter 5 Ctors, Dtors, Converisons, and Operator Overloading</h2>

<p><strong>Polymorphism</strong> means giving different meanings to the same function name or operator, dependent on context. Overloading of functions gives the same function name different meanings. The name has several interpretations that depend on function selection. This is called ad hoc polymorphism.</p>

<ul>
<li>ad hoc polymorphism: function overloading, operator overloading
<ul>
<li> functions can be applied to arguments of different types</li>
</ul></li>
<li>parametric polymorphism: using templates
<ul>
<li>allows the same code to be used with respect to various types, in which the type is a parameter of the code body.</li>
</ul></li>
<li>pure polymorphism: using virtual functions</li>
</ul>

<p>Chapter 11</p>

<p>OOP Language Characteristics</p>

<ul>
<li>Encapsulation with data hiding: the ability to distinguish an object&#39;s internal state and behavior from its external state and behavior.</li>
<li>Type extensibility: the ability to add user-defined types to augment the native types</li>
<li>Inheritance: the ability to create new types by importing or reusing the description of existing types</li>
<li>Polymorphism with dynamic binding: the ability of objects to be responsible for interpreting function invocation</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop和MapReduce入门]]></title>
    <link href="http://larryim.cc/hadoop_mapreduce.html"/>
    <updated>2018-07-15T00:06:54+08:00</updated>
    <id>http://larryim.cc/hadoop_mapreduce.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Part I Big Data</a>
<ul>
<li>
<a href="#toc_1">2 data source</a>
</li>
<li>
<a href="#toc_2">3. big data</a>
</li>
<li>
<a href="#toc_3">4. big data solution</a>
</li>
<li>
<a href="#toc_4">5. Definition of Big Data</a>
</li>
<li>
<a href="#toc_5">6 challenges</a>
</li>
<li>
<a href="#toc_6">8 the 3vs</a>
</li>
<li>
<a href="#toc_7">9 data worth storing?</a>
</li>
<li>
<a href="#toc_8">11 variety</a>
</li>
<li>
<a href="#toc_9">15 velocity</a>
</li>
<li>
<a href="#toc_10">16 Doug intro</a>
</li>
<li>
<a href="#toc_11">17. core hadoop</a>
</li>
<li>
<a href="#toc_12">18. hadoop ecosystem</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">Part 2 HDFS and MapReduce</a>
</li>
<li>
<a href="#toc_14">Part 3 MapReduce Code</a>
</li>
<li>
<a href="#toc_15">Part 4 MapReduce Design Patterns</a>
</li>
</ul>


<p>来自<a href="https://cn.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617">Udacity</a>课程Introduction to Hadoop and Mapreduce的笔记</p>

<h2 id="toc_0">Part I Big Data</h2>

<h3 id="toc_1">2 data source</h3>

<p>data increases</p>

<ul>
<li>phone data</li>
<li>online store</li>
</ul>

<p>how to store and process large amounts of data?</p>

<h3 id="toc_2">3. big data</h3>

<p>what is big data?</p>

<ul>
<li>order details for a store</li>
<li>all orders across 100s of stores</li>
<li>a person&#39;s stock portfoio</li>
<li>all stock transaction for the new york</li>
</ul>

<h3 id="toc_3">4. big data solution</h3>

<p>big data:</p>

<ul>
<li>all orders across 100s of stores</li>
<li>all stock transaction for the new york</li>
</ul>

<h3 id="toc_4">5. Definition of Big Data</h3>

<p>big data is data that is too big to process on a single machine</p>

<h3 id="toc_5">6 challenges</h3>

<ul>
<li>most data is worthless. false</li>
<li>data is created fast. true</li>
<li>data from different sources in various formats. true</li>
</ul>

<h3 id="toc_6">8 the 3vs</h3>

<ul>
<li>volumes: size of data 
<ul>
<li>reliable storage: find a cheaper way </li>
</ul></li>
<li>variety: data coming from  different source and format</li>
<li>velocity: speed of data generation</li>
</ul>

<h3 id="toc_7">9 data worth storing?</h3>

<ul>
<li>transactions</li>
<li>logs</li>
<li>business</li>
<li>user</li>
<li>sensor</li>
<li>medical</li>
<li>social</li>
</ul>

<p>all </p>

<h3 id="toc_8">11 variety</h3>

<p>data variety. for a long time, people use sql, mysql, oracle to store their data. the problem is that data needs to be fit in pre-defined tables. and a lot of data we deal these days tend to be unstructured or semi-structured data</p>

<h3 id="toc_9">15 velocity</h3>

<p>TB/day</p>

<h3 id="toc_10">16 Doug intro</h3>

<p>hadoop 之父 doug cutting</p>

<p>Here are the papers Google published about their <a href="http://static.googleusercontent.com/media/research.google.com/en/us/archive/gfs-sosp2003.pdf">distributed file system (GFS)</a> and their processing framework, <a href="http://static.googleusercontent.com/media/research.google.com/en/us/archive/mapreduce-osdi04.pdf">MapReduce</a><br/>
.</p>

<h3 id="toc_11">17. core hadoop</h3>

<p>store in hdfs, process with mapreduce</p>

<h3 id="toc_12">18. hadoop ecosystem</h3>

<p><img src="media/15315844145426/hadoop_ecosystem.png" alt="hadoop_ecosystem"/></p>

<h2 id="toc_13">Part 2 HDFS and MapReduce</h2>

<h2 id="toc_14">Part 3 MapReduce Code</h2>

<h2 id="toc_15">Part 4 MapReduce Design Patterns</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 链接]]></title>
    <link href="http://larryim.cc/Linking.html"/>
    <updated>2018-01-06T05:42:41+08:00</updated>
    <id>http://larryim.cc/Linking.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 编译器驱动程序</a>
</li>
<li>
<a href="#toc_1">2 静态链接</a>
</li>
<li>
<a href="#toc_2">3 目标文件</a>
</li>
<li>
<a href="#toc_3">4 可重定位目标文件</a>
</li>
<li>
<a href="#toc_4">5 符号和符号表</a>
</li>
<li>
<a href="#toc_5">6 符号解析</a>
</li>
<li>
<a href="#toc_6">7 重定位</a>
</li>
<li>
<a href="#toc_7">8 可执行目标文件</a>
</li>
<li>
<a href="#toc_8">9 加载可执行目标文件</a>
</li>
<li>
<a href="#toc_9">10 动态链接共享库</a>
</li>
<li>
<a href="#toc_10">14 处理目标文件的工具</a>
</li>
</ul>


<p><strong>链接</strong>(Linking)是将各种<strong>代码</strong>和<strong>数据片段</strong>收集并组合成为一个单一文件的过程。链接可以在编译、加载、运行时执行。在现代系统中，链接由<strong>链接器</strong>(Linker)自动执行。</p>

<p>链接器使得<strong>分离编译</strong>(separate compilation)成为可能：</p>

<ul>
<li>可以将源文件分解为更小、更好管理的模块，可以独立地修改和编译这些模块</li>
<li>修改一个模块后，只需重新编译它，并重新链接，不必编译其他文件</li>
</ul>

<h2 id="toc_0">1 编译器驱动程序</h2>

<p><strong>编译器驱动程序</strong>(<code>compiler driver</code>)，代表用户在需要时调用预处理器(cpp)、编译器(ccl)、汇编器(as)和链接器(ld)。典型的编译器驱动程序，包括GNU GCC, Clang。</p>

<p>例如，一个简单打印hello的<code>hello.c</code>程序，经过下面四个阶段，生成可执行目标文件：</p>

<pre><code class="language-c">//file: hello.c
#include &lt;stdio.h&gt;

int main()
{
    int i;
    printf(&quot;Hello World&quot;);
}
</code></pre>

<pre><code class="language-bash">linux &gt; gcc -o hello hello.c
</code></pre>

<p><img src="media/15151885614329/compiler_system.jpeg" alt="compiler_syste"/></p>

<h2 id="toc_1">2 静态链接</h2>

<p>静态链接器有两个主要任务：</p>

<ul>
<li><strong>符号解析</strong>(symbol resolution): 将每个符号 <u>引用</u> 正好和一个符号 <u>定义</u> 关联起来。</li>
<li><strong>重定位</strong>(relocation): 把每个符号定义与一个内存位置关联起来，并修改所有对这些符号的引用，使得它们指向这个内存位置。</li>
</ul>

<h2 id="toc_2">3 目标文件</h2>

<p>目标文件有三种格式：<strong>可重定位目标文件</strong>(<code>.o</code>)，<strong>可执行目标文件</strong>(<code>.out</code>)，<strong>共享目标文件</strong>(<code>.so</code>)</p>

<ul>
<li><strong>可重定位目标文件</strong>(.o文件)。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。</li>
<li><strong>可执行目标文件</strong>(a.out文件)。包含二进制代码和数据，其形式可以被直接复制到内存并执行。</li>
<li><strong>共享目标文件</strong>(.so文件)。在加载或者运行时被动态地加载进内存并链接</li>
</ul>

<p>各个系统的目标文件格式不同，Windows使用<strong>可移植可执行</strong>(Portable Executable, <code>PE</code>)格式。现代x86-64系统使用<strong>可执行可链接格式</strong>(Executable and Linkable Format, <code>ELF</code>)。</p>

<h2 id="toc_3">4 可重定位目标文件</h2>

<p>以可执行可链接(ELF)格式为例，一个典型的可重定位目标文件包括以下几个节：</p>

<ul>
<li>ELF头和节头部表</li>
<li><code>.text</code> 已编译程序的机器代码</li>
<li><code>.rodata</code> 只读数据</li>
<li><code>.data</code>  已初始化的全局和静态C变量</li>
<li><code>.bss</code>  未初始化的全局和静态C变量</li>
<li><code>.symtab</code> 一个符号表</li>
<li><code>.rel.text</code> 一个.text节中位置的列表</li>
<li><code>.rel.data</code> 重定位信息</li>
<li><code>.debug</code> 调试符号表</li>
<li><code>.line</code>  原始程序行号和机器指令之间的映射</li>
<li><code>.strtab</code>  字符串表</li>
</ul>

<p><img src="media/15151885614329/elf.png" alt="elf"/></p>

<p>利用<code>READELF</code>程序可以显示程序<code>hello.c</code>生成的可执行可链接文件的信息：</p>

<pre><code class="language-bash">gcc hello.c -c
readelf -a hello.o ## UNIX/LINUX
greadelf -a hello.o ## MAC, after brew install binutils
</code></pre>

<pre><code class="language-text">ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2&#39;s complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          304 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           64 (bytes)
  Number of section headers:         13
  Section header string table index: 10

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       0000000000000015  0000000000000000  AX       0     0     1
  [ 2] .rela.text        RELA             0000000000000000  00000590
       0000000000000030  0000000000000018          11     1     8
  [ 3] .data             PROGBITS         0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .bss              NOBITS           0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 5] .rodata           PROGBITS         0000000000000000  00000055
       000000000000000c  0000000000000000   A       0     0     1
  [ 6] .comment          PROGBITS         0000000000000000  00000061
       000000000000002c  0000000000000001  MS       0     0     1
  [ 7] .note.GNU-stack   PROGBITS         0000000000000000  0000008d
       0000000000000000  0000000000000000           0     0     1
  [ 8] .eh_frame         PROGBITS         0000000000000000  00000090
       0000000000000038  0000000000000000   A       0     0     8
  [ 9] .rela.eh_frame    RELA             0000000000000000  000005c0
       0000000000000018  0000000000000018          11     8     8
  [10] .shstrtab         STRTAB           0000000000000000  000000c8
       0000000000000061  0000000000000000           0     0     1
  [11] .symtab           SYMTAB           0000000000000000  00000470
       0000000000000108  0000000000000018          12     9     8
  [12] .strtab           STRTAB           0000000000000000  00000578
       0000000000000015  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), l (large)
  I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)

There are no section groups in this file.

There are no program headers in this file.

Relocation section &#39;.rela.text&#39; at offset 0x590 contains 2 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000005  00050000000a R_X86_64_32       0000000000000000 .rodata + 0
00000000000f  000a00000002 R_X86_64_PC32     0000000000000000 printf - 4

Relocation section &#39;.rela.eh_frame&#39; at offset 0x5c0 contains 1 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000200000002 R_X86_64_PC32     0000000000000000 .text + 0

The decoding of unwind sections for machine type Advanced Micro Devices X86-64 is not currently supported.

Symbol table &#39;.symtab&#39; contains 11 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS hello.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    3
     4: 0000000000000000     0 SECTION LOCAL  DEFAULT    4
     5: 0000000000000000     0 SECTION LOCAL  DEFAULT    5
     6: 0000000000000000     0 SECTION LOCAL  DEFAULT    7
     7: 0000000000000000     0 SECTION LOCAL  DEFAULT    8
     8: 0000000000000000     0 SECTION LOCAL  DEFAULT    6
     9: 0000000000000000    21 FUNC    GLOBAL DEFAULT    1 main
    10: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND printf

No version information found in this file.
</code></pre>

<h2 id="toc_4">5 符号和符号表</h2>

<p><code>.symtab</code>中的<strong>符号表</strong>，有三种不同的符号(不包括本地非静态变量)：</p>

<ul>
<li>由模块\(m\)定义并能被其他模块引用的<strong>全局符号</strong>。
<ul>
<li>非静态C函数和全局变量</li>
</ul></li>
<li>由其他模块定义并被模块\(m\)引用的全局符号。
<ul>
<li>对应于其他模块中定义的非静态C函数和全局变量</li>
</ul></li>
<li>只被模块\(m\)定义和引用的局部符号。
<ul>
<li>静态C函数和全局变量 </li>
</ul></li>
</ul>

<h2 id="toc_5">6 符号解析</h2>

<p><strong>符号解析</strong>是将每个<strong>符号引用</strong>和可重定位目标文件中的<strong>符号定义</strong>关联起来。链接器的输入是一组可重定位目标文件(模块)，有些是局部的( <u>局部符号</u> ，只对定义该符号的模块可见)，有些是全局的( <u>全局符号</u> ，对其他模块可见)。</p>

<ul>
<li><strong>局部符号</strong>：每个模块中每个局部符号有一个定义</li>
<li><p><strong>全局符号</strong>：可重定位目标文件的符号表里的全局符号是区分<strong>强</strong>和<strong>弱</strong>的，链接器根据以下规则来处理多重定义的符号名：</p>
<ul>
<li>规则1: 不允许有多个同名的强符号</li>
<li>规则2: 如果有一个强符号和多个弱符号同名，那么选择强符号</li>
<li>规则3：如果有多个弱符号同名，那么任选一个 </li>
</ul></li>
</ul>

<h2 id="toc_6">7 重定位</h2>

<p>重定位合并输入模块，并为每个符号分配运行时地址：</p>

<ul>
<li>重定位节和符号定义：将所有相同类型的节合并为同一类型的新的聚合节，并将运行时内存地址赋给新的聚合节和每个符号定义。
<ul>
<li>例如，来自所有输入模块的<code>.data</code>节被全部合并成输出的可执行目标文件的<code>.data</code>节<br/></li>
</ul></li>
<li>重定位节中的符号引用：将运行时地址付给每个符号引用</li>
</ul>

<h2 id="toc_7">8 可执行目标文件</h2>

<p>下图概括了一个典型的ELF可执行文件的给类信息。</p>

<p><img src="media/15151885614329/%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6.png" alt="可执行目标文件"/></p>

<h2 id="toc_8">9 加载可执行目标文件</h2>

<p>当在shell中执行目标文件时，首先通过调用<strong>加载器</strong>(<code>loader</code>)的操作系统代码来运行它，加载器将可执行目标文件的代码和数据复制到主存，跳转到程序的第一条指令(入口点，<code>_start_</code>函数的地址)运行该程序。</p>

<p>在Unix系统中，加载器是系统调用(system call)<code>execve()</code>的回调(call back)，其任务包括：</p>

<ul>
<li>确认(权限，内存要求等)</li>
<li>复制程序到主存</li>
<li>复制命令行参数到栈</li>
<li>初始化寄存器(例如栈针)</li>
<li>跳到入口点(<code>_start_</code>)</li>
</ul>

<h2 id="toc_9">10 动态链接共享库</h2>

<p>静态库有2大缺陷：</p>

<ul>
<li>静态库更新时，需要显示地将程序与更新了的库重新链接</li>
<li>浪费内存资源：几乎每个C程序都使用标准I/O函数，这些函数代码会被复制到每个运行进程的文本段中</li>
</ul>

<p>共享库(shared library)是致力于解决静态库缺陷的产物。</p>

<p><strong>动态链接</strong>(dynamic linking)：共享库在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。</p>

<ul>
<li>由动态链接器(dynamic linke)执行；</li>
<li>在linux系统中常用<code>.so</code>后缀表示。</li>
</ul>

<p><img src="media/15151885614329/dynamic_linking.png" alt="dynamic_linking"/></p>

<h2 id="toc_10">14 处理目标文件的工具</h2>

<p>Unix系统提供了一系列命令帮助理解和处理目标文件。这些工具包括：</p>

<ul>
<li><code>ar</code> ：创建静态库，插入、删除、列出和提取成员；</li>
<li><code>STRINGS</code> ：列出目标文件中所有可以打印的字符串；</li>
<li><code>STRIP</code> ：从目标文件中删除符号表信息；</li>
<li><code>NM</code> ：列出目标文件符号表中定义的符号；</li>
<li><code>SIZE</code> ：列出目标文件中节的名字和大小；</li>
<li><code>READELF</code> ：显示一个目标文件的完整结构，包括ELF 头中编码的所有信息。</li>
<li><code>OBJDUMP</code> ：显示目标文件的所有信息，最有用的功能是反汇编.text节中的二进制指令。</li>
<li><code>LDD</code> ：列出可执行文件在运行时需要的共享库。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 1 - Introduction]]></title>
    <link href="http://larryim.cc/os-concepts-introduction.html"/>
    <updated>2018-07-16T18:07:17+08:00</updated>
    <id>http://larryim.cc/os-concepts-introduction.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">what operating system do</a>
</li>
<li>
<a href="#toc_1">Computer-system organisation</a>
</li>
<li>
<a href="#toc_2">Interrupt</a>
<ul>
<li>
<a href="#toc_3">interrupt, exception, trap</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">multiprogramming and multitasking</a>
</li>
<li>
<a href="#toc_5">dual-mode</a>
</li>
<li>
<a href="#toc_6">timer</a>
</li>
<li>
<a href="#toc_7">virtualization</a>
</li>
<li>
<a href="#toc_8">Free and Open-Source OS</a>
</li>
</ul>


<h2 id="toc_0">what operating system do</h2>

<p>There is no completely adequate definition of operating system. A simple viewpoint is that it includes everything a vendor ships. A more common definition is that the <u>operating system is the one program running at all times on computer - usually  called <strong>kernel</strong></u> . </p>

<p>Three main <strong>purposes</strong> of an operating system are,</p>

<ul>
<li>manages a computer&#39;s hardware</li>
<li>provides a basis for application programs</li>
<li>acts as an intermediary between the user and hardware</li>
</ul>

<p>The operating system includes the always running <strong>kernel</strong>, <strong>middleware</strong> frameworks that ease application development and provide features, and <strong>system programs</strong> that aid in managing the system while it is running.</p>

<p>Anything between the kernel and user applications is considered <strong>middleware</strong>(中间件) [<a href="https://en.wikipedia.org/wiki/Middleware">1</a>].</p>

<h2 id="toc_1">Computer-system organisation</h2>

<p>A computer system can be divided roughly into four components: the <strong>hardware</strong>, the <strong>operating system</strong>, the <strong>application programs</strong>, and a <strong>user</strong>.</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/abstractviewofcomputersytem.png" alt="Abstract view of the components of a computer system"/></p>

<p>A <strong>computer system</strong>(计算机系统) consists of one or more <strong>CPUs</strong> and a number of <strong>device controllers</strong>(设备控制器) connected through a common <strong>bus</strong>(总线) that provides access between components and shared <strong>memory</strong>.</p>

<p>A <strong>device controller</strong> maintains some <strong>local buffer storage</strong>(局部缓冲存储) and a set of special-purpose <strong>registers</strong>.</p>

<hr/>

<p>Typically, operating systems have a <strong>device driver</strong>(设备驱动) for each device controller. This device driver understands the device controller and provides the rest of the operating system with a uniform interface to the device</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/AtypicalPCcomputerSystem.png" alt="一个典型的PC计算机系统"/></p>

<h2 id="toc_2">Interrupt</h2>

<p>When the CPU is <strong>interrupted</strong>, it stops what it is doing and immediately transfers execution to a fixed location. The fixed location usually contains the starting address where the service routine for the interrupt is located.</p>

<p>The <strong>interrupt routine</strong>(中断程序) is called indirectly through the interrupt vector table（中断向量表).</p>

<ul>
<li>Generally, the table of pointers is stored in low memory (the first hundred or so locations).</li>
<li>These locations hold the addresses of the interrupt service routines for the various devices.</li>
<li>Interrupt vector is then indexed by a unique number(interrupt vector number, 中断向量号)</li>
<li>interrupt priority levels(中断优先级)</li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/interruptvectortable.png" alt="中断向量号"/></p>

<p>Some <strong>services</strong> are provided outside of the kernel by system programs that are loaded into memory at boot time to become system <strong>daemons</strong>, which run the entire time the kernel is running.</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/interrupt-driven%20I:O%20cycle.png" alt="interrupt-driven I:O cycle"/></p>

<h3 id="toc_3">interrupt, exception, trap</h3>

<p>Unfortunately, there is no clear consensus as to the exact meaning of these terms(exceptions, faults, aborts, traps, and interrupts). Different authors adopt different terms to their own use [<a href="http://www.plantation-productions.com/Webster/www.artofasm.com/DOS/pdf/ch17.pdf">ref</a>].</p>

<p><strong>trap</strong>(陷阱) or <strong>exception</strong>(异常): a software-generated interrupt either by an error（e.g. division by zero, or invalid memory access or by a system call.</p>

<ul>
<li>usual way to invoke a kernel routine (a system call) </li>
</ul>

<p><strong>interrupt</strong>(中断):  generated by the hardware (devices like the hard disk, graphics card, I/O ports, etc).</p>

<h2 id="toc_4">multiprogramming and multitasking</h2>

<p><strong>Multiprogramming</strong>(多道程序) explained:</p>

<ul>
<li>The operating system <strong>keeps several processes in memory</strong> simultaneously. </li>
<li>The operating system picks and begins to execute one of these processes.</li>
<li>Eventually, the process may have to wait for some task, such as an I/O operation, to complete.</li>
<li>When that process needs to wait, the CPU <strong>switches</strong> to another process, and so on.</li>
<li> Eventually, the first process finishes waiting and gets the CPU back. As long as at least one process needs to execute, the <strong>CPU is never idle</strong>.</li>
</ul>

<p><strong>Multitasking</strong>(多任务) is a logical <strong>extension</strong> of multiprogramming. In multitasking systems, the CPU executes multiple processes by switching among them, but the switches occur <strong>frequently</strong>, providing the user with a <strong>fast</strong> response time.</p>

<h2 id="toc_5">dual-mode</h2>

<p>In order to ensure the proper execution of the system, we must be able to distinguish between the execution of operating-system code（<strong>kernel mode</strong>）and user-defined code (<strong>user mode</strong>).</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/transitionfromusermodetokernelmode.png" alt="Transition from user mode to kernel mode"/></p>

<p><strong>Mode bit</strong>(模式位), is added to the hardware of the computer to indicate the current mode: kernel (0) or user (1).</p>

<p>The concept of modes can be <strong>extended</strong> beyond two modes. </p>

<ul>
<li><p><strong>protection rings</strong>（保护环) are mechanisms to protect data and functionality from faults (by improving fault tolerance) and malicious behavior (by providing computer security). </p></li>
<li><p>For intel processors, ring 0 is kernel mode and ring 3 is user mode</p></li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/15317318589869.jpg" alt=""/></p>

<h2 id="toc_6">timer</h2>

<p>A timer (定时器) can  be set to interrupt the computer after a specified period( usually, 100s hz)</p>

<ul>
<li>A variable timer is generally implemented by a fixed-rate clock and a counter. </li>
<li>The operating system sets the counter. Every time the clock ticks, the counter is decremented. </li>
<li>When the counter reaches 0, an interrupt occurs.</li>
</ul>

<h2 id="toc_7">virtualization</h2>

<p><strong>virtualization</strong>(虚拟化) is a technology that allows us to abstract the hardware of a single computer into several different execution environments, thereby creating the illusion that <u><em>each separate environment is running on its own private computer</em></u> .</p>

<ul>
<li>v.s. [different] Emulation involves simulating computer handware in software.</li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/virtualmachines.png" alt="A computer running (a) a single operating system and (b) three virtual machines"/></p>

<h2 id="toc_8">Free and Open-Source OS</h2>

<p>Open-source OS</p>

<ul>
<li>source code available</li>
<li>opposite: closed-source OS</li>
</ul>

<p>Free OS</p>

<ul>
<li>source code available</li>
<li>allow no-cost use, redistribution, and modification</li>
</ul>

<p>Arguably, open-source code is <strong>more secure</strong> than closed-source code because many more eyes are viewing the code.</p>

<p>e.g. OS</p>

<ul>
<li> GNU/Linux</li>
<li> FreeBSD</li>
<li> Solaris</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 2 - Operating System structures]]></title>
    <link href="http://larryim.cc/os-concepts-os-structures.html"/>
    <updated>2018-07-16T18:16:02+08:00</updated>
    <id>http://larryim.cc/os-concepts-os-structures.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Operating system service</a>
</li>
<li>
<a href="#toc_1">User Interface</a>
</li>
<li>
<a href="#toc_2">System call</a>
<ul>
<li>
<a href="#toc_3">API</a>
</li>
<li>
<a href="#toc_4">Types of system calls</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">System Service</a>
</li>
<li>
<a href="#toc_6">OS Design and Implementation</a>
</li>
<li>
<a href="#toc_7">Operating system structure</a>
<ul>
<li>
<a href="#toc_8">Monolithic structure</a>
</li>
<li>
<a href="#toc_9">Layered</a>
</li>
<li>
<a href="#toc_10">Microkernel</a>
</li>
<li>
<a href="#toc_11">Modules</a>
</li>
<li>
<a href="#toc_12">Hybrid systems</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">System boot</a>
</li>
</ul>


<h2 id="toc_0">Operating system service</h2>

<p>The figure below is a view of the various operating-system services and how they interrelate.</p>

<p><img src="media/15317361625058/A%20view%20of%20operating%20system%20services.png" alt="A view of operating system services"/></p>

<h2 id="toc_1">User Interface</h2>

<p>There&#39;re mainly three ways for users to interface with the operating system:</p>

<ul>
<li>command interpreter</li>
<li>graphical user interface</li>
<li>touch-screen interface</li>
</ul>

<h2 id="toc_2">System call</h2>

<p>Purpose of System Call: System calls provide an <strong>interface to the services</strong> made available by an operating system.</p>

<h3 id="toc_3">API</h3>

<p>Typically, application developers design programs according to an application programming interface(<strong>API</strong>, 应用程序编程接口) rather than invoking <strong>actual system call</strong>.</p>

<ul>
<li>because even simple program may make heavy use of system call.</li>
<li><strong>program portabilit</strong>y: expect programs to compile and run other system that supports the same API</li>
<li><strong>run-time environment</strong>(RTE, 运行时环境) - the full suit of software needed to execute applications, including its compilers, interpreters, libraries, loaders.</li>
</ul>

<h3 id="toc_4">Types of system calls</h3>

<p>System calls can be grouped roughly into six major categories:<br/>
系统调用可分成六大类：进程控制，文件管理，设备管理，信息维护，通信和保护。</p>

<ul>
<li>process control</li>
<li>file management</li>
<li>device management</li>
<li>information maintenance</li>
<li>communications</li>
<li>protection</li>
</ul>

<p><img src="media/15317361625058/examplesofunixandlinuxsystemcalls.png" alt="Examples of Windows and Unix systemcalls"/></p>

<p>Three ways to pass parameters to the operating system:</p>

<ul>
<li>when less than five parameters, passing the parameters in registers</li>
<li>when more than five parameters, parameters are stored in a block, passing the address of the block in a register</li>
<li>using stack</li>
</ul>

<h2 id="toc_5">System Service</h2>

<p><strong>System services</strong>, also known as <strong>system utilities</strong>, provide a convenient environment for program development and execution.</p>

<h2 id="toc_6">OS Design and Implementation</h2>

<p>One important principle of OS design is <u>the separation of <strong>policy</strong> from <strong>mechanism</strong></u> . Mechanisms determine <strong>how</strong> to do something; policies determine <strong>what</strong> will be done.<br/>
操作系统设计的一个重要原则是策略（policy）和机制（mechanism）的分离。机制决定如何做，策略决定做什么。</p>

<ul>
<li>The separation of policy and mechanism is important for <strong>flexibility</strong>.</li>
</ul>

<h2 id="toc_7">Operating system structure</h2>

<h3 id="toc_8">Monolithic structure</h3>

<p>Operating systems with <strong>monolithic structure</strong> (单体结构) place all of the functionality of kernel into a <strong>single</strong>, <strong>static</strong> binary file that runs in a <strong>single</strong> address space.</p>

<ul>
<li>a common technique for designing operating system</li>
<li>e.g. original Unix operating system ( figure below)</li>
</ul>

<p><img src="media/15317361625058/traditional%20unix%20system%20structure.png" alt="Traditional Unix system structure"/></p>

<ul>
<li>e.g. Linux is based on Unix and is structured similarly, as shown in figure below.</li>
</ul>

<p><img src="media/15317361625058/linux%20system%20structure.png" alt="linux system structure"/></p>

<p>pros</p>

<ul>
<li>simplicity of kernels</li>
<li>a distinct performance advantage</li>
<li>very little overhead in the system-call interface</li>
<li>fast communication within the kernel</li>
</ul>

<p>cons</p>

<ul>
<li>difficult to implement and extend</li>
</ul>

<h3 id="toc_9">Layered</h3>

<p>A <strong>loosely coupled</strong> (松耦合) system is divided into separate, smaller components that have specific and limited functionality (<strong>modular</strong> approach). All these components together comprise the kernel .</p>

<ul>
<li>changes in one component affect only that component</li>
</ul>

<p>A system can be made modular in many ways.</p>

<ul>
<li>one way is the layered approach.</li>
</ul>

<p>For the <strong>layered operating system</strong> (层次式操作系统), it is broken into a number of layers.</p>

<ul>
<li>The bottom layer is the hardware; the highest is the user interface.</li>
<li>low-level layers can be invoked by higher-level layers</li>
</ul>

<p>pros</p>

<ul>
<li>simplicity of construction and debugging
<ul>
<li>each layer is implemented only with operations provided by lower-level layers. </li>
<li>higher-level layers can be debugged without any concern for the lower-level layers</li>
</ul></li>
</ul>

<p>cons</p>

<ul>
<li>difficulty of defining the functionality of each layer</li>
<li>poor performance
<ul>
<li>overhead of requiring a user program to traverse through multiple layers to obtain an operating-system service </li>
</ul></li>
</ul>

<p>Used in computer networks and web applications</p>

<p><img src="media/15317361625058/alayeredoperatingsystem.png" alt="A layered operating system"/></p>

<h3 id="toc_10">Microkernel</h3>

<p>Another way to modularized the kernel is using microkernel approach (微内核)。</p>

<ul>
<li><strong>removing all nonessential</strong> components from the kernel and implementing them as <strong>user-level</strong> programs the reside in <strong>separate</strong> address spaces.</li>
<li>smaller kernel</li>
</ul>

<p>A typical microkernel shown below.<br/>
<img src="media/15317361625058/a%20typical%20microkernel.png" alt="A typical microkernel"/></p>

<p>pros</p>

<ul>
<li>easy to extend the os
<ul>
<li>all new services added to user space do not require modification of the kernel.</li>
<li>when modification of kernel needed, changes tend to be fewer because of small kernel</li>
</ul></li>
<li>more security and reliability
<ul>
<li>since most services are running as user</li>
</ul></li>
</ul>

<p>cons</p>

<ul>
<li>performance may suffer due to increased system function overhead.
<ul>
<li>messages of user-level services to communicate must be copied between the services. </li>
</ul></li>
</ul>

<p>Best-known microkernel os is <strong>Darwin</strong>, the kernel component of the macOS and iOS.  </p>

<h3 id="toc_11">Modules</h3>

<p>Perhaps the best current methodology for operating system design involves using <strong>loadable kernel modules</strong>(LVMs, 可装载内核模块). Here, the kernel has a set of core components and can link in additional services via modules, either at boot time or during run time.</p>

<ul>
<li>design purpose: for the kernel to provide core services, while other services are implemented <strong>dynamically</strong>, as the kernel is running</li>
</ul>

<h3 id="toc_12">Hybrid systems</h3>

<p>In practice, <strong>very few</strong> operating system adopt a single, strictly defined structure. Instead, they <strong>combine different structures</strong><br/>
, resulting in <strong>hybrid systems</strong> that address performance, security, and usability issues.</p>

<p>Architecture of Apple’s macOS and iOS operating systems:<br/>
<img src="media/15317361625058/Architecture%20of%20Apple%E2%80%99s%20macOS%20and%20iOS%20operating%20systems.png" alt="Architecture of Apple’s macOS and iOS operating systems"/></p>

<p>Darwin provides two system-call interfaces: Mach system calls and BSD system calls.</p>

<p>The structure of Darwin:<br/>
<img src="media/15317361625058/The%20structure%20of%20Darwin..png" alt="The structure of Darwin."/></p>

<p>To address such performance problems, Darwin combines Mach, BSD, the I/O kit, and any kernel extensions into a <strong>single</strong> address space.</p>

<p><a href="https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/Architecture/Architecture.html#//apple_ref/doc/uid/TP30000905-CH1g-CACDAEDC">detailed documents for Darwin kernel</a></p>

<h2 id="toc_13">System boot</h2>

<p>The process of starting a computer by loading the kernel is known as <strong>booting</strong> the system.</p>

<ol>
<li>A small piece of code known as the <strong>bootstrap program</strong>（引导程序） or boot loader locates the kernel.</li>
<li>The kernel is loaded into memory and started.</li>
<li>The kernel initializes hardware.</li>
<li>The root file system is mounted.</li>
</ol>

<p>bootstrap program:</p>

<ul>
<li>usually, bootstrap program located in BIOS( nonvolatile firmware(固件) on motherboard, <a href="https://en.wikipedia.org/wiki/BIOS">wiki</a>)</li>
<li><strong>GRUB</strong> is an open-source bootstrap program for Linux and Unix systems <a href="https://en.wikipedia.org/wiki/GNU_GRUB">wiki</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop the definitive guide 1 - Hadoop fundamentals]]></title>
    <link href="http://larryim.cc/Hadoop%20_the_definitive_guide_1-Hadoop_fundamentals.html"/>
    <updated>2018-07-17T00:56:20+08:00</updated>
    <id>http://larryim.cc/Hadoop%20_the_definitive_guide_1-Hadoop_fundamentals.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 异常控制流]]></title>
    <link href="http://larryim.cc/exceptional_control_flow.html"/>
    <updated>2018-07-10T17:24:32+08:00</updated>
    <id>http://larryim.cc/exceptional_control_flow.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 异常</a>
<ul>
<li>
<a href="#toc_1">1.1 异常的处理</a>
</li>
<li>
<a href="#toc_2">1.2 异常的类别</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">2 进程</a>
<ul>
<li>
<a href="#toc_4">2.1 逻辑控制流</a>
</li>
<li>
<a href="#toc_5">2.2 并发流</a>
</li>
<li>
<a href="#toc_6">2.3 私有地址空间</a>
</li>
<li>
<a href="#toc_7">2.4 用户模式和内核模式</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">3 系统调用错误处理</a>
</li>
<li>
<a href="#toc_9">4 进程控制</a>
<ul>
<li>
<a href="#toc_10">4.1 获取进程ID</a>
</li>
<li>
<a href="#toc_11">4.2 创建和终止进程</a>
</li>
<li>
<a href="#toc_12">4.3 回收子进程</a>
</li>
<li>
<a href="#toc_13">4.4 进程休眠</a>
</li>
<li>
<a href="#toc_14">4.5  加载并运行程序</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">5 信号</a>
<ul>
<li>
<a href="#toc_16">5.1 发送/接收信号</a>
</li>
<li>
<a href="#toc_17">5.2 发送信号</a>
</li>
<li>
<a href="#toc_18">5.3 接收信号</a>
</li>
<li>
<a href="#toc_19">5.4 阻塞信号和进程回收</a>
<ul>
<li>
<a href="#toc_20">5.4.1 隐式阻塞机制</a>
</li>
<li>
<a href="#toc_21">5.4.2 显式阻塞机制</a>
</li>
</ul>
</li>
<li>
<a href="#toc_22">5.5 信号处理程序</a>
</li>
</ul>
</li>
</ul>


<p>从给处理器加电开始，直到你断电为止，程序计数器假设成一个值的序列</p>

<p>\[a_0, a_1, ..., a_{n-1}\]</p>

<p>其中，每个\(a_k\)是某个相应的指令\(I_k\)的 <u>地址</u> 。每次从\(a_k\)到\(a_{k+1}\)的过渡称为<strong>控制转移</strong>(control transfer)。这样的控制转移序列叫做处理器的<strong>控制流</strong>(control flow)。</p>

<p>现在系统通过使控制流发生突变来应对系统状态的变化(eg.缺页异常，网络等待)，把这些突变称为<strong>异常控制流</strong>(Exceptional Control Flow, ECF)。</p>

<h2 id="toc_0">1 异常</h2>

<h3 id="toc_1">1.1 异常的处理</h3>

<p>系统为每<strong>类</strong>可能的异常都分配了一个唯一的非负整数的<strong>异常号</strong>(exception number)。在系统启动时，操作系统分配和初始化一张称为<strong>异常表</strong>的跳转表，使得表目\(k\)包含异常\(k\)的处理程序的地址。</p>

<p><img src="media/15312146721582/%E5%BC%82%E5%B8%B8%E8%A1%A8.png" alt="异常表"/></p>

<p>当检测到发生了一个事件，并且确定了相应的异常号\(k\)，处理器触发异常，执行间接过程调用，通过异常表的表目\(k\)，转到相应的处理程序。</p>

<h3 id="toc_2">1.2 异常的类别</h3>

<p>异常(exceptions)可以分为四类：中断(interrupt)、陷阱(trap)、故障(fault)和终止(abort)。<br/>
<img src="media/15312146721582/Exceptions.png" alt="Exceptions"/></p>

<ul>
<li><strong>中断</strong>是异步发生的，是来自处理器外部的I/O设备的信号的结果。</li>
<li><strong>陷阱</strong>是有意的异常，是执行一条指令的结果。
<ul>
<li>其用途是在用户程序和内核之间提供一个像过程一样的接口(系统调用)</li>
</ul></li>
<li><strong>故障</strong>是由错误情况引起的，可能能够被故障处理程序修正。
<ul>
<li>例如缺页异常</li>
</ul></li>
<li><strong>终止</strong>是不可恢复的致命错误造成的结果，通常是一些硬件错误。<br/></li>
</ul>

<h2 id="toc_3">2 进程</h2>

<p>进程(Process)的经典定义就是 <u>一个执行中程序的实例</u> (A process is a program in execuation) 。系统中的每个程序都运行在某个进程的上下文(context)中。上下文是由程序正确运行所需的状态组成的。这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合。</p>

<p>进程提供了应用程序两个关键抽象：</p>

<ul>
<li>一个<strong>独立</strong>的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器。</li>
<li>一个<strong>私有</strong>的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统。</li>
</ul>

<h3 id="toc_4">2.1 逻辑控制流</h3>

<p><strong>逻辑控制流</strong>(Logical Control Flow，简称逻辑流)是PC值的序列。</p>

<h3 id="toc_5">2.2 并发流</h3>

<p>一个逻辑流的执行在时间上与另一个流重叠，称为<strong>并发流</strong>(concurrent flow)，这两个流被称为<strong>并发地运行</strong>。</p>

<h3 id="toc_6">2.3 私有地址空间</h3>

<p>进程为每个程序提供它自己的<strong>私有地址空间</strong>。一般而言，和这个空间中某个地址相关联的那个内存字节是不能被其他进程读或者写的，从这个意义上说，这个地址空间是私有的。</p>

<h3 id="toc_7">2.4 用户模式和内核模式</h3>

<p>处理器通常是用某个控制寄存器中的一个<strong>模式位</strong>(mode bit)来控制用户/内核模式。当设置了模式位时，进程就运行在<strong>内核模式</strong>中，否则运行在<strong>用户模式</strong>中。</p>

<p>运行在内核模式的进程可以执行指令集中的任何指令，可以访问任何内存位置。用户模式中的进程不允许执行特权指令，也不允许直接引用地址空间中内核区的代码和数据。</p>

<h2 id="toc_8">3 系统调用错误处理</h2>

<h2 id="toc_9">4 进程控制</h2>

<p>进程控制包括获取进程ID、创建和终止进程、回收子进程、让进程休眠、加载并运行程序等。这一节将描述Unix提供了控制进程的系统调用。</p>

<h3 id="toc_10">4.1 获取进程ID</h3>

<p>每一个进程都有一个唯一的整数(非零)进程ID(PID)。<code>getpid</code>函数返回调用进程的PID。<code>getppid</code>函数返回它的父进程的PID。</p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

pid_t getpid(void);
pit_t getppid(void);
</code></pre>

<h3 id="toc_11">4.2 创建和终止进程</h3>

<p><strong>父进程</strong>通过调用fork函数创建一个新的运行的<strong>子进程</strong>。</p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

pid_t fork(void);
</code></pre>

<p>新创建的子进程几乎但不完全与父进程相同：</p>

<ul>
<li><strong>相同但是独立的地址空间</strong>：子进程获得父进程虚拟地址空间的一份副本</li>
<li><strong>共享文件</strong>：子进程获得父进程打开文件描述符相同的副本</li>
<li>子进程与父进程pid不同</li>
</ul>

<h3 id="toc_12">4.3 回收子进程</h3>

<p>进程在终止后，并不会被内核从系统中清除，而是保持这种状态，直到被它的父进程<strong>回收</strong>(reaped)。</p>

<ul>
<li>一个终止了但还未被回收的进程称为<strong>僵死进程</strong>(zombie)。</li>
<li>即使僵死进程没有运行，它仍然消耗系统的内存资源。</li>
</ul>

<p>通过调用<code>waitpid</code>函数来等待子进程终止或者停止。</p>

<h3 id="toc_13">4.4 进程休眠</h3>

<p><code>sleep</code>函数将一个进程挂起一段制定的时间。</p>

<pre><code class="language-c">#include &lt;unistd.n&gt;
unsigned int sleep(unsigned int secs);
</code></pre>

<h3 id="toc_14">4.5  加载并运行程序</h3>

<p><code>execve</code>函数在当前进程的上下文中加载并运行一个新程序。</p>

<ul>
<li><code>execve</code>调用一次并从不返回。</li>
</ul>

<h2 id="toc_15">5 信号</h2>

<p>Linux<strong>信号</strong>，通知进程系统中发生一个某种类型的事件。每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。下面是Linux系统上常见的信号：</p>

<p><strong>常见的信号</strong>：</p>

<table>
<thead>
<tr>
<th>编号</th>
<th>名称</th>
<th>默认动作</th>
<th>对应事件</th>
</tr>
</thead>

<tbody>
<tr>
<td>2</td>
<td>SIGINT</td>
<td>终止</td>
<td>来自键盘的中断CTRL+C</td>
</tr>
<tr>
<td>3</td>
<td>SIGQUIT</td>
<td>终止</td>
<td>来自键盘的退出CTRL+\</td>
</tr>
<tr>
<td>9</td>
<td>SIGKILL</td>
<td>终止</td>
<td>杀死程序 <code>\bin\kill -9</code></td>
</tr>
<tr>
<td>11</td>
<td>SIGSEGV</td>
<td>终止并转储内存</td>
<td>段故障(无效的内存引用)</td>
</tr>
<tr>
<td>15</td>
<td>SIGTERM</td>
<td>终止</td>
<td>软件终止信号<code>\bin\kill</code></td>
</tr>
<tr>
<td>17</td>
<td>SIGCHLD</td>
<td>忽略</td>
<td>子进程停止或终止</td>
</tr>
<tr>
<td>18</td>
<td>SIGCONT</td>
<td>忽略</td>
<td>继续进程如果该进程停止</td>
</tr>
<tr>
<td>20</td>
<td>SIGTSTP</td>
<td>停止直到下一个SIGCONT</td>
<td>用户输入CTRL+Z</td>
</tr>
</tbody>
</table>

<p>详细信息可以通过<code>man 7 signal</code>查询。</p>

<h3 id="toc_16">5.1 发送/接收信号</h3>

<p>传送一个信号到目的进程由发送、接收信号两个步骤组成：</p>

<ul>
<li>发送信号。内核通过更新目的进程上下文中的某个状态，发送(递送)一个信号给目的进程。</li>
<li>接收信号。当目的进程被内核强迫已某种方式对信号的发送做出反应时，它就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为<strong>信号处理程序</strong>的用户层函数捕获这个信号。</li>
</ul>

<h3 id="toc_17">5.2 发送信号</h3>

<p>发送信号可以由以下原因引起：</p>

<ul>
<li>用户：用户能够通过输入<code>CTRL+c</code>(<code>SIGINT</code>)、<code>Ctrl+z</code>(<code>SIGTSTP</code>)，或者是终端驱动程序分配给信号控制字符的其他任何键来请求内核产生信号；</li>
<li>内核：当进程执行出错时，内核会给进程发送一个信号，例如非法段存取(内存访问违规)、浮点数溢出等；</li>
<li>进程：一个进程可以通过系统调用kill给另一个进程或自己发送信号。</li>
</ul>

<h3 id="toc_18">5.3 接收信号</h3>

<p>当内核把进程\(p\)从内核模式切换到用户模式时，它会检查进程\(p\)的未被阻塞的待处理信号的集合(<code>pending&amp;~blocked</code>,见下文)，如果集合非空，那么内核强制\(p\)接收信号，触发进程采取某种行为。</p>

<p>进程接收到信号以后，可以有如下3种选择进行处理：</p>

<ul>
<li>接收默认处理：接收默认处理的进程通常会导致进程本身消亡。例如连接到终端的进程，用户按下CTRL+c，将导致内核向进程发送一个SIGINT的信号，进程如果不对该信号做特殊的处理，系统将采用默认的方式处理该信号，即终止进程的执行；</li>
<li>忽略信号：进程可以通过代码，显示地忽略某个信号的处理，例如：<code>signal(SIGINT,SIGDEF)</code>；但是某些信号是不能被忽略的，</li>
<li>捕获信号并处理：当接收到信号时，由信号处理程序自动捕获并且处理信号。</li>
</ul>

<pre><code class="language-c">sighandler_t signal(int signum, sighandler_t handler);
</code></pre>

<p>有两个信号既不能被忽略也不能被捕获，它们是<code>SIGKILL</code>和<code>SIGSTOP</code>。即进程接收到这两个信号后，只能接受系统的默认处理，即终止线程。</p>

<h3 id="toc_19">5.4 阻塞信号和进程回收</h3>

<p>一个发出而没有被接受的信号叫做<strong>未处理信号</strong>（Pending Signal）。进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未处理状态，直到进程解除对此信号的阻塞，才执行接收的动作。阻塞和忽略是不同的，<strong>只要信号被阻塞就不会接收</strong>，而忽略是在接收之后可选的一种处理动作。</p>

<p>Linux提供阻塞信号的隐式和显式机制:</p>

<ul>
<li><strong>隐式阻塞机制</strong>：内核默认阻塞任何当前处理程序正在处理信号类型的待处理的信号。如果在进程解除对某信号的阻塞之前这种信号产生过多次，只计一次。因为每个信号只有一个bit的未处理标志(如下图)，非0即1，不记录该信号产生了多少次，阻塞标志也是这样表示的。</li>
<li><strong>显式阻塞机制</strong>：应用<code>sigprocmask</code>函数，明确地阻塞和解除阻塞选定的信号。</li>
</ul>

<p>内核为每个进程在<strong>pending位向量</strong>中维护着待处理信号的集合，而在<strong>blocked位向量</strong>中维护着被阻塞的信号集合。信号在内核中的表示可以看作是这样的：</p>

<p><img src="media/15156057194882/15156070945641.png" alt=""/></p>

<p>每个信号都有两个标志位分别表示阻塞和未处理，还有一个函数指针表示处理动作。信号产生时，内核在进程控制块中设置该信号的未处理标志，直到信号接收才清除该标志。在上图的例子中，</p>

<ul>
<li>SIGHUP信号未阻塞也未产生过，当它接收时执行默认处理动作。</li>
<li>SIGINT信号产生过，但正在被阻塞，所以暂时不能接收。虽然它的处理动作是忽略，但在没有解除阻塞之前不能忽略这个信号，因为进程仍有机会改变处理动作之后再解除阻塞。</li>
<li>SIGQUIT信号未产生过，一旦产生SIGQUIT信号将被阻塞，它调用信号处理程序<code>sighandler</code>。</li>
</ul>

<h4 id="toc_20">5.4.1 隐式阻塞机制</h4>

<p>当多个未处理信号(<code>pending signal</code>)到达时，由于信号并不会产生排队等待这样的情况，所以产生的效果仅相当于一个未处理信号(也就是对应的<code>pending</code>位标记为1，例如上图中的<code>SIGINT</code>信号)。</p>

<p>这样带来几个问题：</p>

<ul>
<li>不能用信号来对其他进程中发生的事件计数，这是显而易见的</li>
<li>在回收子进程时，要回收尽可能多的子进程。例如下面这个例子。</li>
</ul>

<pre><code class="language-c">void handler1(int sig)   
{  
    pid_t pid;  
  
    if ((pid = waitpid(-1, NULL, 0)) &lt; 0)  
        unix_error(&quot;waitpid error&quot;);  
    printf(&quot;Handler reaped child %d\n&quot;, (int)pid);  
    Sleep(2);  
    return;  
}  

/* $begin signal2 */
void handler2(int sig) 
{
    int olderrno = errno;

    while (waitpid(-1, NULL, 0) &gt; 0) {
        Sio_puts(&quot;Handler reaped child\n&quot;);
    }
    // waitpid()函数有可能因为找不到子进程而报ECHILD错误
    if (errno != ECHILD)
        Sio_error(&quot;waitpid error&quot;);
    Sleep(1);
    errno = olderrno;
}
/* $end signal2 */

int main() 
{
    int i, n;
    char buf[MAXBUF];

    if (signal(SIGCHLD, handler2) == SIG_ERR) //handler2 或者 handler1
        unix_error(&quot;signal error&quot;);

    /* Parent creates children */
    for (i = 0; i &lt; 3; i++) {
        if (Fork() == 0) {
            printf(&quot;Hello from child %d\n&quot;, (int)getpid());
            exit(0);
        }
    }

    /* Parent waits for terminal input and then processes it */
    if ((n = read(STDIN_FILENO, buf, sizeof(buf))) &lt; 0)
        unix_error(&quot;read&quot;);

    printf(&quot;Parent processing input\n&quot;);
    while (1)
        ;

    exit(0);
}
</code></pre>

<p>在上面这个例子中，父进程创建一些子进程，这些子进程各自独立运行一段时间，然后终止。用<code>SIGCHLD</code>处理程序来回收子进程，其中<code>handler1</code>是错误的，会产生僵死子进程。<code>handler2</code>是安全的。原因是在<code>handler1</code>中，可能存在子进程先被执行，产生<code>SIGCHLD</code>信号；但是在子进程还未被回收之前，又有多个子进程被执行，产生多个<code>SIGCHLD</code>信号。于是多余的未处理<code>SIGCHLD</code>信号就被抛弃，只相当于一个<code>SIGCHLD</code>信号。最终会造成有的子进程未被回收，产生僵死子进程。</p>

<p>执行的可能结果如下，可以看到父进程只回收了两个子进程。</p>

<pre><code class="language-text">Hello from child 5617
Hello from child 5616
Hello from child 5618
Handler reaped child
Handler reaped child

Parent processing input
</code></pre>

<h4 id="toc_21">5.4.2 显式阻塞机制</h4>

<p>有时候不希望在发送信号后就立即去接收、处理信号，同时也不希望忽略该信号，那么可以通过<code>sigprocmask</code>显式地阻塞信号从而实现延迟接收信号。</p>

<p>函数<code>sigprocmask</code>可以更改当前阻塞的信号集合(即blocked位向量):</p>

<pre><code class="language-c">int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);
</code></pre>

<p>其具体行为依赖于how值：</p>

<pre><code class="language-text">SIG_BLOCK, blocked = blocked | set //添加set信号
SIG_UNBLOCK, blocked = blocked &amp; ~set //删除set信号
SIG_SETMASK, block = set //设置set信号为阻塞的信号
</code></pre>

<p>阻塞的信号集合其实就是一个无符号整型数组(在x86-64上，数组长度是16)。</p>

<pre><code class="language-c">/* A `sigset_t&#39; has a bit for each signal.  */
# define _SIGSET_NWORDS (1024 / (8 * sizeof (unsigned long int)))
typedef struct
{
    unsigned long int __val[_SIGSET_NWORDS];
} sigset_t;
</code></pre>

<p>还有其他的一些函数可以对信号集进行操作：</p>

<pre><code class="language-c">int sigfillset(sigset_t *set); // 信号集初始化, 然后把所有的信号加入到此信号集里
int sigemptyset(sigset_t *set); //信号集初始化为空
int sigaddset(sigset_t *set, int signo); //将信号signo添加到信号集中  
</code></pre>

<p>下面看个例子, 是一个具有细微同步错误的SHELL程序。如果子进程在父进程能够开始运行前就结束了，那么<br/>
<code>addjob()</code> 和 <code>deletejob()</code> 会以错误的方式被调用。这个程序希望父进程在一个作业列表中记录着它的当前子进程，每个作业条目。 <code>addjob()</code> 和 <code>deletejob()</code> 分别想这个作业列表添加和从中删除作业。当父进程创建一个新的子进程时，它就把这个子进程添加到作业列表中。当父进程在<code>SIGCHLD</code> 处理程序中回收一个终止的（僵死）子进程时，它就从作业列表中删除这个子进程。乍一看，这段代码是对的。不幸的是，可能发生下面的情况：</p>

<ul>
<li>1. 父进程执行<code>fork()</code>，内核调度新创建的子进程运行，而不是父进程</li>
<li>2. 在父进程能够再次运行之前，子进程就终止，并且变成一个僵死进程，使得内核传递一个<code>SIGCHLD</code>信号给父进程</li>
<li>3. 后来，当父进程再次变成可运行但又在它执行之前，内核注意到待处理的<code>SIGCHLD</code>信号，并通过在父进程中运行处理程序接收这个信号</li>
<li>4. 处理程序回收终止的子进程，并调用<code>deletejob()</code>，这个函数什么都不做，因为父进程还没有把该子进程添加到列表中</li>
<li>5. 在处理程序运行结束后，内核运行父进程，父进程从<code>fork()</code>返回，通过调用<code>addjob()</code> 错误地把（不存在的）子进程添加到作业列表中</li>
</ul>

<pre><code class="language-c">void handler(int sig)
{
        pid_t pid;
        while ((pid = waitpid(-1, NULL, 0)) &gt; 0) /* Reap a zombie child */
                deletejob(pid); /* Delete the child from the job list */
        if (errno != ECHILD)
                unix_error(&quot;waitpid error&quot;);
}

int main(int argc, char **argv)
{
        int pid;

        Signal(SIGCHLD, handler);
        initjobs();             /* Initialize the job list */

        while (1) {
                /* Child process */
                if ((pid = Fork()) == 0) {
                        Execve(&quot;/bin/date&quot;, argv, NULL);
                }

                /* Parent process */
                addjob(pid);    /* Add the child to the job list */
        }

        exit(0);
}
</code></pre>

<p>正确的做法应该如下,  通过在调用 <code>fork()</code> 之前，阻塞 <code>SIGCHLD</code> 信号，然后在我们调用了 <code>addjob()</code> 之后就取消阻塞这些信号，我们保证了在子进程被添加到作业列表之后回收该子进程。注意，子进程继承了它们父进程的被阻塞集合，所以我们必须在调用 <code>execve()</code> 之前，小心地解除子进程中阻塞的 <code>SIGCHLD</code> 信号。这样，父进程保证在相应的 <code>deletejob()</code> 之前执行 <code>addjob()</code>。</p>

<pre><code class="language-c">int main(int argc, char **argv)
{
    int pid;
    sigset_t mask_all, mask_one, prev_one;

    Sigfillset(&amp;mask_all);
    Sigemptyset(&amp;mask_one);
    Sigaddset(&amp;mask_one, SIGCHLD);
    Signal(SIGCHLD, handler);
    initjobs(); /* Initialize the job list */

    while (1) {
        Sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;prev_one); /* Block SIGCHLD */
        if ((pid = Fork()) == 0) { /* Child process */
            Sigprocmask(SIG_SETMASK, &amp;prev_one, NULL); /* Unblock SIGCHLD */
            Execve(&quot;/bin/date&quot;, argv, NULL);
        }
        Sigprocmask(SIG_BLOCK, &amp;mask_all, NULL); /* Parent process */  
        addjob(pid);  /* Add the child to the job list */
        Sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);  /* Unblock SIGCHLD */
    }
    exit(0);
}
</code></pre>

<h3 id="toc_22">5.5 信号处理程序</h3>

<p>信号处理程序(signal handler)是重要且棘手的一个问题。其难点在：</p>

<ul>
<li>处理程序与主程序并发运行，共享同样的全局变量，因此可能与主程序和其他处理程序相互干扰；</li>
<li>如何以及何时接收信号的规则常常违背人的直觉。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Overhead]]></title>
    <link href="http://larryim.cc/overhead.html"/>
    <updated>2018-01-21T12:39:28+08:00</updated>
    <id>http://larryim.cc/overhead.html</id>
    <content type="html"><![CDATA[
<p><strong>overhead</strong>这个词在计算机中经常出现，那么它到底是什么意思呢？</p>

<p>overhead视风格可以翻译成「额外开销」、「额外消耗」、「虚耗」。</p>

<p>额外开销是建立一个操作所需的资源，它可能看起来不相关，但是却是必须的。就好像当你需要去某个地方的时候，你可能需要一辆车。但是如果你开车上街这件事是大量的额外开销，你可能会想要走路；但是如果你要开车穿越一个国家，额外开销是值得的。</p>

<p>The meaning of the word can differ a lot with context. In general, it&#39;s resources (most often memory and CPU time) that are used, which do not contribute directly to the intended result, but are required by the technology or method that is being used. Examples:</p>

<ul>
<li><p>Protocol overhead: Ethernet frames, IP packets and TCP segments all have headers, TCP connections require handshake packets. Thus, you cannot use the entire bandwidth the hardware is capable of for your actual data. You can reduce the overhead by using larger packet sizes and UDP has a smaller header and no handshake.</p></li>
<li><p>Data structure memory overhead: A linked list requires at least one pointer for each element it contains. If the elements are the same size as a pointer, this means a 50% memory overhead, whereas an array can potentially have 0% overhead.</p></li>
<li><p>Method call overhead: A well-designed program is broken down into lots of short methods. But each method call requires setting up a stack frame, copying parameters and a return address. This represents CPU overhead compared to a program that does everything in a single monolithic function. Of course, the added maintainability makes it very much worth it, but in some cases, excessive method calls can have a significant performance impact.</p></li>
</ul>

<h2 id="toc_0">参考</h2>

<ul>
<li><a href="https://stackoverflow.com/questions/2860234/what-is-overhead">https://stackoverflow.com/questions/2860234/what-is-overhead</a></li>
<li><a href="https://www.zhihu.com/question/20596199?sort=created">https://www.zhihu.com/question/20596199?sort=created</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - x86-64汇编]]></title>
    <link href="http://larryim.cc/15146536465849.html"/>
    <updated>2017-12-31T01:07:26+08:00</updated>
    <id>http://larryim.cc/15146536465849.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">汇编代码格式</h2>

<p>现在主要存在<code>ATT</code>和<code>Intel</code>两种汇编代码格式。<code>ATT</code>格式是<code>GCC</code>、 <code>OBJDUMP</code>常用工具的默认格式。其他的诸如Microsoft的工具和来自Intel的文档都是<code>Intel</code>格式的。本文使用<code>ATT</code>格式。</p>

<p><code>ATT</code>汇编格式的注释格式有两种</p>

<pre><code class="language-text"># this is a comment
/* this is a comment */
</code></pre>

<h2 id="toc_1">寄存器</h2>

<p><code>x86-64</code>体系结构广泛存在于个人电脑中。它拥有16个整数寄存器，分别存储64位的值。这些寄存器可以存储地址或整数数据，其分布如下：</p>

<p><img src="media/15146536465849/sfd.png" alt="sfd"/></p>

<p>根据惯例，寄存器%rbx, %rbp和%r12~%r15被划分为<strong>被调用者保存寄存器</strong>。所有其他的寄存器，除了栈指针%rsp都分类为<strong>调用者保存寄存器</strong>。</p>

<ul>
<li>在函数被调用时，不能改变<strong>被</strong>调用者寄存器；</li>
<li>如果要改变的话，只能把<strong>被</strong>调用者寄存器的值压入栈中，在使用后，从栈中恢复<strong>被</strong>调用者寄存器。</li>
</ul>

<h3 id="toc_2">rip 寄存器与PC相对寻址</h3>

<p>%rip 的名称来自于(instruction pointer register，指令指针寄存器)。%rip其实就是<strong>程序计数器</strong>(Program Counter, PC), <u><em>存放着下一条指令的地址</em></u> 。不可以直接修改%rip。</p>

<p>-&gt; <code>instruction pointer = program counter = %rip</code></p>

<p>%rip的其他很重要的一个用法就是RIP/<strong>PC相对寻址</strong>(RIP/PC relative addressing)。即<code>%rip + displacement</code>的用法。</p>

<p>例如，</p>

<pre><code class="language-assembly">mov    0x202a62(%rip),%rdi        # 6044d0 &lt;infile&gt;  rdi = infile
</code></pre>

<p>表示传输%rip+0x202a62的地址对应的内存上的内容到%rdi。</p>

<p>下面说说它是怎么进行PC相对寻址的。</p>

<ul>
<li>源文件经过预处理器、编译器、汇编器处理，输出<strong>可重定位目标文件</strong></li>
<li>再经过<strong>符号解析</strong>(Symbol resolution)把代码中的每个符号引用和一个符号定义关联起来之后，要完成<strong>重定位</strong>(Relocation)任务，最终输出<strong>可执行目标文件</strong>。
<ul>
<li>在<strong>重定位</strong>阶段，ELF(可重定位目标文件在LINUX系统上的一种格式)文件中的<code>R_X86_64_PC32</code>重定位类型重定位了一个使用32位PC相对地址的引用。</li>
<li>当CPU执行一条使用PC相对寻址的指令时，它就将在指令中编码的32位值加上PC的当前运行时值，得到<strong>有效地址</strong>。</li>
</ul></li>
</ul>

<h2 id="toc_3">指令</h2>

<p>指令主要有<code>mov</code>数据传送指令，<code>push</code>、<code>pop</code>压入和压出栈数据，<code>add</code>,<code>sub</code>等算数操作指令，<code>ret</code>, <code>call</code>等转移控制指令。</p>

<h3 id="toc_4">数据传送指令</h3>

<table>
<thead>
<tr>
<th>指令</th>
<th>效果</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>MOV S, D</td>
<td>将S中数据传送到D中</td>
<td>传送</td>
</tr>
<tr>
<td>movb</td>
<td>传送字节</td>
<td></td>
</tr>
<tr>
<td>movw</td>
<td>传送字(双字节)</td>
<td></td>
</tr>
<tr>
<td>movl</td>
<td>传送双字(四字节)</td>
<td></td>
</tr>
<tr>
<td>MOVS S, D</td>
<td>将S中数据传送到D，过程中做了符号扩展处理 传送需要符号扩展的字节</td>
<td></td>
</tr>
<tr>
<td>movsbw</td>
<td>将做了符号扩展的字节传送到字</td>
<td></td>
</tr>
<tr>
<td>movsbl</td>
<td>将做了符号扩展的字节传送到双字</td>
<td></td>
</tr>
<tr>
<td>movswl</td>
<td>将做了符号扩展的字传送到双字</td>
<td></td>
</tr>
<tr>
<td>MOVZ S, D</td>
<td>将S中数据传送到D，过程中做了零扩展处理</td>
<td>传送需要零扩展的字节</td>
</tr>
<tr>
<td>movzbw</td>
<td>将做了零扩展的字节传送到</td>
<td></td>
</tr>
<tr>
<td>movzbl</td>
<td>将做了零扩展的字节传送到双字</td>
<td></td>
</tr>
<tr>
<td>movzwl</td>
<td>将做了零扩展的字传送到双字</td>
<td></td>
</tr>
<tr>
<td>pushl S</td>
<td>R[%esp] &lt;- R[%esp] - 4; M[R[%esp]] &lt;- S;</td>
<td>将双字压栈</td>
</tr>
<tr>
<td>popl D</td>
<td>D &lt;- M[R[%esp]]; R[%esp] &lt;- R[%esp] + 4;</td>
<td>将双字出栈</td>
</tr>
</tbody>
</table>

<h3 id="toc_5">ret, call指令</h3>

<p>在x86-64上，<code>ret</code>指令，相当于从栈中弹出地址A，然后把PC设置为A。<br/>
<code>pop %rip</code><br/>
而<code>call</code>指令，刚好相反，把%rip 压入栈中，然后跳到函数对应的地址。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSE 421/521 Operating Systems]]></title>
    <link href="http://larryim.cc/15312166852240.html"/>
    <updated>2018-07-10T17:58:05+08:00</updated>
    <id>http://larryim.cc/15312166852240.html</id>
    <content type="html"><![CDATA[
<p>主页：<a href="https://www.ops-class.org">https://www.ops-class.org</a><br/>
Notes: </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Objdump 反汇编]]></title>
    <link href="http://larryim.cc/objdump_disassembler.html"/>
    <updated>2018-01-01T03:54:09+08:00</updated>
    <id>http://larryim.cc/objdump_disassembler.html</id>
    <content type="html"><![CDATA[
<p><code>objdump</code>是一个反汇编器(<code>disassembler</code>)，可以将机器语言生成对应的汇编文件。常用的命令是</p>

<pre><code class="language-text">objdump -d filename.o
</code></pre>

<p>其选项有：</p>

<pre><code class="language-text">--archive-headers 
-a 
显示档案库的成员信息,类似ls -l将lib*.a的信息列出。 

-b bfdname 
--target=bfdname 
指定目标码格式。这不是必须的，objdump能自动识别许多格式，比如： 

objdump -b oasys -m vax -h fu.o 
显示fu.o的头部摘要信息，明确指出该文件是Vax系统下用Oasys编译器生成的目标文件。objdump -i将给出这里可以指定的目标码格式列表。 

-C 
--demangle 
将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外，还使得C++函数名以可理解的方式显示出来。 

--debugging 
-g 
显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。仅仅支持某些类型的调试信息。有些其他的格式被readelf -w支持。 

-e 
--debugging-tags 
类似-g选项，但是生成的信息是和ctags工具相兼容的格式。 

--disassemble 
-d 
从objfile中反汇编那些特定指令机器码的section。 

-D 
--disassemble-all 
与 -d 类似，但反汇编所有section. 

--prefix-addresses 
反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式。 

-EB 
-EL 
--endian={big|little} 
指定目标文件的小端。这个项将影响反汇编出来的指令。在反汇编的文件没描述小端信息的时候用。例如S-records. 

-f 
--file-headers 
显示objfile中每个文件的整体头部摘要信息。 

-h 
--section-headers 
--headers 
显示目标文件各个section的头部摘要信息。 

-H 
--help 
简短的帮助信息。 

-i 
--info 
显示对于 -b 或者 -m 选项可用的架构和目标格式列表。 

-j name
--section=name 
仅仅显示指定名称为name的section的信息 

-l
--line-numbers 
用文件名和行号标注相应的目标代码，仅仅和-d、-D或者-r一起使用使用-ld和使用-d的区别不是很大，在源码级调试的时候有用，要求编译时使用了-g之类的调试编译选项。 

-m machine 
--architecture=machine 
指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如S-records)，这个选项很有用。可以用-i选项列出这里能够指定的架构. 

--reloc 
-r 
显示文件的重定位入口。如果和-d或者-D一起使用，重定位部分以反汇编后的格式显示出来。 

--dynamic-reloc 
-R 
显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 

-s 
--full-contents 
显示指定section的完整内容。默认所有的非空section都会被显示。 

-S 
--source 
尽可能反汇编出源代码，尤其当编译的时候指定了-g这种调试参数时，效果比较明显。隐含了-d参数。 

--show-raw-insn 
反汇编的时候，显示每条汇编指令对应的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--no-show-raw-insn 
反汇编时，不显示汇编指令的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--start-address=address 
从指定地址开始显示数据，该选项影响-d、-r和-s选项的输出。 

--stop-address=address 
显示数据直到指定地址为止，该项影响-d、-r和-s选项的输出。 

-t 
--syms 
显示文件的符号表入口。类似于nm -s提供的信息 

-T 
--dynamic-syms 
显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。它显示的信息类似于 nm -D|--dynamic 显示的信息。 

-V 
--version 
版本信息 

--all-headers 
-x 
显示所可用的头信息，包括符号表、重定位入口。-x 等价于-a -f -h -r -t 同时指定。 

-z 
--disassemble-zeroes 
一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 

@file 可以将选项集中到一个文件中，然后使用这个@file选项载入。
</code></pre>

<p>下面通过一个简单的例子来说明一下<code>objdump</code>的常见用法，以及它生成的文件的格式。</p>

<p>假设写一个简单的C程序<code>test.c</code>如下：</p>

<pre><code class="language-c">int foo()
{
    int a = 5;
    int b = 0;
    b = a + 3;
}
</code></pre>

<p>用<code>gcc</code>命令<code>gcc test.c -c</code>生成目标文件<code>test.o</code>后, 利用<code>objdump -d test.o &gt; test.s</code>生成类似汇编文件：</p>

<pre><code class="language-text">test.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;foo&gt;:
   0:   55                      push   %rbp
   1:   48 89 e5                mov    %rsp,%rbp
   4:   c7 45 f8 05 00 00 00    movl   $0x5,-0x8(%rbp)
   b:   c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)
  12:   8b 45 f8                mov    -0x8(%rbp),%eax
  15:   83 c0 03                add    $0x3,%eax
  18:   89 45 fc                mov    %eax,-0x4(%rbp)
  1b:   5d                      pop    %rbp
  1c:   c3                      retq
</code></pre>

<p>可以看到的其实这个类似于汇编文件的格式是<code>elf64-x86-64</code>, 下一小节会简单的介绍这个格式。其中最重要的内容是从<code>0000000000000000 &lt;foo&gt;</code>开始到结束的部分。这部分从左到右依次是</p>

<ul>
<li>指令开始的地址<code>memory staring addresses</code></li>
<li>汇编代码对应的二进制指令<code>byte codes for instruction</code></li>
<li>汇编代码<code>assembly codes</code></li>
</ul>

<h3 id="toc_0">显示文件的符号表入口</h3>

<p><code>objdump -t</code> 命令会打印文件的符号表<code>symbol table</code>. 输出的文件一共有7列，从左到右依次是</p>

<ul>
<li>value</li>
<li>class</li>
<li>type</li>
<li>size</li>
<li>line</li>
<li>section</li>
<li>symbol-name</li>
</ul>

<h2 id="toc_1">elf64-x86-64 文件</h2>

<p><code>elf</code>是<code>Executable and Linkable Format</code>(可执行和可链接格式，<a href="http://larryim.cc/Linking.html">看本文</a>)的简称。<code>elf</code>文件格式及其复杂，如果只需要研究<code>objdump</code>产生的反汇编文件没有必要去专门学习<code>elf</code>格式。掌握下面几点，就可以阅读<code>objdump</code>产生的反汇编文件了。<code>objdump</code>产生的<code>elf</code>文件，主要包括以下几个部分：</p>

<ul>
<li>Disassembly of section .init</li>
<li>Disassembly of section .plt</li>
<li>Disassembly of section .text</li>
<li>Disassembly of section .fini</li>
</ul>

<p>下面是一个具体的文件，为了更简洁的展示，每一部分只保留了一小段内容：</p>

<pre><code class="language-text">ctarget:     file format elf64-x86-64


Disassembly of section .init:

0000000000400c48 &lt;_init&gt;:
  400c48:   48 83 ec 08             sub    $0x8,%rsp
  400c4c:   e8 6b 02 00 00          callq  400ebc &lt;call_gmon_start&gt;
  400c51:   48 83 c4 08             add    $0x8,%rsp
  400c55:   c3                      retq   

Disassembly of section .plt:

0000000000400cb0 &lt;strcpy@plt&gt;:
  400cb0:   ff 25 6a 33 20 00       jmpq   *0x20336a(%rip)        # 604020 &lt;_GLOBAL_OFFSET_TABLE_+0x38&gt;
  400cb6:   68 04 00 00 00          pushq  $0x4
  400cbb:   e9 a0 ff ff ff          jmpq   400c60 &lt;_init+0x18&gt;


Disassembly of section .text:

00000000004011ad &lt;main&gt;:
  4011bb:   be c5 1d 40 00          mov    $0x401dc5,%esi
  4011c0:   bf 0b 00 00 00          mov    $0xb,%edi
  4011c5:   e8 86 fb ff ff          callq  400d50 &lt;signal@plt&gt;
  4011cf:   bf 07 00 00 00       
  401384:   c3                      retq   


Disassembly of section .fini:

0000000000402d74 &lt;_fini&gt;:
  402d74:   48 83 ec 08             sub    $0x8,%rsp
  402d78:   48 83 c4 08             add    $0x8,%rsp
  402d7c:   c3                      retq   

</code></pre>

<p>其中<code>.fini</code>部分是有关进程结束的指令。<code>.init</code>部分是有关进程启动的指令，在<code>main()</code>函数执行前会执行。<code>PLT</code>代表<code>Procedure Linkage Table</code>(过程链接表),用来调用在链接阶段未知的外部函数/过程的，在运行时它会动态链接。所以最重要的内容都在<code>.text</code>部分中。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 过程]]></title>
    <link href="http://larryim.cc/procedure.html"/>
    <updated>2018-07-12T10:43:40+08:00</updated>
    <id>http://larryim.cc/procedure.html</id>
    <content type="html"><![CDATA[
<p><strong>过程</strong>(procedure)是软件中一种很重要的抽象。它提供了一种封装代码的方式，用一组制定的参数和一个可选的返回值实现了某这功能。然后，可以在程序中不同的地方调用这个函数。不同编程语言中，过程的形式多样：函数(function)、方法(method)、子例程(subroutine)、处理函数(handler)等等。</p>

<p>假设过程P调用过程Q，Q执行后返回到P，包含下面一个或多个机制：</p>

<ul>
<li>传递控制。在进入过程Q的时候，程序计数器必须被设置为Q的代码的起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址。</li>
<li>传递数据。P必须能够向Q提供一个或多个参数，Q必须能够向P返回一个值。</li>
<li>分配和释放内存。在开始时，Q可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间。</li>
</ul>

<h2 id="toc_0">1 运行时栈</h2>

<p>在函数调用时，往往使用了栈(<code>Stack</code>)这一数据结构。当x86-64过程需要的存储空间超出寄存器能够存放的大小时(意味着其实很多函数根本不需要帧栈)，就会在栈上分配空间，称为<strong>帧栈</strong>(stack frame)。</p>

<p>Current Stack Frame (“Top” to Bottom) contains:</p>

<ul>
<li>Argument build(参数构造区):
<ul>
<li>Parameters for function about to call</li>
<li>可以通过寄存器最多传递6个整形参数，超出6个部分就要通过栈来传递</li>
</ul></li>
<li>Local variables(局部变量):
<ul>
<li>寄存器不足够存放所有的本地数据</li>
<li>使用地址运算符&amp;，必须能够产生一个地址</li>
</ul></li>
<li>Saved register context(被保存的寄存器)
<ul>
<li>保存寄存器的值到栈中</li>
</ul></li>
<li>Old frame pointer (optional)</li>
</ul>

<p><img src="media/15312146721582/stack_frame.png" alt="stack_frame"/></p>

<h2 id="toc_1">参考资料</h2>

<p>Randal E B, David O H. 2015. Computer Systems: A programmer&#39;s Perspective, 3rd.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 虚拟内存]]></title>
    <link href="http://larryim.cc/virtual_memory_and_dynamic_memory_allocate.html"/>
    <updated>2018-01-20T07:09:22+08:00</updated>
    <id>http://larryim.cc/virtual_memory_and_dynamic_memory_allocate.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1 物理/虚拟寻址</h2>

<p>主存是由连续的<strong>字节大小</strong>的单元组成的数组，每字节都有一个唯一的<strong>物理地址</strong>(Physical Adress)。CPU使用物理地址访问内存的方式称为<strong>物理寻址</strong>(Physical adressing)。</p>

<p>早期的PC以及数字信号处理器等使用物理寻址，下面是物理寻址的示意图：</p>

<p><img src="media/15164033620970/physical_address.png" alt="physical_address"/></p>

<p>现代处理器通过生成一个<strong>虚拟地址</strong>(Virtual Address)来访问主存，虚拟地址经过<strong>地址翻译</strong>转换为物理地址。地址翻译由CPU内的<strong>内存管理单元</strong>(Memory Management Unit, <code>MMU</code>)负责.</p>

<p><img src="media/15164033620970/virtual_memory%20.png" alt="virtual_memory "/></p>

<p>虚拟内存充当着三个角色：</p>

<ul>
<li>作为缓存的工具，可以更有效率的使用内存：使用DRAM当做部分的虚拟地址空间的缓存</li>
<li>作为内存管理的工具，简化内存管理：每个进程都有统一的线性地址空间</li>
<li>作为内存保护的工具，分隔地址空间：进程的内存不会相互影响；用户程序不能访问保密的内核信息和代码</li>
</ul>

<p>下面一节具体讲解虚拟内存的这三个角色。</p>

<h2 id="toc_1">2 虚拟内存的三个角色</h2>

<h3 id="toc_2">2.1 作为缓存的工具</h3>

<p>可以把主存DRAM看作是虚拟内存的缓存，类似于L1、L2、L3高速缓存是DRAM内存的缓存。也就是说可以把虚拟内存看成是存储器层次结构的一部分。</p>

<p><img src="media/15164033620970/vm_as_cache.png" alt="vm_as_cache"/></p>

<p>和其他存储器层次结构中的缓存一样，较低层上的数据被分割成块，作为与较高层之间的传输单元。这里较低层是虚拟内存，分割成<strong>虚拟页</strong>(Virtual Page, VP)，虚拟页大小为\(P=2^p\)字节。类似的，这里的较高层，物理内存DRAM，被分割为<strong>物理页</strong>(Physical Page, PP)，大小也为\(P\)，也叫做页桢。</p>

<p>虚拟页的状态分为三种：</p>

<ul>
<li>未分配(Unallocated): 系统还未分配(创建)的页，不占用磁盘空间。</li>
<li>缓存的(Cached): 当前已缓存在物理内存中的已分配页。</li>
<li>未缓存的(Uncached): 未缓存在物理内存中的已分配页。</li>
</ul>

<p>那么具体是怎么判断一个虚拟页的状态呢？怎么知道虚拟页放在哪个物理页中呢？</p>

<p>物理内存中存在一个叫<strong>页表</strong>(page table)的数据结构，由操作系统负责。页表将虚拟页映射到物理页，每次内存管理单元中的<strong>地址翻译硬件</strong>将虚拟地址转换为物理地址时都会读取页表。</p>

<p>页表其实是一个页表条目(Page Table Entry, PTE)的数组。页表条目包含一个有效位(valid bit)和一个n位地址字段。</p>

<p><img src="media/15164033620970/page_table.jpg" alt="page_table"/></p>

<p>在虚拟内存的习惯说法中，DRAM缓存命中/不命中，特称为<strong>页命中</strong>/<strong>缺页</strong>(Page Fault)。</p>

<h3 id="toc_3">2.2 作为内存管理的工具</h3>

<p>操作系统为每个进程提供了一个独立的页表，也就是提供了一个独立的虚拟地址空间。多个虚拟页面可以映射到同一个共享物理页面上。虚拟内存简化了链接和加载、代码和数据共享、以及应用程序的内存分配。</p>

<h3 id="toc_4">2.3 作为内存保护的工具</h3>

<p>一方面，每个进程拥有独立的地址空间使得区分不同进程的私有内存变得容易。另一方面在每个页表条目PTE中，添加了额外的<strong>许可位</strong>(SUP, READ, WRITE, EXEC)来控制对一个虚拟页面内容的访问：</p>

<ul>
<li>SUP位表示进程是否运行在超级用户模式下才能访问</li>
<li>READ/WRITE位控制读和写的访问</li>
<li>EXEC位控制执行的访问</li>
</ul>

<p><img src="media/15164033620970/vm_protection.png" alt="vm_protection"/></p>

<p>如果违反许可条件，那么就触发段错误(segmentation fault)。</p>

<h2 id="toc_5">3 Linux虚拟内存系统</h2>

<p>Linux为每个进程维护了一个单独的虚拟地址空间。Linux将虚拟内存组织成一些<strong>区域</strong>的集合。一个区域就是已分配的虚拟内存的连续片。</p>

<p>Linux虚拟地址空间由如下几个区域组成：</p>

<ul>
<li>代码（<code>.text</code>）: 这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。</li>
<li>初始化数据段（<code>.data</code>）: 这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：<code>int val=&quot;100</code>。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用<code>exec</code>函数启动该程序时从源程序文件中读入。</li>
<li>未初始化数据段（<code>.bss</code>）: 位于这一段中的数据，内核在执行该程序前，将其初始化为0或者<code>null</code>。例如出现在任何函数之外的全局变量：int sum;</li>
<li>堆（<code>Heap</code>）: 这个段用于在程序中进行动态内存申请，例如经常用到的<code>malloc</code>，<code>new</code>系列函数就是从这个段中申请内存。</li>
<li>共享库(<code>Shared Library</code>): 用来存放像C标准库和数学哭这样的共享库的代码和数据的区域。</li>
<li>栈（<code>Stack</code>）: 函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中，具体见下面一节。</li>
<li>内核虚拟内存：包含内核中的代码和数据结构。</li>
</ul>

<p><img src="media/15089188725996/linux_virtual_memory.png" alt="linux_virtual_memory"/></p>

<h3 id="toc_6">3.1 Linux是如何组织虚拟内存的</h3>

<p>那么Linux具体是怎么组织虚拟内存的呢？Linux内核为系统中的每个进程维护一个单独的任务结构体(<code>task_struct</code>, 在<code>sched.h</code>头文件中)。<code>task_struct</code>中的元素包含运行该进程所需要的所有信息(PID、指向用户栈的指针、可执行目标文件的名字、以及程序计数器)。</p>

<p><img src="media/15164033620970/vm_linux.png" alt="vm_linux"/></p>

<p><code>task_struct</code>中的一个元素指向<code>mm_struct</code>，它描述了虚拟内存的当前状态。<code>pgd</code>指向第一级页表的基址，而<code>mmap</code>指向一个<code>vm_area_struct</code>(区域结构, 定义在<code>mm_types.h</code>)的链表。每个区域结构链表都描述了虚拟地址空间的一个区域，包含以下字段：</p>

<ul>
<li><code>vm_start</code>: 指向区域的起始处</li>
<li><code>vm_end</code>: 指向区域的结束处</li>
<li><code>vm_prot</code>: 描述着区域内包含的所有页的读写许可权限</li>
<li><code>vm_flags</code>: 描述进程共享/私有</li>
<li><code>vm_next</code>: 下一个区域结构</li>
</ul>

<h3 id="toc_7">3.2 Linux 缺页异常处理</h3>

<p>内存管理单元MMU在试图翻译某个虚拟地址A时，触发了一个缺页异常，引起缺页异常处理程序：</p>

<ul>
<li>虚拟地址A是合法的吗？-&gt; 段错误(segment fault)</li>
<li>试图进行的内存访问是合法的吗？ -&gt; 保护异常(也引发段错误)</li>
</ul>

<p><img src="media/15164033620970/linux_page_fault.png" alt="linux_page_fault"/></p>

<h2 id="toc_8">4 动态内存分配</h2>

<p>程序使用动态内存分配的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小。一般使用动态内存分配器(dynamic memeory allocator)来分配动态内存。</p>

<p>分配器根据哪个实体来负责释放已分配的块，分为两种：</p>

<ul>
<li>显示分配器(explicit allocator)：要求程序显示地释放任何已分配的块。例如C中的malloc/free，C++中的new/delete。</li>
<li>隐式分配器(implicit allocator): 除此之外，自动释放未使用的已分配块(垃圾收集，garbage collection)。</li>
</ul>

<h3 id="toc_9">4.2 显式分配器的要求和目标</h3>

<h4 id="toc_10">4.2.1 分配器的要求</h4>

<p>分配器有如下的要求：</p>

<ul>
<li>处理任意请求序列</li>
<li>立即相应请求</li>
<li>只使用堆</li>
<li>对齐块(对齐要求)</li>
<li>不修改已分配的块</li>
</ul>

<h4 id="toc_11">4.2.2 分配器的目标</h4>

<p>分配器试图最大化吞吐率和内存利用率</p>

<ul>
<li>最大化吞吐率(吞吐率：每个单位时间里完成的请求数)</li>
<li>最大化内存利用率</li>
</ul>

<p>最大化吞吐率和最大化利用率之间是相互 <u>牵制</u> 的，分配器设计的目标是在这两者之间找到一个适当的平衡。</p>

<p>造成利用率很低的主要原因是<strong>碎片</strong>(fragmentation)现象。当有效载荷比块要小时，发生<strong>内部碎片</strong>(Internal fragmentation)，引起的原因有：对齐等。</p>

<p><img src="media/15164033620970/internal_fragmentation.png" alt="internal_fragmentation"/></p>

<p>当即使有足够的累积的块内存，但是没有单一块能够满足需求时，发生<strong>外部碎片</strong>(external fragmentation)：</p>

<p><img src="media/15164033620970/external_fragmentation.png" alt="external_fragmentation"/></p>

<p>外部碎片还取决于将来的请求，例如上图，如果最后的p4请求4个字节呢？也就不会发生碎片。正因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大量的小空闲块。</p>

<h3 id="toc_12">4.3 实现方法</h3>

<ul>
<li>隐式空闲列表 Implicit Free List</li>
<li>显式空闲列表 Explicit Free List</li>
<li>分离式空闲列表 Segregated Free List</li>
</ul>

<h4 id="toc_13">4.3.1 隐式空闲列表</h4>

<p><img src="media/15164033620970/implicit_list.png" alt="implicit_list"/></p>

<p>隐式空闲链表优点是简单，缺点是操作开销大。因为无论是分配还是释放块，都需要对隐式空闲列表进行搜索，复杂度是\(O(n)\)，\(n\)是已分配块和空闲块的总数。</p>

<h4 id="toc_14">4.3.1 显式空闲列表</h4>

<p><img src="media/15164033620970/explict_list.png" alt="explict_list"/></p>

<h4 id="toc_15">4.3.1 分离式空闲列表</h4>

<h2 id="toc_16">5 C程序中常见的与内存有关的错误</h2>

<h4 id="toc_17">5.1 间接引用坏指针</h4>

<p>这是非常常见的例子，没有引用对应的地址，少了 &amp;</p>

<pre><code class="language-c">int val;
scanf(&quot;%d&quot;, val); // 正确应该是scanf(&quot;%d, &amp;val);
</code></pre>

<h4 id="toc_18">5.2 读未初始化的内存</h4>

<p><strong>堆内存是没有被初始化为0的</strong>：</p>

<pre><code class="language-c">/* return y = Ax */
int *matvec(int **A, int *x) {
    int *y = malloc(N * sizeof(int));
    int i, j;
    
    for (i = 0; i &lt; N; i++)
        for (j = 0; j &lt; N; j++)
            y[i] += A[i][j] * x[j];
    return y;
}
</code></pre>

<p>正确的方法是显式地将y[i]设置为0，或者使用<code>calloc</code>。</p>

<h4 id="toc_19">5.3 允许栈缓冲区溢出</h4>

<p>没有检查字符串的长度（经典的缓冲区溢出攻击也是利用相同的机制）</p>

<pre><code class="language-c">char s[8];
int i;
gets(s); /* stack buffer overflow, reads &quot;123456789&quot; from stdin */
</code></pre>

<h4 id="toc_20">5.4 引用不存在的变量</h4>

<p>尽管指针仍然指向一个合法的内存地址，但是已经不再指向一个合法的变量了。以后在程序中调用其他函数时，内存将重用它们的栈针。</p>

<pre><code class="language-c">int *foo() {
    int val;
    
    return &amp;val;
}
</code></pre>

<h4 id="toc_21">5.5 多次释放</h4>

<p>这个不用多说，不能重复搞两次</p>

<pre><code class="language-c">x = malloc(N * sizeof(int));
//  &lt;manipulate x&gt;
free(x);
y = malloc(M * sizeof(int));
//  &lt;manipulate y&gt;
free(x);
</code></pre>

<h4 id="toc_22">5.6 引用已经被释放的堆块中的数据</h4>

<p>同样是很明显的错误，不要犯</p>

<pre><code class="language-c">x = malloc(N * sizeof(int));
//  &lt;manipulate x&gt;
free(x);
//  ....
y = malloc(M * sizeof(int));
for (i = 0; i &lt; M; i++)
    y[i] = x[i]++;
</code></pre>

<h4 id="toc_23">内存泄漏</h4>

<p>5.7忘记释放已分配块：</p>

<pre><code class="language-c">foo() {
    int *x = malloc(N * sizeof(int));
    // ...
    return ;
}
</code></pre>

<p>或者只释放了数据结构的一部分：</p>

<pre><code class="language-c">struct list {
    int val;
    struct list *next;
};
foo() {
    struct list *head = malloc(sizeof(struct list));
    head-&gt;val = 0;
    head-&gt;next = NULL;
    //...
    free(head);
    return;
}
</code></pre>

<h2 id="toc_24">6 core i7内存系统</h2>

<p>Core i7在2008年冬季发布，基于全新Nehalem架构，它的芯片结构如下所示：</p>

<p><img src="media/15164033620970/15312857062358.png" alt=""/></p>

<p>抽象的内存系统：</p>

<p><img src="media/15164033620970/corei7.png" alt="corei7"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 存储器层次结构]]></title>
    <link href="http://larryim.cc/Computer_memory.html"/>
    <updated>2017-10-25T16:07:52+08:00</updated>
    <id>http://larryim.cc/Computer_memory.html</id>
    <content type="html"><![CDATA[
<p>存储器系统(memory system)是一个具有不同 <u>容量</u> 、 <u>成本</u> 和 <u>访问时间</u> 的存储设备的层次结构。</p>

<p><strong>局部性</strong>(locality)：具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。</p>

<h2 id="toc_0">1 存储技术</h2>

<h3 id="toc_1">1.1 RAM</h3>

<p>随机访问存储器(Random-Access Memory, RAM)分为两类：静态(SRAM)和动态(DRAM)的。SRAM比DRAM更快，但也贵得多。</p>

<h3 id="toc_2">1.2 磁盘</h3>

<p>磁盘是由盘片(platter)构成的。每个盘片如同切西瓜一样被“切”成一块一块的扇面，同时沿着半径的方向被划分成了一组同心圆(磁道, track)，每条磁道被扇面切成很多的扇形区域叫做扇区（sector, 扇区是从磁盘读出和写入信息的最小单位，包含相等数量的数据位，通常为512字节），不同盘片上的同半径磁道组成了柱面。</p>

<p><img src="media/15089188725996/15312767746205.jpg" alt=""/></p>

<p>磁盘的容量： 磁头数 × 磁道数 × 每道扇区数 × 每扇区字节数</p>

<h2 id="toc_3">2 局部性</h2>

<p>一个编写良好的计算机程序常常具有良好的局部性(locality)。也就是，它们倾向于引用邻近于其他最近引用过的数据项的数据项(空间局部性)，或者最近引用过的数据项本身(时间局部性)。</p>

<p>现代计算机系统的各个层次，从硬件到操作系统、再到应用程序，它们的设计都利用了局部性。</p>

<h2 id="toc_4">3 存储器层次结构 Memory Hierarchy</h2>

<p>一般而言，从高层往低层走，存储设备变得更慢、更便宜和更大。</p>

<p><img src="media/15128019428341/15128077150126.png" alt="存储器层次结构"/></p>

<h2 id="toc_5">虚拟内存 Virtual Memory</h2>

<p>虚拟内存(<code>Virtual Memory</code>)是一个抽象概念。它为每个进程提供了假象，即每个进程都在独占地使用内存。每个进程看到的内存都是一致的，称为虚拟地址空间<code>Virtual Address Space</code>.</p>

<p>虚拟内存在不同操作系统上有区别，以Linux系统为例,下面是<code>Linux  x86-64运行时的内存映像</code>。</p>

<p><img src="media/15089188725996/linux_virtual_memory.png" alt="linux_virtual_memory"/></p>

<p>虚拟地址空间由如下几部分组成：</p>

<ul>
<li>代码（<code>.text</code>）: 这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。</li>
<li>初始化数据段（<code>.data</code>）: 这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：<code>int val=&quot;100</code>。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用<code>exec</code>函数启动该程序时从源程序文件中读入。</li>
<li>未初始化数据段（<code>.bss</code>）: 位于这一段中的数据，内核在执行该程序前，将其初始化为0或者<code>null</code>。例如出现在任何函数之外的全局变量：int sum;</li>
<li>堆（<code>Heap</code>）: 这个段用于在程序中进行动态内存申请，例如经常用到的<code>malloc</code>，<code>new</code>系列函数就是从这个段中申请内存。</li>
<li>共享库(<code>Shared Library</code>): 用来存放像C标准库和数学哭这样的共享库的代码和数据的区域。</li>
<li>栈（<code>Stack</code>）: 函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中，具体见下面一节。</li>
<li>内核虚拟内存：包含内核中的代码和数据结构。</li>
</ul>

<p>注意：</p>

<ul>
<li>底部内存地址是最小的，越往上地址越大。</li>
<li>堆(正向增长)和栈(反向增长)的生长方向(箭头➡️所指方向)是相反的。</li>
</ul>

<p>下面是程序示意：</p>

<pre><code class="language-c"> #include&lt;stdio.h&gt;    
 #include &lt;malloc.h&gt;    
     
 void print(char *,int);    
 int main()    
{    
      char *s1 = &quot;abcde&quot;;  //&quot;abcde&quot;作为字符串常量存储在常量区 s1、s2、s5拥有相同的地址  
      char *s2 = &quot;abcde&quot;;    
      char s3[] = &quot;abcd&quot;;    
      long int *s4[100];    
      char *s5 = &quot;abcde&quot;;    
      int a = 5;    
      int b =6;//a,b在栈上，&amp;a&gt;&amp;b地址反向增长    
     
     printf(&quot;variables address in main function: s1=%p  s2=%p s3=%p s4=%p s5=%p a=%p b=%p \n&quot;,     
             s1,s2,s3,s4,s5,&amp;a,&amp;b);   
     printf(&quot;variables address in processcall:n&quot;);    
        print(&quot;ddddddddd&quot;,5);//参数入栈从右至左进行,p先进栈,str后进 &amp;p&gt;&amp;str    
     printf(&quot;main=%p print=%p \n&quot;,main,print);    
     //打印代码段中主函数和子函数的地址，编译时先编译的地址低，后编译的地址高main&lt;print    
 }    
  
 void print(char *str,int p)    
{    
     char *s1 = &quot;abcde&quot;;  //abcde在常量区，s1在栈上    
     char *s2 = &quot;abcde&quot;;  //abcde在常量区，s2在栈上 s2-s1=6可能等于0，编译器优化了相同的常量，只在内存保存一份    
     //而&amp;s1&gt;&amp;s2    
     char s3[] = &quot;abcdeee&quot;;//abcdeee在常量区，s3在栈上，数组保存的内容为abcdeee的一份拷贝    
     long int *s4[100];    
     char *s5 = &quot;abcde&quot;;    
     int a = 5;    
     int b =6;    
     int c;    
     int d;           //a,b,c,d均在栈上，&amp;a&gt;&amp;b&gt;&amp;c&gt;&amp;d地址反向增长    
     char *q=str;   
     int m=p;           
     char *r=(char *)malloc(1);    
     char *w=(char *)malloc(1) ;  // r&lt;w 堆正向增长    
    
     printf(&quot;s1=%p s2=%p s3=%p s4=%p s5=%p a=%p b=%p c=%p d=%p str=%p q=%p p=%p m=%p r=%p w=%p \n&quot;,    
            s1,s2,s3,s4,s5,&amp;a,&amp;b,&amp;c,&amp;d,&amp;str,q,&amp;p,&amp;m,r,w);   
     /* 栈和堆是在程序运行时候动态分配的，局部变量均在栈上分配。 
        栈是反向增长的，地址递减；malloc等分配的内存空间在堆空间。堆是正向增长的，地址递增。   
        r,w变量在栈上(则&amp;r&gt;&amp;w)，r,w所指内容在堆中(即r&lt;w)。*/   
 }    
   
</code></pre>

]]></content>
  </entry>
  
</feed>
