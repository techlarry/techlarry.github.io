<!doctype html>
<html class="no-js" lang="en">
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?fdc936c9f5a3b72177541183cdeb8cb3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        <li id=""><a target="_self" href="category.html">Category</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        
        <li><a target="_self" href="category.html">Category</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="C/C++.html">C/C++</a></li>
        
            <li><a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html">PythonÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">PythonÁâπÊÄß</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">Êú∫Âô®Â≠¶‰π†</a></li>
        
            <li><a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html">PythonÁßëÂ≠¶ËÆ°ÁÆó‰∏âÁª¥ÂèØËßÜÂåñ</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Latex.html">Latex</a></li>
        
            <li><a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html">Êìç‰ΩúÁ≥ªÁªü</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux Á≥ªÁªüÁºñÁ®ã</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">Êï∞ÊçÆÂ∫ì</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Data%20Science.html">Data Science</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="cross-validation.html">
                
                  <h1>Cross-Validation</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p><code>cross-validation</code> splits the training set into complementary subsets, and each model is trained against a different combination of these subsets and validates against the remaining parts. Once the model type and hyperparameters on the full training set, and the generalized error is measured on the test set.</p>

<p><img src="media/15038841395536/15042349862270.jpg" alt="demo of cross-validation"/></p>

<p>A great convenient is to use Scikit-Learn&#39;s <code>cross-validation</code> feature. The following code performs <code>K-fold cross-validation</code>: it randomly splits the training set into 10 distinct subsets called <code>folds</code>, then it trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds.</p>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score
scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                             scoring=&quot;neg_mean_squared_error&quot;, cv=10)
    rmse_scores = np.sqrt(-scores)
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/28</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15037532856914.html">
                
                  <h1>K-means clustering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Optimization objective:<br/>
\[J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)=\frac{1}{m}\sum^m_{i=1}\rVert x^{(i)}-\mu_{c^{(i)}}\rVert^2\]</p>

<p>Randomly initialize \(K\) cluster centroid \(\mu_1, \mu_2,...,\mu_k\)</p>

<p>Repeat{<br/>
    for \(i=1\) to \(m\)<br/>
    \( c^{(i)}=\) index (from 1 to \(K\) of cluster centroid closest to \(x^{(i)}\)</p>

<h3 id="toc_0">Random initialization</h3>

<p>Randomly pick \(K\) training examples, and set \(\mu_1, \mu_2,...,\mu_k\) equal to these \(K\) examples.</p>

<p>\[\text{For }i = 1 \text{  to  } 100 {\\<br/>
\text{    Randomly initialize K cluster centroid } \mu_1, \mu_2,...,\mu_k\\<br/>
\text{    Run K-means}\\<br/>
\text{    Compute cost function (distortion)}\\<br/>
}\\<br/>
\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/26</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15036679491914.html">
                
                  <h1>Feature Engineering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>As the saying goes: garbage in, garbage out. Your system will only be capable of learn‚Äê ing if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. This process, called feature engineering, involves:</p>

<ul>
<li><code>Feature selection</code>: selecting the most useful features to train on among existing features.</li>
<li><code>Feature extraction</code>: combining existing features to produce a more useful one (as we saw earlier, dimensionality reduction algorithms can help).</li>
<li><code>Creating new features</code> by gathering new data.</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/25</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="support-vector-machine.html">
                
                  <h1>Machine Learning(7): Support Vector Machines</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Training Objective</h2>

<p>The smaller the weight vector <code>w</code>, the larger the margin. So we want to minimize \(\lVert w\rVert\) to get a large margin.</p>

<h3 id="toc_1">Hard Margin</h3>

<p>If we also want to avoid any margin violation (<code>hard margin</code>), then we need the decision function to be greater than 1 for all positive trainig instances, and lower than  -1 for negative training instances. If we define \(t^{(i)} = -1\) for negative instances (if \(y^{(i)}&gt;0\)) and \(t^{(i)}=1\) for positive instances (if \(y^{(i)}=1\)), then we can express this constraint as \(t^{(i)}(w^T\cdot x^{(i)}+b) \le 1\) for all instances. </p>

<p>** Hard Margin linear SVM classifier objective**</p>

<p>\[<br/>
\min_{w,b} \frac{1}{2}w^T\cdot w \\<br/>
\text{subject to } t^{(i)}(w^T\cdot x^{(i)}+b) \le 1  \quad for \quad i =1,2,...,m<br/>
\]</p>

<h3 id="toc_2">Soft Margin</h3>

<p>To get the soft margin objective, we need to introduce a <code>slack variable</code> \(\zeta^(i)\le0\) for each instance: \(\zeta^{(i)}\) measures how much the \(i^{th}\) instance is allowed to violate the margin. We now have two conflicting objectives: making the slack variables as small as possible to reduce the margin violations, and makeing \(\frac{1}{2}w^T\cdot w \) as small as possible to increase the margin.</p>

<p>** Soft Margin linear SVM classifier objective**</p>

<p>\[<br/>
\min_{w,b} \frac{1}{2}w^T\cdot w + C\sum^m_{i=1}\zeta^{(i)}\\<br/>
\text{subject to } t^{(i)}(w^T\cdot x^{(i)}+b) \le 1 - \zeta^{(i)} \quad for \quad i =1,2,...,m<br/>
\]</p>

<h2 id="toc_3">Implementation</h2>

<pre><code class="language-python">import numpy as np
from sklearn import datasets
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
import matplotlib.pyplot as plt
</code></pre>

<h2 id="toc_4">Soft Margin Classification</h2>

<pre><code class="language-python">
# load data sets
iris = datasets.load_iris()
x = iris[&#39;data&#39;][:,(2,3)] # petal length, petal width
y = (iris[&#39;target&#39;] == 2).astype(np.float64) # Iris-Virginica
</code></pre>

<pre><code class="language-python">%matplotlib inline
plt.scatter(x[:,0], x[:,1], c=y)
</code></pre>

<pre><code>&lt;matplotlib.collections.PathCollection at 0x110ecf0f0&gt;
</code></pre>

<p><img src="media/15036619229303/output_4_1.png" alt="png"/></p>

<pre><code class="language-python"># plot decision boundary
def make_meshgrid(x, y, h=.02):
    &quot;&quot;&quot;Create a mesh of points to plot in

    Parameters
    ----------
    x: data to base x-axis meshgrid on
    y: data to base y-axis meshgrid on
    h: stepsize for meshgrid, optional

    Returns
    -------
    xx, yy : ndarray
    &quot;&quot;&quot;
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(model, xx, yy, **params):
    &quot;&quot;&quot;Plot the decision boundaries for a classifier.

    Parameters
    ----------
    ax: matplotlib axes object
    clf: a classifier
    xx: meshgrid ndarray
    yy: meshgrid ndarray
    params: dictionary of params to pass to contourf, optional
    &quot;&quot;&quot;
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = plt.contourf(xx, yy, Z, **params)
    return out
</code></pre>

<pre><code class="language-python"># svm
svm_clf = Pipeline([
    (&#39;scalar&#39;, StandardScaler()),
    (&#39;linear_svc&#39;, LinearSVC(C=1, loss=&#39;hinge&#39;))])
svm_clf.fit(x, y)
</code></pre>

<pre><code>Pipeline(steps=[(&#39;scalar&#39;, StandardScaler(copy=True, with_mean=True, with_std=True)), (&#39;linear_svc&#39;, LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss=&#39;hinge&#39;, max_iter=1000, multi_class=&#39;ovr&#39;,
     penalty=&#39;l2&#39;, random_state=None, tol=0.0001, verbose=0))])
</code></pre>

<pre><code class="language-python">plot_contours(svm_clf, xx, yy,
              cmap=plt.cm.coolwarm, alpha=0.8)
plt.hold
plt.scatter(x[:,0], x[:,1], c=y)
</code></pre>

<pre><code>&lt;matplotlib.collections.PathCollection at 0x111e5c128&gt;
</code></pre>

<p><img src="media/15036619229303/output_7_1.png" alt="png"/></p>

<h2 id="toc_5">Nonelinear SVM Classification</h2>

<p>One approach to handling nonlinear datasets is to add more features, such as polynomial features. In some cases result in a linearly separable dataset.</p>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures

polynomial_svm_clf = Pipeline([
    (&#39;poly_features&#39;, PolynomialFeatures(degree=3)),
    (&#39;scaler&#39;, StandardScaler()),
    (&#39;svm, clf&#39;, LinearSVC(C=10, loss=&#39;hinge&#39;))
])

polynomial_svm_clf.fit(x, y)
</code></pre>

<pre><code>Pipeline(steps=[(&#39;poly_features&#39;, PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), (&#39;scaler&#39;, StandardScaler(copy=True, with_mean=True, with_std=True)), (&#39;svm, clf&#39;, LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss=&#39;hinge&#39;, max_iter=1000, multi_class=&#39;ovr&#39;,
     penalty=&#39;l2&#39;, random_state=None, tol=0.0001, verbose=0))])
</code></pre>

<pre><code class="language-python">xx, yy = make_meshgrid(x[:,0], x[:,1])
plot_contours(polynomial_svm_clf, xx, yy,
              cmap=plt.cm.coolwarm, alpha=0.8)
plt.hold
plt.scatter(x[:,0], x[:,1], c=y)
</code></pre>

<pre><code>&lt;matplotlib.collections.PathCollection at 0x112f0a470&gt;
</code></pre>

<p><img src="media/15036619229303/output_10_1.png" alt="png"/></p>

<h2 id="toc_6">Gaussian RBF Kernal</h2>

<p>Define the similarity function to be the Gaussian Radial Basis Function (RBF):</p>

<p>\[\phi(x, \gamma) = exp(-\gamma \lVert x-l\rVert ^2)\]</p>

<p>Let&#39;s try the Gaussian RBF kernel using the <code>SVC</code> class:</p>

<pre><code class="language-python">rbf_kernel_svm_clf = Pipeline([
    (&#39;svm_clf&#39;, SVC(kernel=&#39;rbf&#39;, gamma=0.1, C=0.1))
])
rbf_kernel_svm_clf.fit(x,y)
</code></pre>

<pre><code>Pipeline(steps=[(&#39;svm_clf&#39;, SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))])
</code></pre>

<pre><code class="language-python">plot_contours(rbf_kernel_svm_clf, xx, yy,
              cmap=plt.cm.coolwarm, alpha=0.8)
plt.hold
plt.scatter(x[:,0], x[:,1], c=y)
</code></pre>

<pre><code>&lt;matplotlib.collections.PathCollection at 0x114174518&gt;
</code></pre>

<p><img src="media/15036619229303/output_13_1.png" alt="png"/></p>

<p>Other kernals such as <code>sigmoid</code>, <code>precomputed</code> are also used. With so many kernels to choose from, as a rule of thumb, you should always try the linear kernel first, especailly if the training set is very large or if it has plenty of features. If the training set is not too large, you should try the Gaussian RBF kernel as well; it works well in most cases.</p>

<h2 id="toc_7">Complexity</h2>

<p>Time complexity of algorithms above:</p>

<ul>
<li><code>LinearSVC</code>: \(O(m\times n)\)</li>
<li><code>SGDClassifier</code>: \(O(m\times n)\)</li>
<li><code>SVC</code>: \(O(m^2\times n) \text{ to } O(m^3\times n)\)</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/25</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15035780907547.html">
                
                  <h1>TensorFlow(5): Vector and Matrix Product in Numpy and TensorFlow</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Numpy</h2>

<p>Following are common vector and matrix product operations in Numpy, they are quite simple and straightforward:</p>

<ul>
<li><p>Inner Product   \(\quad a^Tb\quad \):  <code>np.inner()</code></p></li>
<li><p>Outer Product  \(\quad ab^T\quad \):  <code>np.outer()</code></p></li>
<li><p>Dot Product  \(\quad a \cdot b = \sum a_ib_i\quad \): <code>np.dot()</code></p></li>
<li><p>Elementwise Product  \(\quad c_i = a_ib_i\quad \): <code>np.multiply()</code></p></li>
</ul>

<p>Note: inner product is defined on vector spaces over a field ùïÇ (finite or infinite dimensional). Dot product refers specifically to the product of vectors in \(‚Ñù^n\)</p>

<p>The difference between the following implementations of the dot/inner/outer/elementwise product are demonstrated as follows:</p>

<pre><code class="language-python">W = np.ones((2, 7), dtype=&#39;float32&#39;)
x1 = [9, 2, 5, 0, 0, 7, 5]
x2 = [9, 2, 2, 9, 0, 9, 2]
print(&#39;vector dot product&#39;, np.dot(x1,x2)) # dot product
print(&#39;inner&#39;, np.inner(x1,x2)) # inner product
print(&#39;outter&#39;, np.outer(x1,x2)) # outter product
print(&#39;element-wsie&#39;, np.multiply(x1,x2)) # Element-wise product
print(&#39;matrix dot product&#39;, np.dot(W, x1)) # dot product
</code></pre>

<pre><code>dot for vector 168
inner 168
outter [[81 18 18 81  0 81 18]
 [18  4  4 18  0 18  4]
 [45 10 10 45  0 45 10]
 [ 0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [63 14 14 63  0 63 14]
 [45 10 10 45  0 45 10]]
element-wsie [81  4 10  0  0 63 10]
dot for matrix [ 28.  28.]
</code></pre>

<h2 id="toc_1">TensorFlow</h2>

<p>Vector inner/outer Product are a bit complex in TensorFlow. </p>

<pre><code class="language-python">import tensorflow as tf
import numpy as np

x = tf.Variable([[1, -2, 3]], tf.float32, name=&#39;x&#39;)
y = tf.Variable([[-1, 2, -3]], tf.float32, name=&#39;y&#39;)

## inner product
inner_product1 = tf.reduce_sum(tf.multiply(x, y))
inner_product2 = tf.matmul(x, y, transpose_a=False, transpose_b= True) # different from inner_product1

## outer product
outer_product2 = tf.matmul(x, y, transpose_a= True)

## matrix dot product
X = tf.constant(np.random.randn(3,3), name=&#39;X&#39;)
W = tf.constant(np.random.randn(3,3), name=&#39;W&#39;)
matrix_product = tf.matmul(W, X)

sess = tf.InteractiveSession()
init_op = tf.global_variables_initializer()

# run
sess.run(init_op)
print(sess.run(inner_product1))
print(sess.run(inner_product2))
print(sess.run(outer_product2))
print(sess.run(matrix_product))
</code></pre>

<pre><code>-14
[[-14]]
[[-1  2 -3]
 [ 2 -4  6]
 [-3  6 -9]]
[[-0.88722509 -0.94128018 -2.1999658 ]
 [-0.67967623  1.33193446 -0.75612585]
 [ 0.31741623  1.3271727  -0.04311113]]
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/24</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Tensorflow.html'>Tensorflow</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_5.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_7.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">‰ªñÂ±±‰πãÁü≥ÔºåÂèØ‰ª•ÊîªÁéâ</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="C/C++.html"><strong>C/C++</strong></a>
        
            <a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html"><strong>PythonÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>PythonÁâπÊÄß</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>Êú∫Âô®Â≠¶‰π†</strong></a>
        
            <a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>PythonÁßëÂ≠¶ËÆ°ÁÆó‰∏âÁª¥ÂèØËßÜÂåñ</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Latex.html"><strong>Latex</strong></a>
        
            <a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html"><strong>Êìç‰ΩúÁ≥ªÁªü</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux Á≥ªÁªüÁºñÁ®ã</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>Êï∞ÊçÆÂ∫ì</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Data%20Science.html"><strong>Data Science</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="C++baics.html">C++ Basics</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="C_language.html">C Basics</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="hardware/software_interface.html">Hardware/Software Interface</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15089188725996.html">Linux ÂÜÖÂ≠òÂ∏ÉÂ±Ä</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15089186263565.html">Valgrind</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
