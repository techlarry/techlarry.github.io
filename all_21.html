<!doctype html>
<html class="no-js" lang="en">
  <head>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?fdc936c9f5a3b72177541183cdeb8cb3";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="wiki">WIKI</a></li>
        
        <li id=""><a target="_blank" href="note-os">NOTE-OS</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="wiki">WIKI</a></li>
        
        <li><a target="_blank" href="note-os">NOTE-OS</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="programming_language.html">编程语言</a></li>
        
            <li><a href="data_structure_and_algorithm.html">数据结构和算法</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">文献阅读</a></li>
        
            <li><a href="Tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15002564768282.html">
                
                  <h1>Database System Concept (1): Introduction</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>A <code>database-management system</code> (DBMS，数据库管理系统) is a collection of interrelated data and a set of programs to access those data.  The collection of data, usually referred to as the <code>database</code>. The primary goal of a DBMS is to provide a way to store and retrieve database information that is both <code>convenient</code> and <code>efficient</code>.</p>

<h2 id="toc_0">Purpose of Database System</h2>

<p>Keeping organizational information in a file-processing system has a number of major disadvantages:</p>

<ul>
<li>Data redundancy and inconsistency
<ul>
<li>Users of one program may be unaware of potentially useful data held by other programs.</li>
</ul></li>
<li>Difficulty in accessing data
<ul>
<li>Programs are written to satisfy particular functions.<br/></li>
<li>Any new requirement needs a new program.</li>
</ul></li>
<li>Data isolation
<ul>
<li>Same data is held by different programs </li>
<li>Each program maintains its own set of data</li>
</ul></li>
<li>Integrity problems</li>
<li>Atomicity problems</li>
<li>Concurrent-access anomalies</li>
<li>Security problems</li>
</ul>

<h2 id="toc_1">View of data</h2>

<h3 id="toc_2">Data Abstraction</h3>

<p>The need for efficiency has led designers to use complex data structures to represent data in the database.</p>

<ul>
<li><code>Physical level</code>. The lowest level of abstraction <em>how</em> the data are actually stored</li>
<li><code>Logical level</code>. The next-higher level of abstraction describes <em>what</em> data are stored in the database, and what relationships exist among those data. Each record is described by a type definition, and the interrelationship of these record types is defined as well.</li>
<li><code>View level</code>. The highest level of abstraction describes only part of the entire data. The system may provide many views for the same database. Computer users see a set of application programs that hide details of the data types.</li>
</ul>

<p><img src="media/15002564768282/Screen%20Shot%202017-07-17%20at%2010.08.36%20AM.png" alt="The three views of data abstraction"/></p>

<h3 id="toc_3">Instances and Schemas</h3>

<ul>
<li><code>Instance</code>: the collection of information stored in the database at a particular moment</li>
<li><code>schema</code>: the overall design of the database.</li>
</ul>

<p>Database systems have several schemas, partitioned according to the levels of abstraction. The <code>Physical schema</code> describes the database design at the physical level, while the <code>logical schema</code> describes the database design at the logical level.</p>

<p>Applications programs are said to exhibit <code>physical data independence</code> if they do not depend on the <code>physical schema</code>, and thus need not be rewritten if the physical schema changes.</p>

<h3 id="toc_4">Data Models</h3>

<p><code>Data Model</code>(数据库): a collection of conceptual tools for describing data, data relationships, data semantics, and consistency constraints.</p>

<ul>
<li><code>Relational Model</code>(关系数据库)</li>
<li><code>Entity-Relationship Model</code> (实体对象模型)</li>
<li><code>Object-Based Data Model</code> (基于对象的数据模型)</li>
<li><code>Semistructed Data Model</code></li>
</ul>

<h2 id="toc_5">Database Language</h2>

<p>A database system provides a <code>data-definition language</code>(DDL) to specify the database schema and a <code>data-manipulation language</code>(DML) to express database queries and updates.</p>

<h2 id="toc_6">Data Storage and Querying</h2>

<p>A database system is partitioned into modules that deal with each of the responsibilities of the overall system. The functional components of a database system can be broadly divided into the <code>storage manager</code> and the <code>query processor</code></p>

<p>The <code>storage manager</code> is the component of a database system that provides the interface between the low-level data stored in the database and the application programs and queries submitted to the system. it is responsible for storing, retrieving, and updating data in the database. The storage manager translates the various DML statement into low-level file-system commands.</p>

<p>The <code>query processor</code> includes:</p>

<ul>
<li><code>DDL interpreter</code>, which interprets DDL statements and records the definitions in the data dictionary.</li>
<li><code>DML compiler</code>, which translates DML statements in a query language into an evaluation plan consisting of low-level instructions that the query evaluation engine understands.</li>
<li><code>Query evaluation engine</code>, which executes low-level instructions generated by the DML compiler.</li>
</ul>

<h2 id="toc_7">Transaction management</h2>

<p><code>Transaction management</code> ensures that the database remains in a consistent (correct) state despite system failures. The transaction manager ensures that concurrent transaction executions proceed without conflicting.</p>

<h2 id="toc_8">Database Architecture</h2>

<p>The architecture of a database system is greatly influenced by the underlying computer system on which the database system runs. Database system can be centralized, or client-server, where one server machine executes work on behalf of multiple client machines.</p>

<p><img src="media/15002564768282/Screen%20Shot%202017-07-17%20at%2010.55.20%20AM.png" alt="System Structure"/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/7/17</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%95%B0%E6%8D%AE%E5%BA%93.html'>数据库</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="priority_queue.html">
                
                  <h1>Priority queue</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p><strong>A priority queue</strong>(优先队列) is an ADP which likes a regular queue or stack , but where additionally each element has a <code>priority</code> associated with it. In a priority queue, an element with high priority is served before an element with low priority. If two elements have the same priority, they are served according to their order in the queue.</p>

<p>A priority queue must at least support the following operations:</p>

<ul>
<li><code>insert_with_priority</code>: add an element to the queue with an associated priority.</li>
<li><code>pull_highest_priority_element</code>: remove the element from the queue that has the highest priority, and return it.</li>
<li><code>peek</code> :return the highest-priority element but does not modify the queue</li>
</ul>

<h2 id="toc_0">Naive Implementation</h2>

<p>There are a variety of simple, usually inefficient, ways to implement a priority queue. They provide an analogy to help one understand what a priority queue is. For instance, one can keep all the elements in an unsorted list. Whenever the highest-priority element is requested, search through all elements for the one with the highest priority. (In big O notation: \(O(1)\) insertion time, \(O(n)\) pull time due to search.)</p>

<h2 id="toc_1">Heap Implementation</h2>

<pre><code class="language-python">class PriorityQueue:
    def __init__(self):
        self.heapArray = [(0, 0)]
        self.currentSize = 0

    def buildHeap(self, alist):
        &quot;&quot;&quot;
        &quot;&quot;&quot;从一个包含元素的列表创建新堆&quot;&quot;&quot;
        :param alist: a list
        &quot;&quot;&quot;
        self.currentSize = len(alist)
        self.heapArray = [(0, 0)]
        for i in alist:
            self.heapArray.append(i)
        i = len(alist) // 2
        while (i &gt; 0):
            self.percDown(i)
            i = i - 1

    def percDown(self, i):
        &quot;&quot;&quot;
        Percolate the ith node down the tree
        &quot;&quot;&quot;
        while (i * 2) &lt;= self.currentSize:
            mc = self.minChild(i)
            if self.heapArray[i][0] &gt; self.heapArray[mc][0]:
                tmp = self.heapArray[i]
                self.heapArray[i] = self.heapArray[mc]
                self.heapArray[mc] = tmp
            i = mc

    def minChild(self, i):
        &quot;&quot;&quot;
        Find the smallest child
        &quot;&quot;&quot;
        if i * 2 &gt; self.currentSize:
            return -1
        else:
            if i * 2 + 1 &gt; self.currentSize:
                return i * 2
            else:
                if self.heapArray[i * 2][0] &lt; self.heapArray[i * 2 + 1][0]:
                    return i * 2
                else:
                    return i * 2 + 1

    def percUp(self, i):
        &quot;&quot;&quot;
        Percolate the ith node up the tree
        &quot;&quot;&quot;
        while i // 2 &gt; 0:
            if self.heapArray[i][0] &lt; self.heapArray[i // 2][0]:
                tmp = self.heapArray[i // 2]
                self.heapArray[i // 2] = self.heapArray[i]
                self.heapArray[i] = tmp
            i = i // 2

    def add(self, k):
        self.heapArray.append(k)
        self.currentSize = self.currentSize + 1
        self.percUp(self.currentSize)

    def delMin(self):
        &quot;&quot;&quot;
        delete the min-vertex of heap array, which always in the first position.
        &quot;&quot;&quot;
        retval = self.heapArray[1][1]
        self.heapArray[1] = self.heapArray[self.currentSize]
        self.currentSize = self.currentSize - 1
        self.heapArray.pop()
        self.percDown(1)
        return retval

    def isEmpty(self):
        &quot;&quot;&quot;
        return true if the heapArray is empty
        &quot;&quot;&quot;
        if self.currentSize == 0:
            return True
        else:
            return False

    def decreaseKey(self, val, amt):
        &quot;&quot;&quot;
        Decrease the key of the specific vertex (here, val)

        First, find its position in the heapArray: myKey
        Second, set its position to the right
        &quot;&quot;&quot;
        done = False
        i = 1
        myKey = 0
        while not done and i &lt;= self.currentSize:
            if self.heapArray[i][1] == val:
                done = True
                myKey = i
            else:
                i = i + 1
        if myKey &gt; 0:
            self.heapArray[myKey] = (amt, self.heapArray[myKey][1])
            self.percUp(myKey)

    def __contains__(self, vtx):
        &quot;&quot;&quot;
        Built-in Magic method
        &quot;&quot;&quot;
        for pair in self.heapArray:
            if pair[1] == vtx:
                return True
        return False
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/7/12</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='data_structure_and_algorithm.html'>数据结构和算法</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="recursion_iteration.html">
                
                  <h1>Recursion Iteration Performace</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>The performance of <code>Recursion</code> v.s. <code>Iteration</code> depends on the language being used.</p>

<p>In Java, C, and Python, <code>recursion</code> is fairly expensive compared to <code>iteration</code> (in general) because it requires the allocation of a new <code>stack frame</code>. In some C compilers, one can use a compiler flag to eliminate this overhead, which transforms certain types of recursion (actually, certain types of tail calls) into jumps instead of function calls.</p>

<h2 id="toc_0">Stack Frame</h2>

<p>When a function is called in Python, a <code>stack frame</code> is allocated to handle the local variables of the function. When the function returns, the return value is left on the top of the stack for the calling function to access.</p>

<p>The stack frame provide a <code>scope</code> for the variables used by the function. Even though we are calling the same function over and over, each call creates a new scope for the variables that are local to the function.</p>

<h3 id="toc_1">Get Stack Frame</h3>

<p>The <code>inspect</code> module in <code>python</code> provides several useful functions to help get information about live objects such as modules, classes, methods, functions, tracebacks, <code>frame objects</code>, and code objects.</p>

<pre><code class="language-python">import inspect

def f1():
    names = []
    # inpect.currentframe
    # Return the frame object for the caller’s stack frame.
    frame = inspect.currentframe()
  
    ## Keep moving to next outer frame
    while True:
        try:
            frame = frame.f_back # next outer frame object (this frame’s caller)
            name = frame.f_code.co_name # name with which this code object was defined
            names.append(name)
        except:
            break
    return names
    
def f2():
   return f1()

def f3():
   return f2()

def f4():
   return f3()

print(f4())
</code></pre>

<p>The results shows:</p>

<pre><code class="language-python">[&#39;f2&#39;, &#39;f3&#39;, &#39;f4&#39;, &#39;&lt;module&gt;&#39;]
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/7/17</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Python%E7%89%B9%E6%80%A7.html'>Python特性</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="overfiting_and_normalization.html">
                
                  <h1>Machine Learning (4): Overfitting and normalization</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">The problem of Overfitting</a>
</li>
<li>
<a href="#toc_1">Regularized Linear Regression</a>
<ul>
<li>
<a href="#toc_2">Normal Equation</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">Regularized Logistic Regression</a>
</li>
</ul>


<h2 id="toc_0">The problem of Overfitting</h2>

<p><strong>Underfitting</strong>, or <strong>high bias</strong>, is when the form of our hypothesis function \(h\) maps poorly to the trend of the data. It is usually caused by a function that is too simple or uses too few features. </p>

<p><strong>Overfitting</strong>, or <strong>high variance</strong>, is caused by a hypothesis function that fits the available data but does not generalize well to predict new data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.</p>

<p>There are two main options to address the issue of overfitting:</p>

<ol>
<li><p><strong><em>Reduce the number of features</em></strong>:<br/>
Manually select which features to keep.<br/>
(Use a model selection algorithm).</p></li>
<li><p><strong><em>Regularization</em></strong><br/>
Keep all the features, but reduce the magnitude of parameters \(\theta_j\). Regularization works well when we have a lot of slightly useful features.</p></li>
</ol>

<p><img src="media/14985711297859/14987109337751.png" alt="sd"/></p>

<p>The figure above shows the Underfitting, Normal, Overfitting.</p>

<h2 id="toc_1">Regularized Linear Regression</h2>

<p>We regularize all of theta parameters in a single summation as:</p>

<p>\[J(\theta)= \dfrac{1}{2m}[ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2]\]</p>

<p>where the \(\lambda\), or lambda, is the <strong>regularization parameter</strong>. It determines how much the costs of our theta parameters are inflated.  If \(\lambda\) is chosen to be too large, it may smooth out the function too much and cause underfitting. </p>

<p><strong>Note that you should not regularize the parameter \(\theta_0\)</strong>.</p>

<p>The corresponding gradient descent is</p>

<p>\[\begin{align*} &amp; \text{Repeat}\ \lbrace \newline &amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline &amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline &amp; \rbrace \end{align*}\]</p>

<p>With some manipulation our update rule can also be represented as:<br/>
\[\theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\]</p>

<h3 id="toc_2">Normal Equation</h3>

<p>To add in regularization, the equation is the same as our original, except that we add another term inside the parentheses:</p>

<p>\[\begin{align*}&amp; \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline&amp; \text{where}\ \ L = \begin{bmatrix} 0 &amp; &amp; &amp; &amp; \newline &amp; 1 &amp; &amp; &amp; \newline &amp; &amp; 1 &amp; &amp; \newline &amp; &amp; &amp; \ddots &amp; \newline &amp; &amp; &amp; &amp; 1 \newline\end{bmatrix}\end{align*}\]</p>

<p>Recall that if \(m &lt; n\), then \(XTX\) is non-invertible. However, when we add the term \(\lambda L\), then \(XTX + \lambda L\) becomes invertible.</p>

<h2 id="toc_3">Regularized Logistic Regression</h2>

<p>We regularize all of \(\theta\) parameters in a single summation as:</p>

<p>\[ J(\theta) = -\dfrac{1}{m} \sum_{i=1}^m[ y ^{(i)}\log(h_\theta(x^{(i)}))+(1-y^{(i)}) \log(1-h_\theta(x^{(i)}))]+ \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2\]</p>

<p>The corresponding gradient descent is<br/>
\[\theta_j:=\theta_j-\frac{\alpha}{m}\Sigma^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j+\frac{\alpha\lambda}{m}\theta_j\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/6/29</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="linear_regression_with_multiple_variables.html">
                
                  <h1>Machine Learning (2): Linear Regression with Multiple Variables</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Multiple Features (variables)</a>
</li>
<li>
<a href="#toc_1">Gradient descent</a>
<ul>
<li>
<a href="#toc_2">Feature Scaling</a>
</li>
<li>
<a href="#toc_3">Learning rate</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">Computing Parameters Analytically</a>
<ul>
<li>
<a href="#toc_5">Normal equation:</a>
</li>
<li>
<a href="#toc_6">Gradient descent v.s. Normal equation</a>
</li>
<li>
<a href="#toc_7">Normal Equation Non-invertible</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">Multiple Features (variables)</h2>

<p>Notation:<br/>
\(m\) = the number of training examples<br/>
\(n\) = the number of features<br/>
\(x^{(i)}\)  = the input (feature) of \(i^{th}\) training example<br/>
\(x^{(i)}_j\) =  value of feature \(j\) of \(i^{th}\) training example</p>

<p>The multivariable form of the hypothesis function accommodating these multiple features is as follows:</p>

<p>\[h_θ(x)=θ_0+θ_1x_1+θ_2x_2+θ_3x_3+⋯+θ_nx_n=\theta^Tx\] (\(n+1\)- dimensional vector)</p>

<p>For convenience of notation, define \(x_0=1\)</p>

<h2 id="toc_1">Gradient descent</h2>

<p><strong>Hypothesis</strong>: <br/>
\[h_\theta(x) = \theta^Tx\]</p>

<p><strong>Parameters</strong>:<br/>
\[\theta\]</p>

<p><strong>Cost Function</strong>:<br/>
\[J(\theta)=\frac{1}{2m}\Sigma^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2\]</p>

<p><strong>Gradient descent</strong>:<br/>
Repeat until converge{</p>

<p>\(\theta_j := \theta_j -\alpha\frac{\partial}{\partial \theta_j}J(\theta)=\theta_j -\alpha\frac{1}{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\)  (simultaneously update for every j= 0,1,...,n)</p>

<h3 id="toc_2">Feature Scaling</h3>

<p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because \(\theta\) will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p>

<p><strong>Idea: Make sure features are on a similar scale.</strong></p>

<p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>.</p>

<ul>
<li><p><strong>Feature scaling</strong> involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. </p></li>
<li><p><strong>Mean normalization</strong> involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. </p></li>
</ul>

<p>Replace \(x_i\) with \( x_i -\mu_i\) to make features have approximately zero mean (Do not apply to \(x_0=1\))</p>

<p>\[x_i =\frac{ x_i - \mu_i}{S_i}\]</p>

<p>where  \(\mu_i\) is average value of \(x_i\) in training set, \(S_i\) is the range (max-min) or standard deviation of \(x_i\).</p>

<p>E.g. \[x_1=\frac{size-1000}{2000}\]<br/>
\[x_2=\frac{\#bedrooms-2}{5}\]</p>

<h3 id="toc_3">Learning rate</h3>

<p><strong>Debugging</strong>: How to make sure gradient descent is working correctly.</p>

<p>-- How to choose learning rate \(\alpha\).</p>

<p>Gradient descent is working correctly if \(J(\theta)\) decreases after every iteration.</p>

<p>Use smaller \(\alpha\). For sufficiently small \(\alpha\), \(J(\theta)\) should decrease on every iteration.</p>

<p><strong>Automatic convergence test</strong>. Declare convergence if \(J(\theta)\) decreases by less than \(E\) in one iteration, where \(E\) is some small value such as \(10^{−3}\). However in practice it&#39;s difficult to choose this threshold value.</p>

<p><strong>Summary</strong>:</p>

<ul>
<li>If  \(\alpha\)  is too small: slow convergence.</li>
<li>If \(\alpha\) is too large: may not decrease on every iteration; may not converge.</li>
</ul>

<h2 id="toc_4">Computing Parameters Analytically</h2>

<h3 id="toc_5">Normal equation:</h3>

<p>Gradient descent gives one way of minimizing \(J\). The &quot;Normal Equation&quot; method minimizes \(J\) by explicitly taking its derivatives with respect to the \(θj\) ’s, and setting them to zero. This allows us to find the optimum theta without iteration. The normal equation formula is given below:</p>

<p>\[\theta = (X^TX)^{-1}X^Ty\]</p>

<p>Matlab command: </p>

<pre><code class="language-matlab">pinv(X&#39;*X)*X&#39;*y
</code></pre>

<p>where <code>pinv</code> is <code>peudoinversion</code> of matrix. It is different to <code>inv</code>.</p>

<h3 id="toc_6">Gradient descent v.s. Normal equation</h3>

<p><img src="media/14972614146835/Screen%20Shot%202017-06-27%20at%202.38.45%20PM.png" alt="Screen Shot 2017-06-27 at 2.38.45 P"/></p>

<h3 id="toc_7">Normal Equation Non-invertible</h3>

<p>The common reason causes non-invertible:</p>

<ul>
<li>Redundant features(linearly dependent)<br/>
E.g. \(x_1\) = size in feet\(^2\), \(x_2\) = size in m\(^2\)</li>
<li>Too many features(e.g. \(m&lt;=n\)).<br/>
-- Delete some features, or use regularization.</li>
</ul>

<p>where \(m\) is the number of training examples, \(n\) is the number of features.</p>

<p>Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/6/12</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_20.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_22.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="programming_language.html"><strong>编程语言</strong></a>
        
            <a href="data_structure_and_algorithm.html"><strong>数据结构和算法</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>文献阅读</strong></a>
        
            <a href="Tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="bit_manipulation.html">Bit manipulation</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="scrapy_top100.html">Scrapy爬取猫眼TOP100榜</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="scrapy_movielens.html">Scrapy爬取MovieLens</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15046649572570.html">Pandas</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="diagrammatize_TCP_IP.html">图解TCP/IP</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
