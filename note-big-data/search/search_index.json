{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"gdm/ch6/","text":"\u9762\u5411\u7a0b\u5e8f\u5458\u7684\u6570\u636e\u6316\u6398\u6307\u5357 - 6 \u6734\u7d20\u8d1d\u53f6\u65af\u7b97\u6cd5\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c \u7ed3\u6784\u5316\u6570\u636e \u662f\u6307\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u6761\u6570\u636e\uff08\u4e0a\u8868\u4e2d\u7684\u4e00\u884c\uff09\u7531\u591a\u4e2a\u7279\u5f81\u8fdb\u884c\u63cf\u8ff0\u3002\u4f8b\u5982\u524d\u9762\u7ae0\u8282\u6d89\u53ca\u7684\u6bd4\u9a6c\u5370\u7b2c\u5b89\u4eba\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u3002 \u975e\u7ed3\u6784\u5316\u6570\u636e \u6307\u7684\u662f\u8bf8\u5982\u7535\u5b50\u90ae\u4ef6\u6587\u672c\u3001\u63a8\u7279\u4fe1\u606f\u3001\u535a\u5ba2\u3001\u65b0\u95fb\u7b49\u3002\u8fd9\u4e9b\u6570\u636e\u81f3\u5c11\u7b2c\u4e00\u773c\u770b\u8d77\u6765\u662f\u65e0\u6cd5\u7528\u4e00\u5f20\u8868\u683c\u6765\u5c55\u73b0\u7684\u3002 \u81ea\u52a8\u5224\u522b\u6587\u672c\u4e2d\u7684\u611f\u60c5\u8272\u5f69 \u5047\u8bbe\u6211\u4eec\u8981\u6784\u5efa\u4e00\u4e2a\u81ea\u52a8\u5224\u522b\u6587\u672c\u611f\u60c5\u8272\u5f69\u7684\u7cfb\u7edf\uff0c\u5b83\u6709\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f\u6bd4\u5982\u8bf4\u6709\u5bb6\u516c\u53f8\u662f\u552e\u5356\u5065\u5eb7\u68c0\u6d4b\u8bbe\u5907\u7684\uff0c\u4ed6\u4eec\u60f3\u8981\u77e5\u9053\u4eba\u4eec\u5bf9\u8fd9\u6b3e\u4ea7\u54c1\u7684\u53cd\u54cd\u5982\u4f55\u3002\u4ed6\u4eec\u6295\u653e\u4e86\u5f88\u591a\u5e7f\u544a\uff0c\u987e\u5ba2\u662f\u559c\u6b22(\u6211\u597d\u60f3\u4e70\u4e00\u53f0)\u8fd8\u662f\u8ba8\u538c(\u770b\u8d77\u6765\u5f88\u7cdf\u7cd5)\u5462\uff1f \u5047\u8bbe\u6211\u8981\u4ece\u6587\u672c\u4e2d\u533a\u5206\u987e\u5ba2\u5bf9\u67d0\u4e9b\u98df\u54c1\u7684\u559c\u597d\uff0c\u53ef\u80fd\u5c31\u4f1a\u5217\u51fa\u4e00\u4e9b\u8868\u8fbe\u559c\u6b22\u7684\u8bcd\u8bed\uff0c\u4ee5\u53ca\u8868\u8fbe\u538c\u6076\u7684\u8bcd\uff1a \u8868\u8fbe\u559c\u6b22\u7684\u8bcd\uff1a\u7f8e\u5473\u3001\u597d\u5403\u3001\u4e0d\u9519\u3001\u559c\u6b22\u3001\u53ef\u53e3 \u8868\u8fbe\u538c\u6076\u7684\u8bcd\uff1a\u7cdf\u7cd5\u3001\u96be\u5403\u3001\u4e0d\u597d\u3001\u8ba8\u538c\u3001\u6076\u5fc3 \u6211\u4eec\u7684\u8bad\u7ec3\u96c6\u662f\u4e00\u7ec4\u6587\u672c\uff0c\u53c8\u79f0\u4e3a \u8bed\u6599\u5e93 \u3002\u6bcf\u4e2a\u6587\u672c(\u5373\u6bcf\u6761\u8bb0\u5f55)\u662f\u4e00\u6761\u63a8\u6587\uff0c\u5e76\u88ab\u6807\u8bb0\u4e3a\u559c\u6b22\u548c\u8ba8\u538c\u4e24\u7c7b\u3002 \u8bad\u7ec3\u9636\u6bb5 \u9996\u5148\uff0c\u6211\u4eec\u7edf\u8ba1\u6240\u6709\u6587\u672c\u4e2d\u4e00\u5171\u51fa\u73b0\u4e86\u591a\u5c11\u4e2a\u4e0d\u540c\u7684\u5355\u8bcd\uff0c\u8bb0\u4f5c\u201c|Vocabulary|\u201d\uff08\u603b\u8bcd\u6c47\u8868\uff09\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u5355\u8bcd w_k w_k \uff0c\u6211\u4eec\u5c06\u8ba1\u7b97 P(w_k|h_i) P(w_k|h_i) \uff0c\u6bcf\u4e2a h_i h_i (\u559c\u6b22\u548c\u8ba8\u538c\u4e24\u79cd)\u7684\u8ba1\u7b97\u6b65\u9aa4\u5982\u4e0b\uff1a \u5c06\u8be5\u5206\u7c7b\u4e0b\u7684\u6240\u6709\u6587\u7ae0\u5408\u5e76\u5230\u4e00\u8d77\uff1b \u7edf\u8ba1\u6bcf\u4e2a\u5206\u7c7b\u4e2d\u5355\u8bcd\u6570\u91cf\uff0c\u8bb0\u4e3a n_i n_i \uff1b \u5bf9\u4e8e\u603b\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u8bcd w_k w_k \uff0c\u7edf\u8ba1\u4ed6\u4eec\u5728\u672c\u7c7b\u6587\u7ae0\u4e2d\u51fa\u73b0\u7684\u6b21\u6570 n_k n_k \u6700\u540e\u8ba1\u7b97\u6982\u7387\uff1a P(w_k|h_i)=\\large \\frac{n_k+1}{n_i+|\\text{Vocabulary}|} P(w_k|h_i)=\\large \\frac{n_k+1}{n_i+|\\text{Vocabulary}|} \u5206\u7c7b\u9636\u6bb5 \u5206\u7c7b\u9636\u6bb5\u6bd4\u8f83\u7b80\u5355\uff0c\u76f4\u63a5\u5e94\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\u5c31\u53ef\u4ee5\u4e86\u3002 \u6bd4\u5982\u4e0b\u9762\u8fd9\u53e5\u8bdd\uff0c\u8981\u5982\u4f55\u5224\u65ad\u5b83\u662f\u6b63\u9762\u8fd8\u662f\u8d1f\u9762\u7684\u5462\uff1f\u201cI am stunned by the hype over gravity.\u201d \u6211\u4eec\u9700\u8981\u8ba1\u7b97\u7684\u662f\u4e0b\u9762\u4e24\u4e2a\u6982\u7387\uff0c\u5e76\u9009\u53d6\u8f83\u9ad8\u7684\u7ed3\u679c\uff1a P(like)\u00d7P(I|like)\u00d7P(am|like)\u00d7P(stunned|like)\u00d7... P(dislike)\u00d7P(I|dislike)\u00d7P(am|dislike)\u00d7P(stunned|dislike)\u00d7... Application: 20 Newsgroups 20newsgroups\u6570\u636e\u96c6\u662f\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3001\u6587\u672c\u6316\u636e\u548c\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u7684\u56fd\u9645\u6807\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\u3002\u6570\u636e\u96c6\u6536\u96c6\u4e86\u5927\u7ea620,000\u5de6\u53f3\u7684\u65b0\u95fb\u7ec4\u6587\u6863\uff0c\u5206\u4e3a20\u4e2a\u4e0d\u540c\u4e3b\u9898\u7684\u65b0\u95fb\u7ec4\u96c6\u5408\u3002 \u4e0b\u8f7d\u4e0b\u6765\u540e\uff0c\u6587\u6863\u683c\u5f0f\u5982\u4e0b\uff1a \u505c\u7528\u8bcd \u505c\u7528\u8bcd \u6307\u7684\u662f\u90a3\u4e9b\u6ca1\u6709\u610f\u4e49\u7684\u3001\u7ec4\u6210\u8bed\u6cd5\u7ed3\u6784\u7684\u5355\u8bcd\uff0c\u5b83\u4eec\u4ea7\u751f\u4f1a\u5f88\u591a\u566a\u97f3\u3002\u8fd9\u4e9b\u5355\u8bcd\u4e00\u822c\u5e76\u4e0d\u4f1a\u5bf9\u5206\u7c7b\u7ed3\u679c\u4ea7\u751f\u5927\u7684\u5f71\u54cd\u3002\u6709\u4e13\u95e8\u7684\u505c\u7528\u8bcd\u8868\u53ef\u4f9b\u4f7f\u7528\u3002 \u53bb\u9664\u505c\u7528\u8bcd\u7684\u597d\u5904\uff1a \u80fd\u591f\u51cf\u5c11\u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\uff1b \u8fd9\u4e9b\u8bcd\u7684\u5b58\u5728\u4f1a\u5bf9\u5206\u7c7b\u6548\u679c\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002 \u4e2d\u6587\u7684\u5e38\u7528\u505c\u7528\u8bcd\u8868\u53ef\u4ee5\u5728 \u8fd9\u91cc \u627e\u5230\u3002 \u82f1\u6587\u7684\u505c\u7528\u8bcd\u8868 \u5e38\u7528\u8bcd\u548c\u505c\u8bcd \u867d\u7136\u50cfthe\u3001a\u8fd9\u79cd\u5355\u8bcd\u7684\u786e\u6ca1\u6709\u610f\u4e49\uff0c\u4f46\u6709\u4e9b \u5e38\u7528\u8bcd \u5982work\u3001write\u3001school\u7b49\u5728\u67d0\u4e9b\u573a\u5408\u4e0b\u8fd8\u662f\u6709\u4f5c\u7528\u7684\uff0c\u5982\u679c\u5c06\u4ed6\u4eec\u4e5f\u5217\u8fdb\u505c\u8bcd\u8868\u91cc\u53ef\u80fd\u4f1a\u6709\u95ee\u9898\u3002 Python\u4ee3\u7801 \u5206\u7c7b\u5668\u7684\u521d\u59cb\u5316\u4ee3\u7801\u8981\u5b8c\u6210\u4ee5\u4e0b\u5de5\u4f5c\uff1a \u8bfb\u53d6\u505c\u8bcd\u5217\u8868\uff1b \u83b7\u53d6\u8bad\u7ec3\u96c6\u4e2d\u5404\u76ee\u5f55\uff08\u5206\u7c7b\uff09\u7684\u540d\u79f0\uff1b \u5bf9\u4e8e\u5404\u4e2a\u5206\u7c7b\uff0c\u8c03\u7528train\u65b9\u6cd5\uff0c\u7edf\u8ba1\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\uff1b \u8ba1\u7b97\u5404\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6982\u7387 class BayesText : def __init__ ( self , trainingdir , stopwordlist ): This class implements a naive Bayes approach to text classification. :param trainingdir, is the training data. Each subdirectory of trainingdir is titled with the name of the classification category -- those subdirectories in turn contain the text files for that category. :param stopwordlist, is a list of words (one per line) will be removed before any counting takes place. self . vocabulary = {} self . prob = {} self . totals = {} self . stopwords = {} f = codecs . open ( stopwordlist , mode = r , encoding = utf-8 ) for line in f : self . stopwords [ line . strip ()] = 1 f . close () categories = os . listdir ( trainingdir ) # filter out files that are not directories self . categories = [ filename for filename in categories if os . path . isdir ( trainingdir + filename )] print ( Counting ... ) for category in self . categories : print ( + category ) ( self . prob [ category ], self . totals [ category ]) = self . train ( trainingdir , category ) # I am going to eliminate any word in the vocabulary # that doesn t occur at least 3 times toDelete = [] for word in self . vocabulary : if self . vocabulary [ word ] 3 : # mark word for deletion # can t delete now because you can t delete # from a list you are currently iterating over toDelete . append ( word ) # now delete for word in toDelete : del self . vocabulary [ word ] # now compute probabilities vocabLength = len ( self . vocabulary ) print ( Computing probabilities: ) for category in self . categories : print ( + category ) denominator = self . totals [ category ] + vocabLength for word in self . vocabulary : if word in self . prob [ category ]: count = self . prob [ category ][ word ] else : count = 1 self . prob [ category ][ word ] = ( float ( count + 1 ) / denominator ) print ( DONE TRAINING \\n\\n ) def train ( self , trainingdir , category ): counts word occurrences for a particular category currentdir = trainingdir + category files = os . listdir ( currentdir ) counts = {} total = 0 for file in files : f = codecs . open ( currentdir + / + file , r , iso8859-1 ) for line in f : tokens = line . split () for token in tokens : # get rid of punctuation and lowercase token token = token . strip ( \\ .,?:- ) token = token . lower () if token != and not token in self . stopwords : self . vocabulary . setdefault ( token , 0 ) self . vocabulary [ token ] += 1 counts . setdefault ( token , 0 ) counts [ token ] += 1 total += 1 f . close () return ( counts , total ) def classify ( self , filename ): classify files :param filename: a file :return: classification result results = {} for category in self . categories : results [ category ] = 0 f = codecs . open ( filename , r , iso8859-1 ) for line in f : tokens = line . split () for token in tokens : # print(token) token = token . strip ( \\ .,?:- ) . lower () if token in self . vocabulary : for category in self . categories : if self . prob [ category ][ token ] == 0 : print ( %s %s % ( category , token )) results [ category ] += math . log ( self . prob [ category ][ token ]) f . close () results = list ( results . items ()) results . sort ( key = lambda tuple : tuple [ 1 ], reverse = True ) # for debugging I can change this to give me the entire list return results [ 0 ][ 0 ] def testCategory ( self , directory , category ): test all files for the category in this directory :param directory: a directory containing category :param category: a categeory folder contains files files = os . listdir ( directory ) total = 0 correct = 0 for file in files : total += 1 result = self . classify ( directory + file ) if result == category : correct += 1 return ( correct , total ) def test ( self , testdir ): Test all files in the test directory--that directory is organized into subdirectories--each subdir is a classification category :param testdir: test directory categories = os . listdir ( testdir ) # filter out files that are not directories categories = [ filename for filename in categories if os . path . isdir ( testdir + filename )] correct = 0 total = 0 for category in categories : print ( . , end = ) ( catCorrect , catTotal ) = self . testCategory ( testdir + category + / , category ) correct += catCorrect total += catTotal print ( \\n\\n Accuracy is %f%% ( %i test instances) % (( float ( correct ) / total ) * 100 , total )) \u6734\u7d20\u8d1d\u53f6\u65af\u4e0e\u60c5\u611f\u5206\u6790 \u60c5\u611f\u5206\u6790\u7684\u76ee\u7684\u662f\u5224\u65ad\u4f5c\u8005\u7684\u6001\u5ea6\u6216\u610f\u89c1\u3002\u60c5\u611f\u5206\u6790\u7684\u4f8b\u5b50\u4e4b\u4e00\u662f\u5224\u65ad\u4e00\u7bc7\u8bc4\u8bba\u662f\u6b63\u9762\u7684\u8fd8\u662f\u53cd\u9762\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u6734\u7d20\u8d1d\u53f6\u65af\u7b97\u6cd5\u6765\u5b9e\u73b0\u3002 Pang Lee 2004\u7684 \u7535\u5f71\u8bc4\u4ef7\u6570\u636e \u96c6\u5305\u542b1000\u4e2a\u6b63\u9762\u548c1000\u4e2a\u8d1f\u9762\u7684\u8bc4\u4ef7\u3002","title":"Chapter 6: \u6734\u7d20\u8d1d\u53f6\u65af\u548c\u6587\u672c\u6570\u636e"},{"location":"gdm/ch6/#-6","text":"\u7ed3\u6784\u5316\u6570\u636e \u662f\u6307\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u6761\u6570\u636e\uff08\u4e0a\u8868\u4e2d\u7684\u4e00\u884c\uff09\u7531\u591a\u4e2a\u7279\u5f81\u8fdb\u884c\u63cf\u8ff0\u3002\u4f8b\u5982\u524d\u9762\u7ae0\u8282\u6d89\u53ca\u7684\u6bd4\u9a6c\u5370\u7b2c\u5b89\u4eba\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u3002 \u975e\u7ed3\u6784\u5316\u6570\u636e \u6307\u7684\u662f\u8bf8\u5982\u7535\u5b50\u90ae\u4ef6\u6587\u672c\u3001\u63a8\u7279\u4fe1\u606f\u3001\u535a\u5ba2\u3001\u65b0\u95fb\u7b49\u3002\u8fd9\u4e9b\u6570\u636e\u81f3\u5c11\u7b2c\u4e00\u773c\u770b\u8d77\u6765\u662f\u65e0\u6cd5\u7528\u4e00\u5f20\u8868\u683c\u6765\u5c55\u73b0\u7684\u3002","title":"\u9762\u5411\u7a0b\u5e8f\u5458\u7684\u6570\u636e\u6316\u6398\u6307\u5357 - 6 \u6734\u7d20\u8d1d\u53f6\u65af\u7b97\u6cd5\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c"},{"location":"gdm/ch6/#_1","text":"\u5047\u8bbe\u6211\u4eec\u8981\u6784\u5efa\u4e00\u4e2a\u81ea\u52a8\u5224\u522b\u6587\u672c\u611f\u60c5\u8272\u5f69\u7684\u7cfb\u7edf\uff0c\u5b83\u6709\u4ec0\u4e48\u4f5c\u7528\u5462\uff1f\u6bd4\u5982\u8bf4\u6709\u5bb6\u516c\u53f8\u662f\u552e\u5356\u5065\u5eb7\u68c0\u6d4b\u8bbe\u5907\u7684\uff0c\u4ed6\u4eec\u60f3\u8981\u77e5\u9053\u4eba\u4eec\u5bf9\u8fd9\u6b3e\u4ea7\u54c1\u7684\u53cd\u54cd\u5982\u4f55\u3002\u4ed6\u4eec\u6295\u653e\u4e86\u5f88\u591a\u5e7f\u544a\uff0c\u987e\u5ba2\u662f\u559c\u6b22(\u6211\u597d\u60f3\u4e70\u4e00\u53f0)\u8fd8\u662f\u8ba8\u538c(\u770b\u8d77\u6765\u5f88\u7cdf\u7cd5)\u5462\uff1f \u5047\u8bbe\u6211\u8981\u4ece\u6587\u672c\u4e2d\u533a\u5206\u987e\u5ba2\u5bf9\u67d0\u4e9b\u98df\u54c1\u7684\u559c\u597d\uff0c\u53ef\u80fd\u5c31\u4f1a\u5217\u51fa\u4e00\u4e9b\u8868\u8fbe\u559c\u6b22\u7684\u8bcd\u8bed\uff0c\u4ee5\u53ca\u8868\u8fbe\u538c\u6076\u7684\u8bcd\uff1a \u8868\u8fbe\u559c\u6b22\u7684\u8bcd\uff1a\u7f8e\u5473\u3001\u597d\u5403\u3001\u4e0d\u9519\u3001\u559c\u6b22\u3001\u53ef\u53e3 \u8868\u8fbe\u538c\u6076\u7684\u8bcd\uff1a\u7cdf\u7cd5\u3001\u96be\u5403\u3001\u4e0d\u597d\u3001\u8ba8\u538c\u3001\u6076\u5fc3 \u6211\u4eec\u7684\u8bad\u7ec3\u96c6\u662f\u4e00\u7ec4\u6587\u672c\uff0c\u53c8\u79f0\u4e3a \u8bed\u6599\u5e93 \u3002\u6bcf\u4e2a\u6587\u672c(\u5373\u6bcf\u6761\u8bb0\u5f55)\u662f\u4e00\u6761\u63a8\u6587\uff0c\u5e76\u88ab\u6807\u8bb0\u4e3a\u559c\u6b22\u548c\u8ba8\u538c\u4e24\u7c7b\u3002 \u8bad\u7ec3\u9636\u6bb5 \u9996\u5148\uff0c\u6211\u4eec\u7edf\u8ba1\u6240\u6709\u6587\u672c\u4e2d\u4e00\u5171\u51fa\u73b0\u4e86\u591a\u5c11\u4e2a\u4e0d\u540c\u7684\u5355\u8bcd\uff0c\u8bb0\u4f5c\u201c|Vocabulary|\u201d\uff08\u603b\u8bcd\u6c47\u8868\uff09\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u5355\u8bcd w_k w_k \uff0c\u6211\u4eec\u5c06\u8ba1\u7b97 P(w_k|h_i) P(w_k|h_i) \uff0c\u6bcf\u4e2a h_i h_i (\u559c\u6b22\u548c\u8ba8\u538c\u4e24\u79cd)\u7684\u8ba1\u7b97\u6b65\u9aa4\u5982\u4e0b\uff1a \u5c06\u8be5\u5206\u7c7b\u4e0b\u7684\u6240\u6709\u6587\u7ae0\u5408\u5e76\u5230\u4e00\u8d77\uff1b \u7edf\u8ba1\u6bcf\u4e2a\u5206\u7c7b\u4e2d\u5355\u8bcd\u6570\u91cf\uff0c\u8bb0\u4e3a n_i n_i \uff1b \u5bf9\u4e8e\u603b\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u8bcd w_k w_k \uff0c\u7edf\u8ba1\u4ed6\u4eec\u5728\u672c\u7c7b\u6587\u7ae0\u4e2d\u51fa\u73b0\u7684\u6b21\u6570 n_k n_k \u6700\u540e\u8ba1\u7b97\u6982\u7387\uff1a P(w_k|h_i)=\\large \\frac{n_k+1}{n_i+|\\text{Vocabulary}|} P(w_k|h_i)=\\large \\frac{n_k+1}{n_i+|\\text{Vocabulary}|} \u5206\u7c7b\u9636\u6bb5 \u5206\u7c7b\u9636\u6bb5\u6bd4\u8f83\u7b80\u5355\uff0c\u76f4\u63a5\u5e94\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\u5c31\u53ef\u4ee5\u4e86\u3002 \u6bd4\u5982\u4e0b\u9762\u8fd9\u53e5\u8bdd\uff0c\u8981\u5982\u4f55\u5224\u65ad\u5b83\u662f\u6b63\u9762\u8fd8\u662f\u8d1f\u9762\u7684\u5462\uff1f\u201cI am stunned by the hype over gravity.\u201d \u6211\u4eec\u9700\u8981\u8ba1\u7b97\u7684\u662f\u4e0b\u9762\u4e24\u4e2a\u6982\u7387\uff0c\u5e76\u9009\u53d6\u8f83\u9ad8\u7684\u7ed3\u679c\uff1a P(like)\u00d7P(I|like)\u00d7P(am|like)\u00d7P(stunned|like)\u00d7... P(dislike)\u00d7P(I|dislike)\u00d7P(am|dislike)\u00d7P(stunned|dislike)\u00d7...","title":"\u81ea\u52a8\u5224\u522b\u6587\u672c\u4e2d\u7684\u611f\u60c5\u8272\u5f69"},{"location":"gdm/ch6/#application-20-newsgroups","text":"20newsgroups\u6570\u636e\u96c6\u662f\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u3001\u6587\u672c\u6316\u636e\u548c\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u7684\u56fd\u9645\u6807\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\u3002\u6570\u636e\u96c6\u6536\u96c6\u4e86\u5927\u7ea620,000\u5de6\u53f3\u7684\u65b0\u95fb\u7ec4\u6587\u6863\uff0c\u5206\u4e3a20\u4e2a\u4e0d\u540c\u4e3b\u9898\u7684\u65b0\u95fb\u7ec4\u96c6\u5408\u3002 \u4e0b\u8f7d\u4e0b\u6765\u540e\uff0c\u6587\u6863\u683c\u5f0f\u5982\u4e0b\uff1a","title":"Application: 20 Newsgroups"},{"location":"gdm/ch6/#_2","text":"\u505c\u7528\u8bcd \u6307\u7684\u662f\u90a3\u4e9b\u6ca1\u6709\u610f\u4e49\u7684\u3001\u7ec4\u6210\u8bed\u6cd5\u7ed3\u6784\u7684\u5355\u8bcd\uff0c\u5b83\u4eec\u4ea7\u751f\u4f1a\u5f88\u591a\u566a\u97f3\u3002\u8fd9\u4e9b\u5355\u8bcd\u4e00\u822c\u5e76\u4e0d\u4f1a\u5bf9\u5206\u7c7b\u7ed3\u679c\u4ea7\u751f\u5927\u7684\u5f71\u54cd\u3002\u6709\u4e13\u95e8\u7684\u505c\u7528\u8bcd\u8868\u53ef\u4f9b\u4f7f\u7528\u3002 \u53bb\u9664\u505c\u7528\u8bcd\u7684\u597d\u5904\uff1a \u80fd\u591f\u51cf\u5c11\u9700\u8981\u5904\u7406\u7684\u6570\u636e\u91cf\uff1b \u8fd9\u4e9b\u8bcd\u7684\u5b58\u5728\u4f1a\u5bf9\u5206\u7c7b\u6548\u679c\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002 \u4e2d\u6587\u7684\u5e38\u7528\u505c\u7528\u8bcd\u8868\u53ef\u4ee5\u5728 \u8fd9\u91cc \u627e\u5230\u3002 \u82f1\u6587\u7684\u505c\u7528\u8bcd\u8868","title":"\u505c\u7528\u8bcd"},{"location":"gdm/ch6/#_3","text":"\u867d\u7136\u50cfthe\u3001a\u8fd9\u79cd\u5355\u8bcd\u7684\u786e\u6ca1\u6709\u610f\u4e49\uff0c\u4f46\u6709\u4e9b \u5e38\u7528\u8bcd \u5982work\u3001write\u3001school\u7b49\u5728\u67d0\u4e9b\u573a\u5408\u4e0b\u8fd8\u662f\u6709\u4f5c\u7528\u7684\uff0c\u5982\u679c\u5c06\u4ed6\u4eec\u4e5f\u5217\u8fdb\u505c\u8bcd\u8868\u91cc\u53ef\u80fd\u4f1a\u6709\u95ee\u9898\u3002","title":"\u5e38\u7528\u8bcd\u548c\u505c\u8bcd"},{"location":"gdm/ch6/#python","text":"\u5206\u7c7b\u5668\u7684\u521d\u59cb\u5316\u4ee3\u7801\u8981\u5b8c\u6210\u4ee5\u4e0b\u5de5\u4f5c\uff1a \u8bfb\u53d6\u505c\u8bcd\u5217\u8868\uff1b \u83b7\u53d6\u8bad\u7ec3\u96c6\u4e2d\u5404\u76ee\u5f55\uff08\u5206\u7c7b\uff09\u7684\u540d\u79f0\uff1b \u5bf9\u4e8e\u5404\u4e2a\u5206\u7c7b\uff0c\u8c03\u7528train\u65b9\u6cd5\uff0c\u7edf\u8ba1\u5355\u8bcd\u51fa\u73b0\u7684\u6b21\u6570\uff1b \u8ba1\u7b97\u5404\u4e2a\u5355\u8bcd\u51fa\u73b0\u7684\u6982\u7387 class BayesText : def __init__ ( self , trainingdir , stopwordlist ): This class implements a naive Bayes approach to text classification. :param trainingdir, is the training data. Each subdirectory of trainingdir is titled with the name of the classification category -- those subdirectories in turn contain the text files for that category. :param stopwordlist, is a list of words (one per line) will be removed before any counting takes place. self . vocabulary = {} self . prob = {} self . totals = {} self . stopwords = {} f = codecs . open ( stopwordlist , mode = r , encoding = utf-8 ) for line in f : self . stopwords [ line . strip ()] = 1 f . close () categories = os . listdir ( trainingdir ) # filter out files that are not directories self . categories = [ filename for filename in categories if os . path . isdir ( trainingdir + filename )] print ( Counting ... ) for category in self . categories : print ( + category ) ( self . prob [ category ], self . totals [ category ]) = self . train ( trainingdir , category ) # I am going to eliminate any word in the vocabulary # that doesn t occur at least 3 times toDelete = [] for word in self . vocabulary : if self . vocabulary [ word ] 3 : # mark word for deletion # can t delete now because you can t delete # from a list you are currently iterating over toDelete . append ( word ) # now delete for word in toDelete : del self . vocabulary [ word ] # now compute probabilities vocabLength = len ( self . vocabulary ) print ( Computing probabilities: ) for category in self . categories : print ( + category ) denominator = self . totals [ category ] + vocabLength for word in self . vocabulary : if word in self . prob [ category ]: count = self . prob [ category ][ word ] else : count = 1 self . prob [ category ][ word ] = ( float ( count + 1 ) / denominator ) print ( DONE TRAINING \\n\\n ) def train ( self , trainingdir , category ): counts word occurrences for a particular category currentdir = trainingdir + category files = os . listdir ( currentdir ) counts = {} total = 0 for file in files : f = codecs . open ( currentdir + / + file , r , iso8859-1 ) for line in f : tokens = line . split () for token in tokens : # get rid of punctuation and lowercase token token = token . strip ( \\ .,?:- ) token = token . lower () if token != and not token in self . stopwords : self . vocabulary . setdefault ( token , 0 ) self . vocabulary [ token ] += 1 counts . setdefault ( token , 0 ) counts [ token ] += 1 total += 1 f . close () return ( counts , total ) def classify ( self , filename ): classify files :param filename: a file :return: classification result results = {} for category in self . categories : results [ category ] = 0 f = codecs . open ( filename , r , iso8859-1 ) for line in f : tokens = line . split () for token in tokens : # print(token) token = token . strip ( \\ .,?:- ) . lower () if token in self . vocabulary : for category in self . categories : if self . prob [ category ][ token ] == 0 : print ( %s %s % ( category , token )) results [ category ] += math . log ( self . prob [ category ][ token ]) f . close () results = list ( results . items ()) results . sort ( key = lambda tuple : tuple [ 1 ], reverse = True ) # for debugging I can change this to give me the entire list return results [ 0 ][ 0 ] def testCategory ( self , directory , category ): test all files for the category in this directory :param directory: a directory containing category :param category: a categeory folder contains files files = os . listdir ( directory ) total = 0 correct = 0 for file in files : total += 1 result = self . classify ( directory + file ) if result == category : correct += 1 return ( correct , total ) def test ( self , testdir ): Test all files in the test directory--that directory is organized into subdirectories--each subdir is a classification category :param testdir: test directory categories = os . listdir ( testdir ) # filter out files that are not directories categories = [ filename for filename in categories if os . path . isdir ( testdir + filename )] correct = 0 total = 0 for category in categories : print ( . , end = ) ( catCorrect , catTotal ) = self . testCategory ( testdir + category + / , category ) correct += catCorrect total += catTotal print ( \\n\\n Accuracy is %f%% ( %i test instances) % (( float ( correct ) / total ) * 100 , total ))","title":"Python\u4ee3\u7801"},{"location":"gdm/ch6/#_4","text":"\u60c5\u611f\u5206\u6790\u7684\u76ee\u7684\u662f\u5224\u65ad\u4f5c\u8005\u7684\u6001\u5ea6\u6216\u610f\u89c1\u3002\u60c5\u611f\u5206\u6790\u7684\u4f8b\u5b50\u4e4b\u4e00\u662f\u5224\u65ad\u4e00\u7bc7\u8bc4\u8bba\u662f\u6b63\u9762\u7684\u8fd8\u662f\u53cd\u9762\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u6734\u7d20\u8d1d\u53f6\u65af\u7b97\u6cd5\u6765\u5b9e\u73b0\u3002 Pang Lee 2004\u7684 \u7535\u5f71\u8bc4\u4ef7\u6570\u636e \u96c6\u5305\u542b1000\u4e2a\u6b63\u9762\u548c1000\u4e2a\u8d1f\u9762\u7684\u8bc4\u4ef7\u3002","title":"\u6734\u7d20\u8d1d\u53f6\u65af\u4e0e\u60c5\u611f\u5206\u6790"},{"location":"projects/\u4e2d\u6587\u60c5\u611f\u5206\u6790/","text":"\u4e2d\u6587\u60c5\u611f\u5206\u6790","title":"\u4e2d\u6587\u60c5\u611f\u5206\u6790"},{"location":"projects/\u4e2d\u6587\u60c5\u611f\u5206\u6790/#_1","text":"","title":"\u4e2d\u6587\u60c5\u611f\u5206\u6790"}]}