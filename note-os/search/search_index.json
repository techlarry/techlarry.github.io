{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"osc/ch6/","text":"Operating System Concepts 6 - Synchronization Tools 1 Background A race condition (\u7ade\u4e89\u6761\u4ef6) occurs when several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place. \u591a\u4e2a\u8fdb\u7a0b\u5e76\u53d1\u8bbf\u95ee\u548c\u64cd\u4f5c\u540c\u4e00\u6570\u636e\uff0c\u4e14\u6267\u884c\u7ed3\u679c\u4e0e\u8bbf\u95ee\u53d1\u751f\u7684\u7279\u5b9a\u987a\u5e8f\u6709\u5173\uff0c\u79f0\u4e4b\u4e3a\u7ade\u4e89\u6761\u4ef6\u3002 2 The Critical-Section problem A critical section (\u4e34\u754c\u533a) is a section of code, in which the process may be accessing and updating data that is shared with at least one other process. When one process is executing in its critical section, no other process is allowed to execute in its critical section. The critical-section problem (\u4e34\u754c\u533a\u95ee\u9898) is to design a protocol that the processes can use to synchronize their activity so as to cooperatively share data. Each process must request permission to enter its critical section. The section of code implementing this request is the entry section (\u8fdb\u5165\u533a) The critical section may be followed by an exit section (\u9000\u51fa\u533a)\u3002 The remaining code is the remainder section (\u5269\u4f59\u533a)\u3002 A solution to the critical-section problem must satisfy the following three requirements: Mutual exclusion (\u4e92\u65a5): If process P_i P_i is executing in its critical section, then no other processes can be executing in their critical sections. \u5982\u679c\u8fdb\u7a0b P_i P_i \u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\uff0c\u90a3\u4e48\u5176\u4ed6\u8fdb\u7a0b\u90fd\u4e0d\u80fd\u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\uff1b Progress (\u524d\u8fdb): If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in deciding which will enter its critical section next, and this selection cannot be postponed indefinitely. \u5982\u679c\u6ca1\u6709\u8fdb\u7a0b\u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\u4e14\u6709\u8fdb\u7a0b\u9700\u8fdb\u5165\u4e34\u754c\u533a\uff0c\u90a3\u4e48\u53ea\u6709\u90a3\u4e48\u4e0d\u5728\u5269\u4f59\u533a\u5185\u6267\u884c\u7684\u8fdb\u7a0b\u53ef\u53c2\u52a0\u9009\u62e9\uff0c\u4ee5\u786e\u5b9a\u8c01\u80fd\u4e0b\u4e00\u4e2a\u8fdb\u5165\u4e34\u754c\u533a\uff0c\u4e14\u8fd9\u79cd\u9009\u62e9\u4e0d\u80fd\u65e0\u9650\u63a8\u8fdf\uff1b Bounded waiting (\u6709\u9650\u7b49\u5f85): There exists a bound, or limit, on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted. \u4ece\u4e00\u4e2a\u8fdb\u7a0b\u505a\u51fa\u8fdb\u5165\u4e34\u754c\u533a\u7684\u8bf7\u6c42\uff0c\u76f4\u5230\u8be5\u8bf7\u6c42\u5141\u8bb8\u4e3a\u6b62\uff0c\u5176\u4ed6\u8fdb\u7a0b\u5141\u8bb8\u8fdb\u5165\u5176\u4e34\u754c\u533a\u5185\u7684\u6b21\u6570\u6709\u4e0a\u9650\u3002 Two general approaches are used to handle critical sections in operating systems: preemptive kernels \uff08\u62a2\u5360\u5185\u6838\uff09 and nonpreemptive kernels \uff08\u975e\u62a2\u5360\u5185\u6838\uff09. A preemptive kernel allows a process to be preempted while it is running in kernel mode. \u62a2\u5360\u5185\u6838\u5141\u8bb8\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u88ab\u62a2\u5360\u3002 A nonpreemptive kernel does not allow a process running in kernel mode to be preempted.A kernel-model process will run until it exists kernel mode, blocks, or voluntarily yields control of the CPU.\u975e\u62a2\u5360\u5185\u6838\u4e0d\u5141\u8bb8\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u88ab\u62a2\u5360\u3002 A nonpreemptive kernel is essentially free from race conditions on kernel data structures, as only on process is active in the kernel at at time. \u975e\u62a2\u5360\u5185\u6838\u7684\u5185\u6838\u4ece\u6839\u672c\u4e0a\u4e0d\u4f1a\u5bfc\u81f4\u7ade\u4e89\u6761\u4ef6\uff0c\u56e0\u4e3a\u5728\u5185\u6838\u4e2d\u4e00\u6b21\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u662f\u6d3b\u8dc3\u7684\u3002 Preemptive kernels must be carefully designed to ensure that shared kernel data are free from race conditions. \u5bf9\u4e8e\u62a2\u5360\u5185\u6838\u9700\u8981\u8ba4\u771f\u8bbe\u8ba1\u4ee5\u786e\u4fdd\u5171\u4eab\u5185\u548c\u6570\u636e\u514d\u4e8e\u7ade\u4e89\u6761\u4ef6\u3002 A preemptive kernel may be more responsive, since there is less risk that a kernel-model process will run for an arbitrarily long period before relinquishing the processor to waiting process. \u62a2\u5360\u5185\u6838\u7684\u54cd\u5e94\u66f4\u5feb\uff0c\u56e0\u4e3a\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u5728\u91ca\u653eCPU\u4e4b\u524d\u4e0d\u4f1a\u8fd0\u884c\u8fc7\u4e45\u3002 A preemptive kernel is more suitable for real-time programming, as it will allow a real-time process to preemptive a process currently running in the kernel. \u62a2\u5360\u5185\u6838\u66f4\u9002\u5408\u5b9e\u65f6\u7f16\u7a0b\uff0c\u56e0\u4e3a\u5b83\u80fd\u5141\u8bb8\u5b9e\u65f6\u8fdb\u7a0b\u62a2\u5360\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u8fd0\u884c\u7684\u5176\u4ed6\u8fdb\u7a0b\u3002 3 Peterson's Solution Peterson\u2019s solution (Peterson \u7b97\u6cd5) is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are numbered P_0 P_0 and P_1 P_1 . For convenience, when presenting P_i P_i , we use P_j P_j to denote the other process; that is j j equals 1-i 1-i . Peterson's solution requires the two processes to share two data items: int turn ; boolean flag [ 2 ]; The structure of process P_i P_i in Peterson's solution. while ( true ) { flag [ i ] = true ; turn = j ; while ( flag [ j ] turn == j ) ; /* critical section */ flag [ i ] = false ; /*remainder section */ } The variable turn indicates whose turn it is to enter its critical section. The flag array is used to indicate if a process is ready to enter its critical section. Note Peterson\u2019s solution is not guaranteed to work on modern computer architectures for the primary reason that, to improve system performance, processors and/or compilers may reorder read and write operations that have no dependencies . If the assignments of the first two statements that appear in the entry section of Peterson's solution are reordered. It is possible that both threads may be active in their critical sections at the same time. 4 Hardware support for Synchronization Hardware support for the critical-section problem includes: Memory barriers Hardware instructions Atomic variables Memory barriers How a computer architecture determines what memory guarantees it will provide to an application program is known as its memory model (\u5185\u5b58\u6a21\u578b). In general, a memory model falls into one of two categories: Strongly ordered , where a memory modification on one processor is immediately visible to all other processors. Weakly ordered , where modifications to memory on one processor may not be immediately visible to other processors. Computer architectures provide instructions that can force any changes in memory to be propagated to all other processors, thereby ensuring that memory modifications are visible to threads running on other processors. Such instruction are known as memory barriers (\u5185\u5b58\u5c4f\u969c). When a memory barrier instruction is performed, the system ensures that all loads and stores are completed before any subsequent load or store operations are performed. Hardware instructions Many modern computer systems provide special hardware instructions that allow either to test and modify the content of a word or to swap the contents of two words atomically - that is, one uninterruptible unit. The definition of the atomic test_and_set() instruction: boolean test_and_set ( boolean * target ) { boolean rv = * target ; * target = true ; return rv ; } Mutual-exclusion implementation with test_and_set() : do { while ( test_and_set ( lock )) ; /* do nothing */ /* critical section */ lock = false ; /* remainder section */ } while ( true ); The definition of the atomic compare_and_swap() \uff08CAS\uff0c \u6bd4\u8f83\u5e76\u4ea4\u6362\uff09instruction: int compare_and_swap ( int * value , int expected , int new value ) { int temp = * value ; if ( * value == expected ) * value = new value ; return temp ; } Mutual exclusion with the compare_and_swap() instruction: while ( true ) { while ( compare_and_swap ( lock , 0 , 1 ) != 0 ) ; /* do nothing */ /* critical section */ lock = 0 ; /* remainder section */ } Atomic variables Atomic variables (\u539f\u5b50\u53d8\u91cf) provides atomic operations on basic data types such as integers and booleans. Their use is often limited to single updates of shared data such as counters and sequence generators . Important It is important to note that although atomic variables provide atomic updates, they do not entirely solve race conditions in all circumstances. increment ( sequence ); void increment ( atomic int * v ) { int temp ; do { temp = * v ; } while ( temp != compare_and_swap ( v , temp , temp + 1 )); } 5 Mutex locks ISSUE: The hardware-based solutions are complicated as well as generally inaccessible to application programmers. SOLUTION: Operating-system designers build higher-level software tools. The simplest of these tools is the mutex lock (\u4e92\u65a5\u9501)\u3002 A process must acquire the lock before entering a critical section; A process releases the lock when it exists the critical section. A mutex lock has a boolean variable available , whose value indicates if the lock is available or not. Calls to either acquire() or release() must be performed atomically. Thus mutex locks can be implemented using the CAS operation. Solution to the critical-section problem using mutex locks: while ( true ) { /* acquire lock */ /* critical section */ /* release lock */ /* remainder section */ } The definition of acquire() is as follows: acquire () { while ( ! available ) ; /* busy wait */ available = false ; } The definition of release() is as follows: release (){ available = true ; } The main disadvantage of the implementation is that it requires busy waiting (\u5fd9\u7b49\u5f85). While a process is in its critical section, any other process that tries enter its critical section must loop continuously in the call to acquire() . It wastes CPU cycles. Because the process \"spins\" while waiting for the lock to become available, this type of mutex lock is also called a spinlock \uff08\u81ea\u65cb\u9501\uff09\u3002 Advantage: no context switch is required Spinlocks are not appropriate for single-processor systems yet are often used in multiprocessor systems. POSIX API for Spinlocks 6 Semaphores A semaphore (\u4fe1\u53f7\u91cf) S is an integer variable that, apart from initialization, is accessed only through two standard atomic operations: wait() and signal() . \u4fe1\u53f7\u91cfS\u662f\u4e2a\u6574\u6570\u53d8\u91cf\uff0c\u9664\u4e86\u521d\u59cb\u5316\u5916\uff0c\u5b83\u53ea\u80fd\u901a\u8fc7\u4e24\u4e2a\u6807\u51c6\u539f\u5b50\u64cd\u4f5c\uff1a wait() \u548c signal() \u6765\u8bbf\u95ee\u3002 The definition of wait() is as follows: wait ( S ){ while ( S = 0 ) ; // busy wait S -- ; { The definition of signal() is as follows: signal ( S ){ S ++ ; } All modifications to the integer value of the semaphore in the wait() and signal() operations must be executed atomically. \u5728 wait() \u548c signal() \u64cd\u4f5c\u4e2d\uff0c\u5bf9\u4fe1\u53f7\u91cf\u6574\u578b\u503c\u7684\u4fee\u6539\u5fc5\u987b\u4e0d\u53ef\u5206\u5730\u6267\u884c\u3002 Operating systems often distinguish between counting and binary semaphores.\u901a\u5e38\u64cd\u4f5c\u7cfb\u7edf\u533a\u5206\u8ba1\u6570\u4fe1\u53f7\u91cf\u548c\u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf\u3002 The value of a counting semaphore (\u8ba1\u6570\u4fe1\u53f7\u91cf) can range over an unrestricted domain.\u8ba1\u6570\u4fe1\u53f7\u91cf\u7684\u503c\u57df\u4e0d\u53d7\u9650\u5236\u3002 The value of a binary semaphore (\u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf) can range only between 0 and 1. \u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf\u7684\u503c\u53ea\u80fd\u4e3a0\u62161\u3002 Counting semaphores can be used to control access to a given resource consisting of a finite number of instances. The semaphore is initialized to the number of resources available. Each process that wishes to use a resource performs a wait() operation on the semaphore (thereby decrementing the count). When a process releases a resource, it performs a signal() operation (incrementing the count). When the count for the semaphore goes to 0, all resources are being used. After that, processes that wish to use a resource will block until the count becomes greater than 0. POSIX API for Semaphores Java API for Semaphores 7 Monitors Monitor Usage Issues: various types of errors can be generated easily when programmers use semaphores or mutex locks incorrectly to solve the critical-section problem. interchanges the order of wait() and signal() replaces signal() with wait() omits wait() or signal() Solution: An abstract data type, monitor (\u7ba1\u7a0b), includes a set of programmer-defined operation related to mutual exclusion within the monitor. The monitor construct ensures that only one process at a time is active within the monitor. Pseudocode syntax of a monitor: monitor monitor name { /* shared variable declarations */ function P1 ( . . . ) { . . .} function P2 ( . . . ) { . . .} . . function Pn ( . . . ) { . . .} initialization code ( . . . ) { . . .} } A monitor uses condition variables that allow processes to wait for certain conditions to become true and to signal one another when conditions have been set to true: \\text{condition x, y;} \\text{condition x, y;} The only operations that can be invoked on a condition variable are wait() and signal() . Implementing a Monitor Using Semaphores binary semaphore next : the signaling processes use it to suspend themselves. integer variable next_count : to count the number of processes suspended on next . condition x , binary semaphore x_sem , and integer variable x_count monitor ResourceAllocator { boolean busy ; condition x ; void acquire ( int time ) { if ( busy ) x . wait ( time ); busy = true ; } void release () { busy = false ; x . signal (); } initialization code () { busy = false ; } signal () { if ( x_count 0 ) { next_count ++ ; signal ( x_sem ); wait ( next ); next_count -- ; } } wait () { x_count ++ ; if ( next_count 0 ) signal ( next ); else signal ( mutex ); wait ( x_sem ); x count -- ; } } Monitor in Java 8 Liveness Deadlock Consider two threads A and B that both need simultaneous access to resources 1 and 2: Thread A runs, grabs the lock for Resource 1 . \u2192 CONTEXT SWITCH \u2190 Thread B runs, grabs the lock for Resource 2 . \u2192 CONTEXT SWITCH \u2190 Thread A runs, tries to acquire the lock for Resource 2 . \u2192 THREAD A SLEEPS \u2190 Thread B runs, tries to acquire the lock for Resource 1 . \u2192 THREAD B SLEEPS \u2190 Deadlocked (\u6b7b\u9501): two or more processes are waiting indefinitely for an event . A set of processes is in a deadlocked state when every process in the set is waiting for an event that can be caused only by another process in the set. Priority Inversion A scheduling challenge arises when a higher-priority process needs to read or modify kernel data that are currently being accessed by a lower-priority process\u2014or a chain of lower-priority processes. Since kernel data are typically protected with a lock, the higher-priority process will have to wait for a lower-priority one to finish with the resource. The situation becomes more complicated if the lower-priority process is preempted in favor of another process with a higher priority. As an example, assume we have three processes\u2014 L L , M M , and H H \u2014whose priorities follow the order L M H L < M < H . Assume that process H H requires a semaphore S S , which is currently being accessed by process L L . Ordinarily, process H H would wait for L L to finish using resource S. However, now suppose that process M M becomes runnable, thereby preempting process L L . Indirectly, a process with a lower priority\u2014process M M \u2014has affected how long process H H must wait for L L to relinquish resource S S . This liveness problem is known as priority inversion (\u4f18\u5148\u7ea7\u53cd\u8f6c), and it can occur only in systems with more than two priorities. Solution\uff1a priority-inheritance protocol (\u4f18\u5148\u7ea7\u7ee7\u627f\u534f\u8bae)\uff1a All processes that are accessing resources needed by a higher-priority process inherit the higher priority until they are finished with the resources. When they are finished, priorities revert to original values. 9 Evaluation Performance differences between CAS-based synchronization and traditional synchronization (such as mutex locks and semaphores) under varying contention loads: Uncontended \uff1aAlthough both options are generally fast, CAS protection will be somewhat faster than traditional synchronization. Moderate contention \uff1aCAS protection will be faster\u2014possibly much faster \u2014than traditional synchronization. High contention \uff1aUnder very highly contended loads, traditional synchronization will ultimately be faster than CAS-based synchronization. Higher-level tools such as monitors and condition variables may have significant overhead, and may be less likely to scale in highly contended situations.","title":"Chapter 6: Synchronization Tools"},{"location":"osc/ch6/#operating-system-concepts-6-synchronization-tools","text":"","title":"Operating System Concepts 6 - Synchronization Tools"},{"location":"osc/ch6/#1-background","text":"A race condition (\u7ade\u4e89\u6761\u4ef6) occurs when several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place. \u591a\u4e2a\u8fdb\u7a0b\u5e76\u53d1\u8bbf\u95ee\u548c\u64cd\u4f5c\u540c\u4e00\u6570\u636e\uff0c\u4e14\u6267\u884c\u7ed3\u679c\u4e0e\u8bbf\u95ee\u53d1\u751f\u7684\u7279\u5b9a\u987a\u5e8f\u6709\u5173\uff0c\u79f0\u4e4b\u4e3a\u7ade\u4e89\u6761\u4ef6\u3002","title":"1 Background"},{"location":"osc/ch6/#2-the-critical-section-problem","text":"A critical section (\u4e34\u754c\u533a) is a section of code, in which the process may be accessing and updating data that is shared with at least one other process. When one process is executing in its critical section, no other process is allowed to execute in its critical section. The critical-section problem (\u4e34\u754c\u533a\u95ee\u9898) is to design a protocol that the processes can use to synchronize their activity so as to cooperatively share data. Each process must request permission to enter its critical section. The section of code implementing this request is the entry section (\u8fdb\u5165\u533a) The critical section may be followed by an exit section (\u9000\u51fa\u533a)\u3002 The remaining code is the remainder section (\u5269\u4f59\u533a)\u3002 A solution to the critical-section problem must satisfy the following three requirements: Mutual exclusion (\u4e92\u65a5): If process P_i P_i is executing in its critical section, then no other processes can be executing in their critical sections. \u5982\u679c\u8fdb\u7a0b P_i P_i \u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\uff0c\u90a3\u4e48\u5176\u4ed6\u8fdb\u7a0b\u90fd\u4e0d\u80fd\u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\uff1b Progress (\u524d\u8fdb): If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in deciding which will enter its critical section next, and this selection cannot be postponed indefinitely. \u5982\u679c\u6ca1\u6709\u8fdb\u7a0b\u5728\u5176\u4e34\u754c\u533a\u5185\u6267\u884c\u4e14\u6709\u8fdb\u7a0b\u9700\u8fdb\u5165\u4e34\u754c\u533a\uff0c\u90a3\u4e48\u53ea\u6709\u90a3\u4e48\u4e0d\u5728\u5269\u4f59\u533a\u5185\u6267\u884c\u7684\u8fdb\u7a0b\u53ef\u53c2\u52a0\u9009\u62e9\uff0c\u4ee5\u786e\u5b9a\u8c01\u80fd\u4e0b\u4e00\u4e2a\u8fdb\u5165\u4e34\u754c\u533a\uff0c\u4e14\u8fd9\u79cd\u9009\u62e9\u4e0d\u80fd\u65e0\u9650\u63a8\u8fdf\uff1b Bounded waiting (\u6709\u9650\u7b49\u5f85): There exists a bound, or limit, on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted. \u4ece\u4e00\u4e2a\u8fdb\u7a0b\u505a\u51fa\u8fdb\u5165\u4e34\u754c\u533a\u7684\u8bf7\u6c42\uff0c\u76f4\u5230\u8be5\u8bf7\u6c42\u5141\u8bb8\u4e3a\u6b62\uff0c\u5176\u4ed6\u8fdb\u7a0b\u5141\u8bb8\u8fdb\u5165\u5176\u4e34\u754c\u533a\u5185\u7684\u6b21\u6570\u6709\u4e0a\u9650\u3002 Two general approaches are used to handle critical sections in operating systems: preemptive kernels \uff08\u62a2\u5360\u5185\u6838\uff09 and nonpreemptive kernels \uff08\u975e\u62a2\u5360\u5185\u6838\uff09. A preemptive kernel allows a process to be preempted while it is running in kernel mode. \u62a2\u5360\u5185\u6838\u5141\u8bb8\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u88ab\u62a2\u5360\u3002 A nonpreemptive kernel does not allow a process running in kernel mode to be preempted.A kernel-model process will run until it exists kernel mode, blocks, or voluntarily yields control of the CPU.\u975e\u62a2\u5360\u5185\u6838\u4e0d\u5141\u8bb8\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u88ab\u62a2\u5360\u3002 A nonpreemptive kernel is essentially free from race conditions on kernel data structures, as only on process is active in the kernel at at time. \u975e\u62a2\u5360\u5185\u6838\u7684\u5185\u6838\u4ece\u6839\u672c\u4e0a\u4e0d\u4f1a\u5bfc\u81f4\u7ade\u4e89\u6761\u4ef6\uff0c\u56e0\u4e3a\u5728\u5185\u6838\u4e2d\u4e00\u6b21\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u662f\u6d3b\u8dc3\u7684\u3002 Preemptive kernels must be carefully designed to ensure that shared kernel data are free from race conditions. \u5bf9\u4e8e\u62a2\u5360\u5185\u6838\u9700\u8981\u8ba4\u771f\u8bbe\u8ba1\u4ee5\u786e\u4fdd\u5171\u4eab\u5185\u548c\u6570\u636e\u514d\u4e8e\u7ade\u4e89\u6761\u4ef6\u3002 A preemptive kernel may be more responsive, since there is less risk that a kernel-model process will run for an arbitrarily long period before relinquishing the processor to waiting process. \u62a2\u5360\u5185\u6838\u7684\u54cd\u5e94\u66f4\u5feb\uff0c\u56e0\u4e3a\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u7684\u8fdb\u7a0b\u5728\u91ca\u653eCPU\u4e4b\u524d\u4e0d\u4f1a\u8fd0\u884c\u8fc7\u4e45\u3002 A preemptive kernel is more suitable for real-time programming, as it will allow a real-time process to preemptive a process currently running in the kernel. \u62a2\u5360\u5185\u6838\u66f4\u9002\u5408\u5b9e\u65f6\u7f16\u7a0b\uff0c\u56e0\u4e3a\u5b83\u80fd\u5141\u8bb8\u5b9e\u65f6\u8fdb\u7a0b\u62a2\u5360\u5904\u4e8e\u5185\u6838\u6a21\u5f0f\u8fd0\u884c\u7684\u5176\u4ed6\u8fdb\u7a0b\u3002","title":"2 The Critical-Section problem"},{"location":"osc/ch6/#3-petersons-solution","text":"Peterson\u2019s solution (Peterson \u7b97\u6cd5) is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are numbered P_0 P_0 and P_1 P_1 . For convenience, when presenting P_i P_i , we use P_j P_j to denote the other process; that is j j equals 1-i 1-i . Peterson's solution requires the two processes to share two data items: int turn ; boolean flag [ 2 ]; The structure of process P_i P_i in Peterson's solution. while ( true ) { flag [ i ] = true ; turn = j ; while ( flag [ j ] turn == j ) ; /* critical section */ flag [ i ] = false ; /*remainder section */ } The variable turn indicates whose turn it is to enter its critical section. The flag array is used to indicate if a process is ready to enter its critical section. Note Peterson\u2019s solution is not guaranteed to work on modern computer architectures for the primary reason that, to improve system performance, processors and/or compilers may reorder read and write operations that have no dependencies . If the assignments of the first two statements that appear in the entry section of Peterson's solution are reordered. It is possible that both threads may be active in their critical sections at the same time.","title":"3 Peterson's Solution"},{"location":"osc/ch6/#4-hardware-support-for-synchronization","text":"Hardware support for the critical-section problem includes: Memory barriers Hardware instructions Atomic variables","title":"4 Hardware support for Synchronization"},{"location":"osc/ch6/#memory-barriers","text":"How a computer architecture determines what memory guarantees it will provide to an application program is known as its memory model (\u5185\u5b58\u6a21\u578b). In general, a memory model falls into one of two categories: Strongly ordered , where a memory modification on one processor is immediately visible to all other processors. Weakly ordered , where modifications to memory on one processor may not be immediately visible to other processors. Computer architectures provide instructions that can force any changes in memory to be propagated to all other processors, thereby ensuring that memory modifications are visible to threads running on other processors. Such instruction are known as memory barriers (\u5185\u5b58\u5c4f\u969c). When a memory barrier instruction is performed, the system ensures that all loads and stores are completed before any subsequent load or store operations are performed.","title":"Memory barriers"},{"location":"osc/ch6/#hardware-instructions","text":"Many modern computer systems provide special hardware instructions that allow either to test and modify the content of a word or to swap the contents of two words atomically - that is, one uninterruptible unit. The definition of the atomic test_and_set() instruction: boolean test_and_set ( boolean * target ) { boolean rv = * target ; * target = true ; return rv ; } Mutual-exclusion implementation with test_and_set() : do { while ( test_and_set ( lock )) ; /* do nothing */ /* critical section */ lock = false ; /* remainder section */ } while ( true ); The definition of the atomic compare_and_swap() \uff08CAS\uff0c \u6bd4\u8f83\u5e76\u4ea4\u6362\uff09instruction: int compare_and_swap ( int * value , int expected , int new value ) { int temp = * value ; if ( * value == expected ) * value = new value ; return temp ; } Mutual exclusion with the compare_and_swap() instruction: while ( true ) { while ( compare_and_swap ( lock , 0 , 1 ) != 0 ) ; /* do nothing */ /* critical section */ lock = 0 ; /* remainder section */ }","title":"Hardware instructions"},{"location":"osc/ch6/#atomic-variables","text":"Atomic variables (\u539f\u5b50\u53d8\u91cf) provides atomic operations on basic data types such as integers and booleans. Their use is often limited to single updates of shared data such as counters and sequence generators . Important It is important to note that although atomic variables provide atomic updates, they do not entirely solve race conditions in all circumstances. increment ( sequence ); void increment ( atomic int * v ) { int temp ; do { temp = * v ; } while ( temp != compare_and_swap ( v , temp , temp + 1 )); }","title":"Atomic variables"},{"location":"osc/ch6/#5-mutex-locks","text":"ISSUE: The hardware-based solutions are complicated as well as generally inaccessible to application programmers. SOLUTION: Operating-system designers build higher-level software tools. The simplest of these tools is the mutex lock (\u4e92\u65a5\u9501)\u3002 A process must acquire the lock before entering a critical section; A process releases the lock when it exists the critical section. A mutex lock has a boolean variable available , whose value indicates if the lock is available or not. Calls to either acquire() or release() must be performed atomically. Thus mutex locks can be implemented using the CAS operation. Solution to the critical-section problem using mutex locks: while ( true ) { /* acquire lock */ /* critical section */ /* release lock */ /* remainder section */ } The definition of acquire() is as follows: acquire () { while ( ! available ) ; /* busy wait */ available = false ; } The definition of release() is as follows: release (){ available = true ; } The main disadvantage of the implementation is that it requires busy waiting (\u5fd9\u7b49\u5f85). While a process is in its critical section, any other process that tries enter its critical section must loop continuously in the call to acquire() . It wastes CPU cycles. Because the process \"spins\" while waiting for the lock to become available, this type of mutex lock is also called a spinlock \uff08\u81ea\u65cb\u9501\uff09\u3002 Advantage: no context switch is required Spinlocks are not appropriate for single-processor systems yet are often used in multiprocessor systems. POSIX API for Spinlocks","title":"5 Mutex locks"},{"location":"osc/ch6/#6-semaphores","text":"A semaphore (\u4fe1\u53f7\u91cf) S is an integer variable that, apart from initialization, is accessed only through two standard atomic operations: wait() and signal() . \u4fe1\u53f7\u91cfS\u662f\u4e2a\u6574\u6570\u53d8\u91cf\uff0c\u9664\u4e86\u521d\u59cb\u5316\u5916\uff0c\u5b83\u53ea\u80fd\u901a\u8fc7\u4e24\u4e2a\u6807\u51c6\u539f\u5b50\u64cd\u4f5c\uff1a wait() \u548c signal() \u6765\u8bbf\u95ee\u3002 The definition of wait() is as follows: wait ( S ){ while ( S = 0 ) ; // busy wait S -- ; { The definition of signal() is as follows: signal ( S ){ S ++ ; } All modifications to the integer value of the semaphore in the wait() and signal() operations must be executed atomically. \u5728 wait() \u548c signal() \u64cd\u4f5c\u4e2d\uff0c\u5bf9\u4fe1\u53f7\u91cf\u6574\u578b\u503c\u7684\u4fee\u6539\u5fc5\u987b\u4e0d\u53ef\u5206\u5730\u6267\u884c\u3002 Operating systems often distinguish between counting and binary semaphores.\u901a\u5e38\u64cd\u4f5c\u7cfb\u7edf\u533a\u5206\u8ba1\u6570\u4fe1\u53f7\u91cf\u548c\u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf\u3002 The value of a counting semaphore (\u8ba1\u6570\u4fe1\u53f7\u91cf) can range over an unrestricted domain.\u8ba1\u6570\u4fe1\u53f7\u91cf\u7684\u503c\u57df\u4e0d\u53d7\u9650\u5236\u3002 The value of a binary semaphore (\u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf) can range only between 0 and 1. \u4e8c\u8fdb\u5236\u4fe1\u53f7\u91cf\u7684\u503c\u53ea\u80fd\u4e3a0\u62161\u3002 Counting semaphores can be used to control access to a given resource consisting of a finite number of instances. The semaphore is initialized to the number of resources available. Each process that wishes to use a resource performs a wait() operation on the semaphore (thereby decrementing the count). When a process releases a resource, it performs a signal() operation (incrementing the count). When the count for the semaphore goes to 0, all resources are being used. After that, processes that wish to use a resource will block until the count becomes greater than 0. POSIX API for Semaphores Java API for Semaphores","title":"6 Semaphores"},{"location":"osc/ch6/#7-monitors","text":"","title":"7 Monitors"},{"location":"osc/ch6/#monitor-usage","text":"Issues: various types of errors can be generated easily when programmers use semaphores or mutex locks incorrectly to solve the critical-section problem. interchanges the order of wait() and signal() replaces signal() with wait() omits wait() or signal() Solution: An abstract data type, monitor (\u7ba1\u7a0b), includes a set of programmer-defined operation related to mutual exclusion within the monitor. The monitor construct ensures that only one process at a time is active within the monitor. Pseudocode syntax of a monitor: monitor monitor name { /* shared variable declarations */ function P1 ( . . . ) { . . .} function P2 ( . . . ) { . . .} . . function Pn ( . . . ) { . . .} initialization code ( . . . ) { . . .} } A monitor uses condition variables that allow processes to wait for certain conditions to become true and to signal one another when conditions have been set to true: \\text{condition x, y;} \\text{condition x, y;} The only operations that can be invoked on a condition variable are wait() and signal() .","title":"Monitor Usage"},{"location":"osc/ch6/#implementing-a-monitor-using-semaphores","text":"binary semaphore next : the signaling processes use it to suspend themselves. integer variable next_count : to count the number of processes suspended on next . condition x , binary semaphore x_sem , and integer variable x_count monitor ResourceAllocator { boolean busy ; condition x ; void acquire ( int time ) { if ( busy ) x . wait ( time ); busy = true ; } void release () { busy = false ; x . signal (); } initialization code () { busy = false ; } signal () { if ( x_count 0 ) { next_count ++ ; signal ( x_sem ); wait ( next ); next_count -- ; } } wait () { x_count ++ ; if ( next_count 0 ) signal ( next ); else signal ( mutex ); wait ( x_sem ); x count -- ; } } Monitor in Java","title":"Implementing a Monitor Using Semaphores"},{"location":"osc/ch6/#8-liveness","text":"","title":"8 Liveness"},{"location":"osc/ch6/#deadlock","text":"Consider two threads A and B that both need simultaneous access to resources 1 and 2: Thread A runs, grabs the lock for Resource 1 . \u2192 CONTEXT SWITCH \u2190 Thread B runs, grabs the lock for Resource 2 . \u2192 CONTEXT SWITCH \u2190 Thread A runs, tries to acquire the lock for Resource 2 . \u2192 THREAD A SLEEPS \u2190 Thread B runs, tries to acquire the lock for Resource 1 . \u2192 THREAD B SLEEPS \u2190 Deadlocked (\u6b7b\u9501): two or more processes are waiting indefinitely for an event . A set of processes is in a deadlocked state when every process in the set is waiting for an event that can be caused only by another process in the set.","title":"Deadlock"},{"location":"osc/ch6/#priority-inversion","text":"A scheduling challenge arises when a higher-priority process needs to read or modify kernel data that are currently being accessed by a lower-priority process\u2014or a chain of lower-priority processes. Since kernel data are typically protected with a lock, the higher-priority process will have to wait for a lower-priority one to finish with the resource. The situation becomes more complicated if the lower-priority process is preempted in favor of another process with a higher priority. As an example, assume we have three processes\u2014 L L , M M , and H H \u2014whose priorities follow the order L M H L < M < H . Assume that process H H requires a semaphore S S , which is currently being accessed by process L L . Ordinarily, process H H would wait for L L to finish using resource S. However, now suppose that process M M becomes runnable, thereby preempting process L L . Indirectly, a process with a lower priority\u2014process M M \u2014has affected how long process H H must wait for L L to relinquish resource S S . This liveness problem is known as priority inversion (\u4f18\u5148\u7ea7\u53cd\u8f6c), and it can occur only in systems with more than two priorities. Solution\uff1a priority-inheritance protocol (\u4f18\u5148\u7ea7\u7ee7\u627f\u534f\u8bae)\uff1a All processes that are accessing resources needed by a higher-priority process inherit the higher priority until they are finished with the resources. When they are finished, priorities revert to original values.","title":"Priority Inversion"},{"location":"osc/ch6/#9-evaluation","text":"Performance differences between CAS-based synchronization and traditional synchronization (such as mutex locks and semaphores) under varying contention loads: Uncontended \uff1aAlthough both options are generally fast, CAS protection will be somewhat faster than traditional synchronization. Moderate contention \uff1aCAS protection will be faster\u2014possibly much faster \u2014than traditional synchronization. High contention \uff1aUnder very highly contended loads, traditional synchronization will ultimately be faster than CAS-based synchronization. Higher-level tools such as monitors and condition variables may have significant overhead, and may be less likely to scale in highly contended situations.","title":"9 Evaluation"}]}