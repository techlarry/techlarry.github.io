<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Zhenhua Wang">
        <link rel="canonical" href="http://larryim.cc/note/bigdata/projects/SparkStreaming实时流处理项目/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>SparkStreaming实时流处理 - Zhenhua's Notes</title>
        <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/docco.min.css">
        <link href="../../../extra_css/custom.css" rel="stylesheet">
        <link href="../../../extra_css/custom.js" rel="stylesheet">
        <link href="../../../extra_css/friendly.css" rel="stylesheet">
        <link href="../../../extra_css/theme.css" rel="stylesheet">
        <link href="../../../extra_css/mkdocs/js/lunr-0.5.7.min.js" rel="stylesheet">
        <link href="../../../extra_css/mkdocs/js/mustache.min.js" rel="stylesheet">
        <link href="../../../extra_css/mkdocs/js/require.js" rel="stylesheet">
        <link href="../../../extra_css/mkdocs/js/search.js" rel="stylesheet">
        <link href="../../../extra_css/mkdocs/js/text.js" rel="stylesheet">
        <link href="../../../extra_css/code-tab.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="../../..">Zhenhua's Notes</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="../../..">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithm <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">AlgorithmPrinceton</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/">Contents</a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic1/">Topic 1: UnionFind </a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic2/">Topic 2: StackQueue</a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic3/">Topic 3: Sort </a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic4/">Topic 4: PriorityQueues</a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic5/">Topic 5: Symbol Tables</a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmPrinceton/topic6/">Topic 6: Balanced Search Trees</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">AlgorithmStanford</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../algorithm/algorithmStanford/">Contents</a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmStanford/dynamicprogramming/">Topic: Dynammic Programming </a>
</li>
            
<li >
    <a href="../../../algorithm/algorithmStanford/heap/">Topic: Heap </a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">CS61B</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../calgorithm/s61b/index.md">Contents</a>
</li>
            
<li >
    <a href="../../../algorithm/cs61b/Lab1/">Lab1: javac, java, git</a>
</li>
            
<li >
    <a href="../../../algorithm/cs61b/Lab2/">Lab2: Unit Testing with JUnit and IntLists</a>
</li>
            
<li >
    <a href="../../../algorithm/cs61b/Lab3/">Lab3: Unit Testing with JUnit, Debugging</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">OS <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">OSC</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../os/osc/">Contents</a>
</li>
            
<li >
    <a href="../../../os/osc/ch1/">Chapter 1: Introduction </a>
</li>
            
<li >
    <a href="../../../os/osc/ch2/">Chapter 2: Operating System structures</a>
</li>
            
<li >
    <a href="../../../os/osc/ch3/">Chapter 3: Processes</a>
</li>
            
<li >
    <a href="../../../os/osc/ch4/">Chapter 4: Threads and Concurrency</a>
</li>
            
<li >
    <a href="../../../os/osc/ch5/">Chapter 5: CPU Scheduling</a>
</li>
            
<li >
    <a href="../../../os/osc/ch6/">Chapter 6: Synchronization Tools</a>
</li>
            
<li >
    <a href="../../../os/osc/ch7/">Chapter 7: Synchronization Examples</a>
</li>
            
<li >
    <a href="../../../os/osc/ch8/">Chapter 8: Deadlocks</a>
</li>
            
<li >
    <a href="../../../os/osc/ch9/">Chapter 9: Main Memory</a>
</li>
            
<li >
    <a href="../../../os/osc/ch10/">Chapter 10: Virtual Memory</a>
</li>
            
<li >
    <a href="../../../os/osc/ch11/">Chapter 11: Mass-Storage Structure</a>
</li>
            
<li >
    <a href="../../../os/osc/ch13/">Chapter 13: File-System Interfaces</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">CSAPP</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../os/csapp/">Contents</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch1/">Chapter 1: 计算机系统漫游</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch2/">Chapter 2: 信息的表示和处理</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch3/">Chapter 3: 程序的机器级表示</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch4/">Chapter 4: 处理器体系结构</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch5/">Chapter 5: 优化程序性能</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch6/">Chapter 6: 存储器层次结构</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch7/">Chapter 7: 链接</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch8/">Chapter 8: 异常控制流</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch9/">Chapter 9: 虚拟内存</a>
</li>
            
<li >
    <a href="../../../os/csapp/ch10/">Chapter 10: 系统级I/O</a>
</li>
            
<li >
    <a href="../../../csapp/ch11.md">Chapter 11: 网络编程</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">DataBase <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">MySql</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../mysql/index.md">Contents</a>
</li>
            
<li >
    <a href="../../../mysql/LearningMySQLandMariaDB.md">Chapter Learning MySQL and MariaDB</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Java <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">HFJ</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../java/hfj/">Contents</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch1/">Chapter 1: Dive in A Quick Dip</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch2/">Chapter 2: Classes and Objects</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch3/">Chapter 3: Primitives and References</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch4/">Chapter 4: Methods use Instance Variables</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch5/">Chapter 5: Writing a Program</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch6/">Chapter 6: Get to Know the Java API</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch7/">Chapter 7: Inheritance and Polymorphism</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch8/">Chapter 8: Interfaces and Abstract Classes</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch9/">Chapter 9: Constructors and Garbage Collection</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch10/">Chapter 10: Numbers and Statics</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch11/">Chapter 11: Exception Handling</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch12/">Chapter 12: Getting GUI</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch13/">Chapter 13: Using Swing</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch14/">Chapter 14: Serialization and File I/O</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch15/">Chapter 15: Networking and Threads</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch16/">Chapter 16: Collections and Generics</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch17/">Chapter 17: Packages, Jars and Deployment</a>
</li>
            
<li >
    <a href="../../../java/hfj/ch18/">Chapter 18: Remote deploy with RMI</a>
</li>
            
<li >
    <a href="../../../java/hfj/Appendix/">Appendix: The Top Ten Topics</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">HFDP</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../java/hfdp/">Contents</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch1/">Chapter 1: Strategy Pattern </a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch2/">Chapter 2: Observer Pattern</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch3/">Chapter 3: Decorator Pattern </a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch4/">Chapter 4: Factory Pattern</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch5/">Chapter 5: Singleton Pattern</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch6/">Chapter 6: Command Pattern</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch7/">Chapter 7: Adapter and Facade Patterns</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch8/">Chapter 8: Template Method Pattern</a>
</li>
            
<li >
    <a href="../../../java/hfdp/ch9/">Chapter 9: Iterator and Composite Patterns</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">TIJ</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../java/tij/">Contents</a>
</li>
            
<li >
    <a href="../../../java/tij/ch1/">Chapter 1: Introduction</a>
</li>
            
<li >
    <a href="../../../java/tij/ch2/">Chapter 2: Introduction to Objects</a>
</li>
            
<li >
    <a href="../../../java/tij/ch3/">Chapter 3: Everything is an Object</a>
</li>
            
<li >
    <a href="../../../java/tij/ch4/">Chapter 4: Opertors</a>
</li>
            
<li >
    <a href="../../../java/tij/ch5/">Chapter 5: Controlling Execution</a>
</li>
            
<li >
    <a href="../../../java/tij/ch6/">Chapter 6: Initialization & Cleanup</a>
</li>
            
<li >
    <a href="../../../java/tij/ch7/">Chapter 7: Access Control</a>
</li>
            
<li >
    <a href="../../../java/tij/ch8/">Chapter 8: Reusing Clases</a>
</li>
            
<li >
    <a href="../../../java/tij/ch9/">Chapter 9: Polymorphism</a>
</li>
            
<li >
    <a href="../../../java/tij/ch10/">Chapter 10: Interfaces</a>
</li>
            
<li >
    <a href="../../../java/tij/ch11/">Chapter 11: Inner Classes</a>
</li>
            
<li >
    <a href="../../../java/tij/ch12/">Chapter 12: Holding Your Objects</a>
</li>
            
<li >
    <a href="../../../java/tij/ch13/">Chapter 13: Error Handling with Exceptions</a>
</li>
            
<li >
    <a href="../../../java/tij/ch14/">Chapter 14: Strings</a>
</li>
            
<li >
    <a href="../../../java/tij/ch15/">Chapter 15: Type Information</a>
</li>
            
<li >
    <a href="../../../java/tij/ch16/">Chapter 16: Generics</a>
</li>
            
<li >
    <a href="../../../java/tij/ch17/">Chapter 17: Arrays</a>
</li>
            
<li >
    <a href="../../../java/tij/ch18/">Chapter 18: Containers in Depth</a>
</li>
            
<li >
    <a href="../../../java/tij/ch19/">Chapter 19: I/O</a>
</li>
            
<li >
    <a href="../../../java/tij/ch20/">Chapter 20: Enumerated Types</a>
</li>
            
<li >
    <a href="../../../java/tij/ch21/">Chapter 21: Annotations</a>
</li>
            
<li >
    <a href="../../../java/tij/ch22/">Chapter 22: Concurrency</a>
</li>
            
<li >
    <a href="../../../java/tij/ch23/">Chapter 23: Graphical User Interfaces</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">UJVM</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../java/ujvm/">Contents</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch1/">Chapter 1 : 走进Java</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch2/">Chapter 2 : Java内存区域与内存溢出正常</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch3/">Chapter 3 : 垃圾收集器与内存分配策略</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch4/">Chapter 4 : 虚拟机性能监控与故障处理工具</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch5/">Chapter 5 : 调优案例分析与实战</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch6/">Chapter 6 : 类文件结构</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch7/">Chapter 7 : 虚拟机类加载机制</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch8/">Chapter 8 : 虚拟机字节码执行引擎</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch9/">Chapter 9 : 类加载及执行子系统的案例与实战</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch10/">Chapter 10 : 早期(编译期)优化</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch11/">Chapter 11 : 晚期(运行期)优化</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch12/">Chapter 12 : Java内存模型与线程</a>
</li>
            
<li >
    <a href="../../../java/ujvm/ch13/">Chapter 13 : 线程安全与锁优化</a>
</li>
            
<li >
    <a href="../../../java/ujvm/AppendixC/">Appendix HotSpot虚拟机主要参数列表</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">BigData <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">HADOOP</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../hadoop/">Contents</a>
</li>
            
<li >
    <a href="../../hadoop/ch1/">Chapter 1: Meet Hadoop</a>
</li>
            
<li >
    <a href="../../hadoop/ch2/">Chapter 2: MapReduce</a>
</li>
            
<li >
    <a href="../../hadoop/ch3/">Chapter 3: The Hadoop Distributed FileSystem</a>
</li>
            
<li >
    <a href="../../hadoop/ch4/">Chapter 4: YARN</a>
</li>
            
<li >
    <a href="../../hadoop/ch5/">Chapter 5: Hadoop I/O</a>
</li>
            
<li >
    <a href="../../hadoop/ch6/">Chapter 6: Developing a MapReduce Application</a>
</li>
            
<li >
    <a href="../../hadoop/ch7/">Chapter 7: How MapReduce Works</a>
</li>
            
<li >
    <a href="../../hadoop/ch8/">Chapter 8: MapReduce Types and Formats</a>
</li>
            
<li >
    <a href="../../hadoop/ch9/">Chapter 9: MapReduce Features</a>
</li>
            
<li >
    <a href="../../hadoop/ch10/">Chapter 10: Setting Up a Hadoop Cluster</a>
</li>
            
<li >
    <a href="../../hadoop/ch11/">Chapter 11: Adminstering Hadoop</a>
</li>
            
<li >
    <a href="../../hadoop/ch12/">Chapter 12: Avro</a>
</li>
            
<li >
    <a href="../../hadoop/ch13/">Chapter 13: Parquet</a>
</li>
            
<li >
    <a href="../../hadoop/ch14/">Chapter 14: Flume</a>
</li>
            
<li >
    <a href="../../hadoop/ch15/">Chapter 15: Sqoop</a>
</li>
            
<li >
    <a href="../../hadoop/ch16/">Chapter 16: Pig</a>
</li>
            
<li >
    <a href="../../hadoop/ch17/">Chapter 17: Hive</a>
</li>
            
<li >
    <a href="../../hadoop/ch18/">Chapter 18: Crunch</a>
</li>
            
<li >
    <a href="../../hadoop/ch19/">Chapter 19: Spark</a>
</li>
            
<li >
    <a href="../../hadoop/ch20/">Chapter 20: HBase</a>
</li>
            
<li >
    <a href="../../hadoop/ch21/">Chapter 21: ZooKeeper</a>
</li>
            
<li >
    <a href="../../hadoop/ch22/">Chapter 22: Composable Data at Center</a>
</li>
            
<li >
    <a href="../../hadoop/ch23/">Chapter 23: Biological Data Science: Saving Lives with Software</a>
</li>
            
<li >
    <a href="../../hadoop/ch24/">Chapter 24: Cascading</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Spark</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../spark/">Contents</a>
</li>
            
<li >
    <a href="../../spark/ch1/">Chapter 1: Introduction to Data Analysis with Spark</a>
</li>
            
<li >
    <a href="../../spark/ch2/">Chapter 2: Downloading Spark and Getting Started</a>
</li>
            
<li >
    <a href="../../spark/ch3/">Chapter 3: Programming with RDDs</a>
</li>
            
<li >
    <a href="../../spark/ch4/">Chapter 4: Working with Key/Value Pairs</a>
</li>
            
<li >
    <a href="../../spark/ch5/">Chapter 5: Loading and Saving Your Data</a>
</li>
            
<li >
    <a href="../../spark/ch6/">Chapter 6: Advanced Spark Programming</a>
</li>
            
<li >
    <a href="../../spark/ch7/">Chapter 7: Running on a Cluster</a>
</li>
            
<li >
    <a href="../../spark/ch8/">Chapter 8: Tuning and Debugging Spark</a>
</li>
            
<li >
    <a href="../../spark/ch9/">Chapter 9: Spark SQL</a>
</li>
            
<li >
    <a href="../../spark/ch10/">Chapter 10: Spark Streaming</a>
</li>
            
<li >
    <a href="../../spark/ch11/">Chapter 11: Machine Learning with MLlib</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">GDM</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../gdm/">Contents</a>
</li>
            
<li >
    <a href="../../gdm/ch1/">Chapter 1: 推荐系统入门</a>
</li>
            
<li >
    <a href="../../gdm/ch2/">Chapter 2: 隐式评价和基于物品的过滤算法</a>
</li>
            
<li >
    <a href="../../gdm/ch3/">Chapter 3: 分类</a>
</li>
            
<li >
    <a href="../../gdm/ch4/">Chapter 4: 进一步探索分类</a>
</li>
            
<li >
    <a href="../../gdm/ch5/">Chapter 5: 概率和朴素贝叶斯</a>
</li>
            
<li >
    <a href="../../gdm/ch6/">Chapter 6: 朴素贝叶斯和文本数据</a>
</li>
            
<li >
    <a href="../../gdm/ch7/">Chapter 7: 聚类</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">MLIA</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../mlia/">Contents</a>
</li>
            
<li >
    <a href="../../mlia/ch1/">Chapter 1: 机器学习基础</a>
</li>
            
<li >
    <a href="../../mlia/ch2/">Chapter 2: k-近邻算法</a>
</li>
            
<li >
    <a href="../../mlia/ch3/">Chapter 3: 决策树</a>
</li>
            
<li >
    <a href="../../mlia/ch4/">Chapter 4: 基于概率论的分类方法：朴素贝叶斯</a>
</li>
            
<li >
    <a href="../../mlia/ch5/">Chapter 5: Logistic回归</a>
</li>
            
<li >
    <a href="../../mlia/ch6/">Chapter 6: 支持向量机</a>
</li>
            
<li >
    <a href="../../mlia/ch7/">Chapter 7: 利用AdaBoost元算法提高分类性能</a>
</li>
            
<li >
    <a href="../../mlia/ch8/">Chapter 8: 预测数值型数据：回归</a>
</li>
            
<li >
    <a href="../../mlia/ch9/">Chapter 9: 树回归</a>
</li>
            
<li >
    <a href="../../mlia/ch10/">Chapter 10: 利用Ｋ-均值聚类算法对未标注数据分组</a>
</li>
            
<li >
    <a href="../../mlia/ch11/">Chapter 11: 使用Apriori算法进行关联分析</a>
</li>
            
<li >
    <a href="../../mlia/ch11/">Chapter 12: 使用FP-growth算法来高效发现频繁项集</a>
</li>
            
<li >
    <a href="../../mlia/ch13/">Chapter 13: 利用PCA来简化数据</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Crawler</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../crawler/">Contents</a>
</li>
            
<li >
    <a href="../../crawler/ch1/">Chapter 1: 开发环境配置</a>
</li>
            
<li >
    <a href="../../crawler/ch2/">Chapter 2: 爬虫基础</a>
</li>
            
<li >
    <a href="../../crawler/ch3/">Chapter 3: 基本库的使用</a>
</li>
            
<li >
    <a href="../../crawler/ch4/">Chapter 4: 解析库的使用</a>
</li>
            
<li >
    <a href="../../crawler/ch5/">Chapter 5: 数据存储</a>
</li>
            
<li >
    <a href="../../crawler/ch7/">Chapter 7: 动态渲染页面爬取</a>
</li>
            
<li >
    <a href="../../crawler/ch13/">Chapter 13: Scrapy框架的使用</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Projects</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../">Contents</a>
</li>
            
<li class="active">
    <a href="./">SparkStreaming实时流处理</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li >
                                <a href="../../../books/">Books</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li >
                                <a rel="next" href="../">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="../../../books/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#spark-streaming">Spark Streaming实时流处理项目</a></li>
        <li class="main "><a href="#1">1 初识实时流处理</a></li>
            <li><a href="#_1">业务现状分析</a></li>
            <li><a href="#_2">实时流处理产生背景</a></li>
            <li><a href="#_3">实时流处理概述</a></li>
            <li><a href="#_4">离线计算与实时计算对比</a></li>
            <li><a href="#_5">实时流处理框架对比</a></li>
            <li><a href="#_6">实时流处理架构和技术选型</a></li>
            <li><a href="#_7">实时流处理在企业中的应用</a></li>
        <li class="main "><a href="#2-flume">2 分布式日志收集框架Flume</a></li>
            <li><a href="#_8">业务现状分析</a></li>
            <li><a href="#flume">Flume概述</a></li>
            <li><a href="#flume_1">Flume架构及核心组件</a></li>
            <li><a href="#flume_2">Flume实战</a></li>
        <li class="main "><a href="#3-kafka">3 分布式消息队列Kafka</a></li>
            <li><a href="#kafka">Kafka部署及使用</a></li>
            <li><a href="#kafka-java">Kafka Java 编程</a></li>
            <li><a href="#flumekafka">整合Flume和Kafka完成实时数据采集</a></li>
        <li class="main "><a href="#4-spark-streaming">4 Spark Streaming 入门</a></li>
            <li><a href="#_9">应用场景</a></li>
            <li><a href="#spark-streamingspark">Spark Streaming集成Spark生态系统的使用</a></li>
            <li><a href="#_10">发展史</a></li>
            <li><a href="#example">Example: 词频统计</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h3 id="spark-streaming"><strong>Spark Streaming实时流处理项目</strong><a class="headerlink" href="#spark-streaming" title="Permanent link">&para;</a></h3>
<p>该项目从实时数据产生和流向的不同环节出发，通过集成主流的分布式日志收集框架Flume、分布式消息队列Kafka、分布式列式数据库HBase、以及Spark Streaming实现实时流处理。</p>
<h3 id="1">1 初识实时流处理<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<h4 id="_1">业务现状分析<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<p>需求：统计主站每个（指定）课程访问的客户端、地域信息分布</p>
<p>==&gt; 如上两个操作：采用离线（spark/mapreduce）的方式进行统计</p>
<p>实现步骤：</p>
<ul>
<li>课程编号，ip信息，user-agent</li>
<li>进行相应的统计分析操作：MapReduce/Spark</li>
</ul>
<p>项目架构：</p>
<ul>
<li>日志收集：Flume</li>
<li>离线分析：MapReduce/Spark</li>
<li>统计结果图形化展示</li>
</ul>
<p>问题：</p>
<ul>
<li>小时级别</li>
<li>10分钟</li>
<li>秒级别</li>
</ul>
<h4 id="_2">实时流处理产生背景<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<ul>
<li>时效性高</li>
<li>数据量大</li>
</ul>
<h4 id="_3">实时流处理概述<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<p>https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101</p>
<ul>
<li>实时计算 apache storm</li>
<li>流式计算</li>
<li>实时流式计算</li>
</ul>
<h4 id="_4">离线计算与实时计算对比<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<ul>
<li>数据来源<ul>
<li>离线：来自HDFS上的历史数据，数据量比较大</li>
<li>实时：来自消息队列(Kafka)，是实时新增/修改记录过来的某一笔数据</li>
</ul>
</li>
<li>处理过程<ul>
<li>离线：MapReduce, map + reduce</li>
<li>实时: Spark(DStream/SS) </li>
</ul>
</li>
<li>处理速度<ul>
<li>离线：幔</li>
<li>实时：快速 </li>
</ul>
</li>
<li>进程<ul>
<li>离线：进程有启动+销毁的过程</li>
<li>实时： 7*24小时运行</li>
</ul>
</li>
</ul>
<h4 id="_5">实时流处理框架对比<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="http://storm.apache.org/">Apache Storm</a></li>
</ul>
<blockquote>
<p>Apache Storm is a free and open source distributed <strong>realtime</strong> computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!</p>
</blockquote>
<ul>
<li><a href="https://spark.apache.org/streaming/">Apache Spark Streaming</a></li>
</ul>
<blockquote>
<p>实际上是微批处理（批处理间隔非常小)</p>
</blockquote>
<ul>
<li><a href="http://kafka.apache.org/">Apache kafka</a></li>
<li><a href="https://flink.apache.org/">Apache Flink</a></li>
</ul>
<blockquote>
<p>Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.</p>
</blockquote>
<h4 id="_6">实时流处理架构和技术选型<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<p><img alt="实时流处理架构和技术选型" src="../figures/实时流处理架构和技术选型.jpg" /></p>
<p>加一层flume消息队列，主要为了减轻压力，起到缓冲作用</p>
<p><img alt="" src="../figures/15370800175689.jpg" /></p>
<h4 id="_7">实时流处理在企业中的应用<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<ul>
<li>电信行业： 你的手机套餐流量用完，收到短信提示</li>
<li>电商行业：搜索商品时，进行推荐</li>
</ul>
<h3 id="2-flume">2 分布式日志收集框架Flume<a class="headerlink" href="#2-flume" title="Permanent link">&para;</a></h3>
<p>see detail in Hadoop: definitive Guide, <a href="../hadoop/ch14/">Chapter 14</a></p>
<h4 id="_8">业务现状分析<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<p>You have a lot of servers and systems</p>
<ul>
<li>network devices</li>
<li>operating system</li>
<li>web servers</li>
<li>applications</li>
</ul>
<p>And they generate large amount of logs and other data.</p>
<p>Problem: Since you have a business idea, how to implement the idea?</p>
<p>OPTION: You may move logs and data generated to hadoop hdfs directly.</p>
<p>但是存在问题：</p>
<ul>
<li>如何做监控</li>
<li>如何保证时效性</li>
<li>直接传送文本数据，开销太大</li>
<li>容错</li>
<li>负载均衡</li>
</ul>
<p>SOLUTION: 使用Flume，基本上写配置文件就OK了，Flume自动解决以上问题。</p>
<h4 id="flume">Flume概述<a class="headerlink" href="#flume" title="Permanent link">&para;</a></h4>
<blockquote>
<p>Flume is a distributed, reliable, and available service for efficiently <strong>collecting, aggregating, and moving large amounts of log data</strong>. It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online analytic application. [<a href="http://flume.apache.org/">Apache Flume</a>]</p>
</blockquote>
<h4 id="flume_1">Flume架构及核心组件<a class="headerlink" href="#flume_1" title="Permanent link">&para;</a></h4>
<p><img alt="" src="../figures/apacheFlumeDemo.png" /></p>
<p>see detail in Hadoop: definitive Guide, <a href="../hadoop/ch14/">Chapter 14</a></p>
<h4 id="flume_2">Flume实战<a class="headerlink" href="#flume_2" title="Permanent link">&para;</a></h4>
<p><hh>需求： 从指定网络端口采集数据<hh></p>
<p>使用Flume的关键就是写配置文件</p>
<ul>
<li>配置Source, Channel, Sink</li>
<li>把以上三个组件串起来</li>
</ul>
<p> <div class=codehilite><pre>http://flume.apache.org/FlumeUserGuide.html#example-2
# example.conf: A single-node Flume configuration

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</pre></div></p>
<blockquote>
<p><CB>netcat source</CB>: A netcat-like source that listens on a given port and turns each line of text into an event. It opens a specified port and listens for data. The expectation is that the supplied data is newline separated text. Each line of text is turned into a Flume event and sent via the connected channel. [<a href="http://flume.apache.org/FlumeUserGuide.html#netcat-tcp-source">NetCat TCP Source</a>]</p>
<p><CB>logger sink</CB>: Logs event at INFO level. Typically useful for testing/debugging purpose.  [<a href="http://flume.apache.org/FlumeUserGuide.html#logger-sink">Logger Sink</a>]</p>
<p><CB>memory channel</CB>: The events are stored in an in-memory queue with configurable max size. It’s ideal for flows that need higher throughput and are prepared to lose the staged data in the event of an agent failures. [<a href="http://flume.apache.org/FlumeUserGuide.html#memory-channel0">memory channel</a>]</p>
</blockquote>
<p> <div class=codehilite><pre><span class=c1>## 启动flume</span>
$ flume-ng agent <span class=se>\</span>
--name a1 <span class=se>\ </span> <span class=c1># agent name</span>
--conf <span class=nv>$F</span>LUME_HOME/conf <span class=se>\ </span><span class=c1># use configs in &lt;conf&gt; directory</span>
--conf-file  example.conf <span class=se>\ </span><span class=c1># specify a config file</span>
-Dflume.root.logger<span class=o>=</span>INFO,console <span class=c1># sets a Java system property value</span>

<span class=c1>## 在另外一个terminal用telnet模拟数据源</span>
$ telnet localhost <span class=m>44444</span> 
Trying 127.0.0.1...
Connected to localhost.
Escape character is <span class=s1>&#39;^]&#39;</span>.
hello
OK
hellomy
OK
</pre></div></p>
<p><hh>需求： 监控一个文件实时采集新增的数据输出到控制台<hh></p>
<p>Agent选型： exec source + memory channel + logger sink</p>
<p> <div class=codehilite><pre># filename: exec-memeory-logger.conf

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /tmp/data.log

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</pre></div></p>
<blockquote>
<p><CB>exec source</CB> runs a given Unix command on start-up and expects that process to continuously produce data on standard out (stderr is simply discarded, unless property logStdErr is set to true). If the process exits for any reason, the source also exits and will produce no further data. This means configurations such as cat [named pipe] or tail -F [file] are going to produce the desired results where as date will probably not - the former two commands produce streams of data where as the latter produces a single event and exits. [<a href="http://flume.apache.org/FlumeUserGuide.html#exec-source">exec source</a>]</p>
</blockquote>
<p>将内容输入到<code class="codehilite">/tmp/data.log</code>文件中：</p>
<p> <div class=codehilite><pre>$ <span class=nb>echo</span> <span class=s2>&quot;hello&quot;</span> &gt; data.log
$ <span class=nb>echo</span> <span class=s2>&quot;hello&quot;</span> &gt; data.log
</pre></div></p>
<p><hh>需求： 将A服务器上的日志实时采集到B服务器<hh></p>
<p>日志收集过程：</p>
<ul>
<li>机器1上监控一个文件，当我们访问主站时会有用户行为日志记录到<code class="codehilite">access.log</code>中。</li>
<li>avro sink把新产生的日志输出到对应的avro source指定的hostname和port上。</li>
<li>通过avro对应的agent将我们的日志输出到控制台。</li>
</ul>
<p><img alt="" src="../figures/UsingAvroSink.png" /></p>
<blockquote>
<p><CB>avro sink</CB>: forms one half of Flume’s tiered collection support. Flume events sent to this sink are turned into Avro events and sent to the configured hostname / port pair. [<a href="http://flume.apache.org/FlumeUserGuide.html#avro-sink">Avro sink</a>]</p>
</blockquote>
<div class=md-fenced-code-tabs id=tab-tab-group-4><input name=tab-group-4 type=radio id=tab-group-4-0_text checked=checked class=code-tab data-lang=text aria-controls=tab-group-4-0_text-panel role=tab><label for=tab-group-4-0_text class=code-tab-label data-lang=text id=tab-group-4-0_text-label>Exec-Memeory-Avro.conf</label><div class=code-tabpanel role=tabpanel data-lang=text id=tab-group-4-0_text-panel aria-labelledby=tab-group-4-0_text-label><div class=codehilite><pre># filename: exec-memeory-avro.conf

# Name the components on this agent
a1.sources = exec-source
a1.sinks = avro-sink
a1.channels = memory-channel

# Describe/configure the source
a1.sources.exec-source.type = exec
a1.sources.exec-source.command = tail -F /tmp/data.log

# Describe the sink
a1.sinks.avro-sink.type = avro
a1.sinks.avro-sink.hostname = localhost
a1.sinks.avro-sink.port = 44444

# Use a channel which buffers events in memory
a1.channels.memory-channel.type = memory
a1.channels.memory-channel.capacity = 1000
a1.channels.memory-channel.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.exec-source.channels = memory-channel
a1.sinks.avro-sink.channel = memory-channel
</pre></div></div><input name=tab-group-4 type=radio id=tab-group-4-1_text class=code-tab data-lang=text aria-controls=tab-group-4-1_text-panel role=tab><label for=tab-group-4-1_text class=code-tab-label data-lang=text id=tab-group-4-1_text-label>Avro-Memeory-Logger.conf</label><div class=code-tabpanel role=tabpanel data-lang=text id=tab-group-4-1_text-panel aria-labelledby=tab-group-4-1_text-label><div class=codehilite><pre># filename: avro-memeory-logger.conf

# Name the components on this agent
a2.sources = avro-source
a2.sinks = logger-sink
a2.channels = memory-channel

# Describe/configure the source
a2.sources.avro-source.type = avro
a2.sources.avro-source.bind = localhost
a2.sources.avro-source.port = 44444

# Describe the sink
a2.sinks.logger-sink.type = logger

# Use a channel which buffers events in memory
a2.channels.memory-channel.type = memory
a2.channels.memory-channel.capacity = 1000
a2.channels.memory-channel.transactionCapacity = 100

# Bind the source and sink to the channel
a2.sources.avro-source.channels = memory-channel
a2.sinks.logger-sink.channel = memory-channel
</pre></div></div></div>

<p>启动flume， 注意两个agent的启动顺序</p>
<p> <div class=codehilite><pre>$ flume-ng agent <span class=se>\</span>
--name a2 <span class=se>\</span>
--conf <span class=nv>$F</span>LUME-HOME/conf <span class=se>\</span>
--conf-file avro-memory-logger.conf <span class=se>\</span>
-Dflume.root.logger<span class=o>=</span>INFO,console

$ flume-ng agent <span class=se>\</span>
--name a1 <span class=se>\</span>
--conf <span class=nv>$F</span>LUME-HOME/conf <span class=se>\</span>
--conf-file exec-memory-avro.conf <span class=se>\</span>
-Dflume.root.logger<span class=o>=</span>INFO,console
</pre></div></p>
<p>将内容输入到<code class="codehilite">/tmp/data.log</code>文件中：</p>
<p> <div class=codehilite><pre>$ <span class=nb>echo</span> <span class=s2>&quot;welcome&quot;</span> &gt; data.log
$ <span class=nb>echo</span> <span class=s2>&quot;welcome&quot;</span> &gt; data.log
</pre></div></p>
<h3 id="3-kafka">3 分布式消息队列Kafka<a class="headerlink" href="#3-kafka" title="Permanent link">&para;</a></h3>
<p>First a few concepts:</p>
<ul>
<li>Kafka is run as a cluster on one or more servers that can span multiple datacenters.</li>
<li>The Kafka cluster stores streams of <em>records</em> in categories called <strong><em>topic</em></strong>s.</li>
<li>Each record consists of a key, a value, and a timestamp.</li>
<li><strong><em>Broker</em></strong>s are the Kafka processes that manage topics and partitions and serve producer and consumer request.</li>
</ul>
<p><img alt="" src="../figures/kafkademo.jpg" /></p>
<h4 id="kafka">Kafka部署及使用<a class="headerlink" href="#kafka" title="Permanent link">&para;</a></h4>
<p><hh>单节点单Broker部署及使用</hh></p>
<p> <div class=codehilite><pre><span class=c1># 启动Zookeeper</span>
$ zkServer.sh start
<span class=c1># 启动kafka</span>
$ kafka-server-start.sh $KAFKA_HOME/config/server.properties
<span class=c1># 创建名为test的topic(single partition and only one replica)</span>
$ kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor <span class=m>1</span> --partitions <span class=m>1</span> --topic <span class=nb>test</span>
<span class=c1># 查看topic</span>
$ kafka-topics.sh --list --zookeeper localhost:2181
<span class=c1>### 启动生产者, 9092是server监听端口</span>
$ kafka-console-producer.sh --broker-list localhost:9092 --topic <span class=nb>test</span>
&gt; This is a message
&gt; This is another message
<span class=c1>### 启动消费者 --from-beginning从头开始接收消息</span>
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=nb>test</span> --from-beginning
This is a message
This is another message
<span class=c1>### 查看所有topics的详细信息</span>
$ kafka-topics.sh --describe --zookeeper localhost:2181
<span class=c1>### 查看指定topic的详细信息</span>
$ kafka-topics.sh --describe --zookeeper localhost:2181 --topic <span class=nb>test</span>
</pre></div></p>
<p><hh>单节点多Broker部署及使用</hh></p>
<p> <div class=codehilite><pre>cp $KAFKA_HOME/config/server.properties $KAFKA_HOME/config/server-1.properties
cp $KAFKA_HOME/config/server.properties $KAFKA_HOME/config/server-2.properties
</pre></div></p>
<p>修改配置文件如下</p>
<p> <div class=codehilite><pre>config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/tmp/kafka-logs-1

config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/tmp/kafka-logs-2
</pre></div></p>
<p>启动kafka</p>
<p> <div class=codehilite><pre><span class=c1># 启动ZooKeeper</span>
$ zkServer.sh start
<span class=c1># 启动kafka server</span>
$ kafka-server-start.sh $KAFKA_HOME/config/server.properties <span class=p>&amp;</span>
$ kafka-server-start.sh $KAFKA_HOME/config/server-1.properties <span class=p>&amp;</span>
$ kafka-server-start.sh $KAFKA_HOME/config/server-2.properties <span class=p>&amp;</span>
<span class=c1># 创建topic, 1个分区，三个副本</span>
$ kafka-topics.sh --create --zookeeper localhost:2181 <span class=se>\</span>
    --replication-factor <span class=m>3</span> --partitions <span class=m>1</span> --topic my-replicated-topic
<span class=c1># 查看topic信息</span>
$ kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: <span class=m>0</span>    Leader: <span class=m>2</span>   Replicas: 2,0,1 Isr: 2,0,1
<span class=c1># 启动生产者</span>
$ kafka-console-producer.sh --broker-list localhost:9092, localhost:9093, localhost:9094 --topic my-replicated-topic
<span class=c1># 启动消费者</span>
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
</pre></div></p>
<h4 id="kafka-java">Kafka Java 编程<a class="headerlink" href="#kafka-java" title="Permanent link">&para;</a></h4>
<p>使用命令行总是不方便的，下面我们尝试着使用Kafka Java API编程，实际操作内容和上一节是一摸一样的，所以直接附上代码了。注意这里使用的API是0.8.2版本以后的，之前版本与之后版本的API相差非常大。</p>
<div class=md-fenced-code-tabs id=tab-tab-group-11><input name=tab-group-11 type=radio id=tab-group-11-0_java checked=checked class=code-tab data-lang=java aria-controls=tab-group-11-0_java-panel role=tab><label for=tab-group-11-0_java class=code-tab-label data-lang=java id=tab-group-11-0_java-label>Producer</label><div class=code-tabpanel role=tabpanel data-lang=java id=tab-group-11-0_java-panel aria-labelledby=tab-group-11-0_java-label><div class=codehilite><pre><span class=kn>import</span> <span class=nn>org.apache.kafka.clients.producer.KafkaProducer</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>org.apache.kafka.clients.producer.ProducerRecord</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>java.util.Properties</span><span class=o>;</span>
<span class=cm>/**</span>
<span class=cm> * Kafka生产者</span>
<span class=cm> * 见官方文档</span>
<span class=cm> * http://kafka.apache.org/20/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</span>
<span class=cm> */</span>
<span class=kd>public</span> <span class=kd>class</span> <span class=nc>MyKafkaProducer</span> <span class=kd>implements</span> <span class=n>Runnable</span> <span class=o>{</span>
    <span class=kd>private</span> <span class=n>String</span> <span class=n>topic</span><span class=o>;</span>
    <span class=kd>private</span> <span class=n>KafkaProducer</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>producer</span><span class=o>;</span>

    <span class=kd>public</span> <span class=nf>MyKafkaProducer</span><span class=o>(</span><span class=n>String</span> <span class=n>topic</span><span class=o>)</span> <span class=o>{</span>
        <span class=k>this</span><span class=o>.</span><span class=na>topic</span> <span class=o>=</span> <span class=n>topic</span><span class=o>;</span>
        <span class=n>Properties</span> <span class=n>props</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Properties</span><span class=o>();</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;bootstrap.servers&quot;</span><span class=o>,</span> <span class=s>&quot;localhost:9092&quot;</span><span class=o>);</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;acks&quot;</span><span class=o>,</span> <span class=s>&quot;all&quot;</span><span class=o>);</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;key.serializer&quot;</span><span class=o>,</span> <span class=s>&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class=o>);</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;value.serializer&quot;</span><span class=o>,</span> <span class=s>&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class=o>);</span>
        <span class=n>producer</span> <span class=o>=</span> <span class=k>new</span> <span class=n>KafkaProducer</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;(</span><span class=n>props</span><span class=o>);</span>
    <span class=o>}</span>

    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>run</span><span class=o>()</span> <span class=o>{</span>
        <span class=kt>int</span> <span class=n>messageNumber</span> <span class=o>=</span> <span class=mi>1</span><span class=o>;</span>
        <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
            <span class=n>String</span> <span class=n>message</span> <span class=o>=</span> <span class=s>&quot;message&quot;</span> <span class=o>+</span> <span class=n>messageNumber</span><span class=o>;</span>
            <span class=n>producer</span><span class=o>.</span><span class=na>send</span><span class=o>(</span><span class=k>new</span> <span class=n>ProducerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;(</span><span class=n>topic</span><span class=o>,</span> <span class=n>message</span><span class=o>));</span>
            <span class=n>messageNumber</span><span class=o>++;</span>
            <span class=k>try</span><span class=o>{</span>
                <span class=n>Thread</span><span class=o>.</span><span class=na>sleep</span><span class=o>(</span><span class=mi>5000</span><span class=o>);</span>
            <span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=n>Exception</span> <span class=n>ex</span><span class=o>)</span> <span class=o>{</span>
                <span class=n>ex</span><span class=o>.</span><span class=na>printStackTrace</span><span class=o>();</span>
            <span class=o>}</span>
        <span class=o>}</span>
    <span class=o>}</span>
<span class=o>}</span>
</pre></div></div><input name=tab-group-11 type=radio id=tab-group-11-1_java class=code-tab data-lang=java aria-controls=tab-group-11-1_java-panel role=tab><label for=tab-group-11-1_java class=code-tab-label data-lang=java id=tab-group-11-1_java-label>Consumer</label><div class=code-tabpanel role=tabpanel data-lang=java id=tab-group-11-1_java-panel aria-labelledby=tab-group-11-1_java-label><div class=codehilite><pre><span class=kn>import</span> <span class=nn>org.apache.kafka.clients.consumer.ConsumerRecord</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>org.apache.kafka.clients.consumer.ConsumerRecords</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>org.apache.kafka.clients.consumer.KafkaConsumer</span><span class=o>;</span>

<span class=kn>import</span> <span class=nn>java.time.Duration</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>java.util.Arrays</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>java.util.List</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>java.util.Properties</span><span class=o>;</span>
<span class=kn>import</span> <span class=nn>java.util.concurrent.atomic.AtomicBoolean</span><span class=o>;</span>

<span class=cm>/**</span>
<span class=cm> * Kafka消费者</span>
<span class=cm> * 官方文档</span>
<span class=cm> * http://kafka.apache.org/20/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html</span>
<span class=cm> */</span>
<span class=kd>public</span> <span class=kd>class</span> <span class=nc>MyKafkaConsumer</span> <span class=kd>implements</span> <span class=n>Runnable</span> <span class=o>{</span>
    <span class=kd>private</span> <span class=kd>final</span> <span class=n>AtomicBoolean</span> <span class=n>closed</span> <span class=o>=</span> <span class=k>new</span> <span class=n>AtomicBoolean</span><span class=o>(</span><span class=kc>false</span><span class=o>);</span>
    <span class=kd>private</span> <span class=n>String</span> <span class=n>topic</span><span class=o>;</span>
    <span class=kd>private</span> <span class=n>KafkaConsumer</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>consumer</span><span class=o>;</span>
    <span class=kd>private</span> <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span><span class=o>;</span>

    <span class=kd>public</span> <span class=nf>MyKafkaConsumer</span><span class=o>(</span><span class=n>String</span> <span class=n>topic</span><span class=o>)</span> <span class=o>{</span>
        <span class=k>this</span><span class=o>.</span><span class=na>topic</span> <span class=o>=</span> <span class=n>topic</span><span class=o>;</span>
        <span class=n>Properties</span> <span class=n>props</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Properties</span><span class=o>();</span>
        <span class=c1>// connect to cluster</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;bootstrap.servers&quot;</span><span class=o>,</span> <span class=s>&quot;localhost:9092&quot;</span><span class=o>);</span>
        <span class=c1>//  subscribing to the topics- test</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;group.id&quot;</span><span class=o>,</span> <span class=s>&quot;test&quot;</span><span class=o>);</span>
        <span class=c1>//  offsets are committed automatically</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;enable.auto.commit&quot;</span><span class=o>,</span> <span class=s>&quot;true&quot;</span><span class=o>);</span>
        <span class=c1>// specify how to turn bytes into objects</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;key.deserializer&quot;</span><span class=o>,</span> <span class=s>&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class=o>);</span>
        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&quot;value.deserializer&quot;</span><span class=o>,</span> <span class=s>&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class=o>);</span>
        <span class=n>consumer</span> <span class=o>=</span> <span class=k>new</span> <span class=n>KafkaConsumer</span><span class=o>&lt;&gt;(</span><span class=n>props</span><span class=o>);</span>

    <span class=o>}</span>

    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>run</span><span class=o>()</span> <span class=o>{</span>
        <span class=k>try</span> <span class=o>{</span>
            <span class=c1>// subsribes to topic</span>
            <span class=n>consumer</span><span class=o>.</span><span class=na>subscribe</span><span class=o>(</span><span class=n>Arrays</span><span class=o>.</span><span class=na>asList</span><span class=o>(</span><span class=n>topic</span><span class=o>));</span>
            <span class=k>while</span> <span class=o>(!</span><span class=n>closed</span><span class=o>.</span><span class=na>get</span><span class=o>())</span> <span class=o>{</span>
                <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>ofMillis</span><span class=o>(</span><span class=mi>10000</span><span class=o>));</span>
                <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span>
                    <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&quot;offset = %d, key = %s, value = %s%n&quot;</span><span class=o>,</span> <span class=n>record</span><span class=o>.</span><span class=na>offset</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>key</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>value</span><span class=o>());</span>
            <span class=o>}</span>
        <span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=n>Exception</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
            <span class=c1>// Ignore exception if closing</span>
            <span class=k>if</span> <span class=o>(!</span><span class=n>closed</span><span class=o>.</span><span class=na>get</span><span class=o>())</span> <span class=k>throw</span> <span class=n>e</span><span class=o>;</span>
        <span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
            <span class=n>consumer</span><span class=o>.</span><span class=na>close</span><span class=o>();</span>
        <span class=o>}</span>

    <span class=o>}</span>

    <span class=c1>// Shutdown hook which can be called from a separate thread</span>
    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>shutdown</span><span class=o>()</span> <span class=o>{</span>
        <span class=n>closed</span><span class=o>.</span><span class=na>set</span><span class=o>(</span><span class=kc>true</span><span class=o>);</span>
        <span class=n>consumer</span><span class=o>.</span><span class=na>wakeup</span><span class=o>();</span>
    <span class=o>}</span>

<span class=o>}</span>
</pre></div></div><input name=tab-group-11 type=radio id=tab-group-11-2_java class=code-tab data-lang=java aria-controls=tab-group-11-2_java-panel role=tab><label for=tab-group-11-2_java class=code-tab-label data-lang=java id=tab-group-11-2_java-label>Clientapp</label><div class=code-tabpanel role=tabpanel data-lang=java id=tab-group-11-2_java-panel aria-labelledby=tab-group-11-2_java-label><div class=codehilite><pre><span class=kd>public</span> <span class=kd>class</span> <span class=nc>ClientApp</span> <span class=o>{</span>
    <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=o>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=o>)</span> <span class=o>{</span>
        <span class=n>Thread</span> <span class=n>job</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Thread</span><span class=o>(</span><span class=k>new</span> <span class=n>MyKafkaProducer</span><span class=o>(</span><span class=s>&quot;test&quot;</span><span class=o>));</span>
        <span class=n>job</span><span class=o>.</span><span class=na>start</span><span class=o>();</span>
        <span class=n>Thread</span> <span class=n>job2</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Thread</span><span class=o>(</span><span class=k>new</span> <span class=n>MyKafkaConsumer</span><span class=o>(</span><span class=s>&quot;test&quot;</span><span class=o>));</span>
        <span class=n>job2</span><span class=o>.</span><span class=na>start</span><span class=o>();</span>
    <span class=o>}</span>
<span class=o>}</span>
</pre></div></div></div>

<h4 id="flumekafka">整合Flume和Kafka完成实时数据采集<a class="headerlink" href="#flumekafka" title="Permanent link">&para;</a></h4>
<p>为了将Flume的输出到Kafka，可以将agent2的logger sink替换成Kafka Sink。然后启动一个Kafka consumer从Kafka sink订阅消息。</p>
<p><img alt="" src="../figures/FlumeKafkaCombined.png" /></p>
<blockquote>
<p><CB>kafka sink</CB> can publish data to a Kafka topic. One of the objective is to integrate Flume with Kafka so that pull based processing systems can process the data coming through various Flume sources. [<a href="http://flume.apache.org/FlumeUserGuide.html#kafka-sink">Kafka Sink</a>]</p>
</blockquote>
<p>下面是agent2对应的Kafka配置文件，在这里agent2改名为<code class="codehilite">avro-memory-kafka</code>。</p>
<p> <div class=codehilite><pre># filename: avro-memeory-kafka.conf

# Name the components on this agent
avro-memory-kafka.sources = avro-source
avro-memory-kafka.sinks = kafka-sink
avro-memory-kafka.channels = memory-channel

# Describe/configure the source
avro-memory-kafka.sources.avro-source.type = avro
avro-memory-kafka.sources.avro-source.bind = localhost
avro-memory-kafka.sources.avro-source.port = 44444

# Describe the sink
avro-memory-kafka.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
avro-memory-kafka.sinks.kafka-sink.kafka.bootstrap.servers = localhost:9092
avro-memory-kafka.sinks.kafka-sink.kafka.topic = test


# Use a channel which buffers events in memory
avro-memory-kafka.channels.memory-channel.type = memory
avro-memory-kafka.channels.memory-channel.capacity = 1000
avro-memory-kafka.channels.memory-channel.transactionCapacity = 100

# Bind the source and sink to the channel
avro-memory-kafka.sources.avro-source.channels = memory-channel
avro-memory-kafka.sinks.kafka-sink.channel = memory-channel
</pre></div></p>
<p>下面是具体的操作流程，同样需要注意两个agent的启动顺序：</p>
<p> <div class=codehilite><pre><span class=c1>## 启动zookeeper, kafka，省略</span>
<span class=c1>## 启动agent</span>
$ flume-ng agent <span class=se>\</span>
--name avro-memory-kafka <span class=se>\</span>
--conf <span class=nv>$F</span>LUME-HOME/conf <span class=se>\</span>
--conf-file avro-memory-kafka.conf <span class=se>\</span>
-Dflume.root.logger<span class=o>=</span>INFO,console

$ flume-ng agent <span class=se>\</span>
--name a1 <span class=se>\</span>
--conf <span class=nv>$F</span>LUME-HOME/conf <span class=se>\</span>
--conf-file exec-memory-avro.conf <span class=se>\</span>
-Dflume.root.logger<span class=o>=</span>INFO,console

<span class=c1>## 启动消费者 </span>
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class=nb>test</span>
</pre></div></p>
<h3 id="4-spark-streaming">4 Spark Streaming 入门<a class="headerlink" href="#4-spark-streaming" title="Permanent link">&para;</a></h3>
<blockquote>
<p>Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Flume, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like <C>map</C>, <C>reduce</C>, <C>join</C> and <C>window</C>. Finally, processed data can be pushed out to filesystems, databases, and live dashboards. In fact, you can apply Spark’s machine learning and graph processing algorithms on data streams. [<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">ref</a>]</p>
</blockquote>
<p><img alt="" src="../figures/sparkStreamingDemo1.png" /></p>
<blockquote>
<p>Spark Streaming receives live input data streams and divides the data into <strong>batches</strong>, which are then processed by the Spark engine to generate the final stream of results in batches.</p>
</blockquote>
<p><img alt="" src="../figures/sparkinput.png" /></p>
<h4 id="_9">应用场景<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<ul>
<li>React to anomalies in sensors in real-time</li>
</ul>
<h4 id="spark-streamingspark">Spark Streaming集成Spark生态系统的使用<a class="headerlink" href="#spark-streamingspark" title="Permanent link">&para;</a></h4>
<p><img alt="Spark" src="../figures/Spark.png" /></p>
<ul>
<li>Join data streams with static data sets</li>
</ul>
<p> <div class=codehilite><pre><span class=c1>// create data set from hadoop file</span>
<span class=k>val</span> <span class=n>dataset</span> <span class=k>=</span> <span class=n>sparkContext</span><span class=o>.</span><span class=n>hadoopFile</span><span class=o>(</span><span class=s>&quot;file&quot;</span><span class=o>)</span>
<span class=c1>// join each batch in stream with the dataset</span>
<span class=n>kafakaStream</span><span class=o>.</span><span class=n>transform</span><span class=o>{</span><span class=n>batchRDD</span><span class=k>=&gt;</span>
    <span class=n>batchRDD</span><span class=o>.</span><span class=n>join</span><span class=o>(</span><span class=n>dataset</span><span class=o>).</span><span class=n>filter</span><span class=o>(...)</span>
<span class=o>}</span>
</pre></div></p>
<ul>
<li>Learn models offline, apply them online</li>
</ul>
<p> <div class=codehilite><pre><span class=c1>//Learn model offline</span>
<span class=k>val</span> <span class=n>model</span> <span class=k>=</span> <span class=nc>KMeans</span><span class=o>.</span><span class=n>train</span><span class=o>(</span><span class=n>dataset</span><span class=o>,...)</span>

<span class=c1>//apply model online on stream</span>
<span class=n>kafkaStream</span><span class=o>.</span><span class=n>map</span><span class=o>{</span><span class=n>event</span><span class=o>=?</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=o>(</span><span class=n>event</span><span class=o>.</span><span class=n>feature</span><span class=o>)</span>
<span class=o>}</span>
</pre></div></p>
<ul>
<li>Interactively query streaming data with SQL</li>
</ul>
<p> <div class=codehilite><pre><span class=c1>// Register each batch in stream as table</span>
<span class=n>kafkaStream</span><span class=o>.</span><span class=n>map</span><span class=o>{</span> <span class=n>batchRDD</span> <span class=o>=?</span> <span class=n>batchRDD</span><span class=o>.</span><span class=n>registerTempTable</span><span class=o>(</span><span class=s>&quot;lastestEvents&quot;</span><span class=o>)</span>
<span class=o>}</span>
<span class=c1>//INteractively query table</span>
<span class=n>sqlContext</span><span class=o>.</span><span class=n>sql</span><span class=o>(</span><span class=s>&quot;select * from latestEvents&quot;</span><span class=o>)</span>
</pre></div></p>
<h4 id="_10">发展史<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<p><img alt="SparkHistory" src="../figures/SparkHistory.png" /></p>
<h4 id="example">Example: 词频统计<a class="headerlink" href="#example" title="Permanent link">&para;</a></h4>
<p><hh>spark-submit执行</hh></p>
<p>使用spark-submit来提交应用程序</p>
<p> <div class=codehilite><pre>$ spark-submit --master <span class=nb>local</span> <span class=se>\</span>
    --class org.apache.spark.examples.streaming.JavaNetworkWordCount <span class=se>\</span>
    --name NetworkWordCount <span class=se>\</span>
    spark-examples_2.11-2.3.1.jar localhost 9999
</pre></div></p>
<p><hh>spark-shell执行</hh></p>
<p>使用spark-submit来测试应用程序</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"search": 83, "next": 78, "help": 191, "previous": 80};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
        <script src="../../../extra_javascript/tabhack.js" defer></script>
        <script src="../../../extra_javascript/baidu.js" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
