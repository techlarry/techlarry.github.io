<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Operating System Concepts 5 - CPU Scheduling - techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">HomePage</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="wiki">WIKI</a></li>
        
        <li id=""><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">HomePage</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="wiki">WIKI</a></li>
        
        <li><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="programming_language.html">编程语言</a></li>
        
            <li><a href="data_structure_and_algorithm.html">数据结构和算法</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html">Python科学计算三维可视化</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">文献阅读</a></li>
        
            <li><a href="Tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>Operating System Concepts 5 - CPU Scheduling</h1>
     
        <div class="read-more clearfix">
          <span class="date">2018/3/27</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='Computer%20System.html'>Computer System</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <ul>
<li>
<a href="#toc_0">1 Basic Concepts</a>
<ul>
<li>
<a href="#toc_1">1.1 CPU-I/O Burst Cycle</a>
</li>
<li>
<a href="#toc_2">1.2 CPU Scheduler</a>
</li>
<li>
<a href="#toc_3">1.3 Preemptive and Nonpreemptive Scheduling</a>
</li>
<li>
<a href="#toc_4">1.4 Dispatcher</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">2 Scheduling Criteria</a>
</li>
<li>
<a href="#toc_6">3 Scheduling Algorithms</a>
<ul>
<li>
<a href="#toc_7">3.1 First-Come,First-Served scheduling, FCFS</a>
</li>
<li>
<a href="#toc_8">3.2 Shortest-job-first scheduling, SJF</a>
</li>
<li>
<a href="#toc_9">3.3 Round-Robin scheduling, RR</a>
</li>
<li>
<a href="#toc_10">3.4 Priority scheduling algorithm</a>
</li>
<li>
<a href="#toc_11">3.5 Multilevel Queue Scheduling</a>
</li>
<li>
<a href="#toc_12">3.6 Multilevel Feedback-Queue Scheduling</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">4 Thread Scheduling</a>
<ul>
<li>
<a href="#toc_14">4.1 Contention Scope</a>
</li>
<li>
<a href="#toc_15">4.2 Pthread Scheduling</a>
</li>
</ul>
</li>
<li>
<a href="#toc_16">5 Multi-Processor Scheduling</a>
<ul>
<li>
<a href="#toc_17">5.1 Approaches to Multiple-Processor Scheduling</a>
</li>
<li>
<a href="#toc_18">5.2 Multicore Processors</a>
</li>
<li>
<a href="#toc_19">5.3 Load Balancing</a>
</li>
<li>
<a href="#toc_20">5.4 Processor Afﬁnity</a>
</li>
</ul>
</li>
<li>
<a href="#toc_21">6 Real-Time CPU Scheduling</a>
</li>
<li>
<a href="#toc_22">7 Linux Scheduling</a>
</li>
</ul>


<p>On modern operating systems it is <strong>kernel-level threads</strong> —not processes—that are in fact being scheduled by the operating system. </p>

<ul>
<li>User-level threads are managed by a thread library, and the kernel is <em>unaware</em> of them.</li>
<li>To run on a CPU, user-level threads must ultimately be mapped to an associated kernel-level thread, although this mapping may be indirect and may use a lightweight process (LWP).</li>
</ul>

<h2 id="toc_0">1 Basic Concepts</h2>

<h3 id="toc_1">1.1 CPU-I/O Burst Cycle</h3>

<p>Process execution consists of a <strong>cycle</strong> of CPU execution and I/O wait. 进程执行由CPU执行周期和I/O等待周期组成。</p>

<ul>
<li>Processes alternate between these two states. 进程在这两个状态之间切换。</li>
<li>Process execution begins with a <strong>CPU burst</strong>, which is followed by an <strong>I/O burst</strong> and so on. 进程执行从CPU区间开始，在这之后是I/O区间。</li>
</ul>

<p>进程在CPU区间和I/O区间之间切换：<br/>
<img src="media/15326899337167/alternating%20sequence%20of%20CPU%20and%20I:O%20bursts.png" alt="alternating sequence of CPU and I:O bursts"/></p>

<p>The durations of CPU bursts tend to have a frequency curve similar to the figure below. </p>

<ul>
<li>The curve is generally characterized as <strong>exponential</strong> or hyperexpoential(超指数).</li>
<li>A large number of short CPU bursts and a small number of long CPU burst.</li>
<li>An I/O-bounded program typically has many short CPU bursts. I/O密集程序通常具有很多短CPU区间。</li>
<li>A CPU-bound program might have a few long CPU bursts.CPU密集程序可能有少量的长CPU区间。</li>
<li>The distribution can be important when implementing a CPU-scheduling algorithm. 分布有助于选择合适的CPU调度算法。</li>
</ul>

<p><img src="media/15326899337167/Histogram%20of%20CPU-burst%20durations.png" alt="Histogram of CPU-burst durations"/></p>

<h3 id="toc_2">1.2 CPU Scheduler</h3>

<p>Whenever the CPU becomes idle, the operating system must select one of the processes in the <strong>ready queue</strong>(就绪队列) to be executed. 每当CPU空闲时，操作系统就必须从就绪队列中选择一个进程来执行。</p>

<ul>
<li>The selection process is carried out by the <strong>CPU scheduler</strong>(CPU调度程序).  进程选择由CPU调度程序执行。</li>
<li>CPU scheduler selects a process from the processes in memory that are ready to execute and allocates the CPU to that process. 调度程序从内存中选择一个能够执行的进程，并为之分配CPU。</li>
<li>A ready queue can be implemented as a FIFO queue, a priority queue, a tree, or simply an unordered linked list. 就绪队列可以是FIFO队列，优先队列、树或无序链表。</li>
</ul>

<h3 id="toc_3">1.3 Preemptive and Nonpreemptive Scheduling</h3>

<p>CPU-scheduling decisions may take place under the following four circumstances: </p>

<ol>
<li>When a process switches from the running state to the waiting state (for example, as the result of an I/O request or an invocation of <code>wait()</code> for the termination of a child process) 当一个进程从运行状态切换到等待状态（如：I/O请求，或者调用wait等待一个子进程的终止） </li>
<li>When a process switches from the running state to the ready state (for example, when an interrupt occurs) 当一个进程从运行状态切换到就绪状态（如：出现中断） </li>
<li>When a process switches from the waiting state to the ready state (for example, at completion of I/O) 当一个进程从等待状态切换到就绪状态（如：I/O完成） </li>
<li>When a process terminates 当一个进程终止时</li>
</ol>

<p>When scheduling takes place only under circumstances 1 and 4, the scheduling scheme is <strong>nonpreemptive</strong>(非抢占的) or <strong>cooperative</strong>(协作的). Otherwise, it is <strong>preemptive</strong>(抢占的).</p>

<ul>
<li>Under nonpreemptive scheduling, once the CPU has been allocated to a process, the process keeps the CPU until it releases it either by terminating or by switching to the waiting state.</li>
<li>Virtually all modern Operating systems use preemptive scheduling algorithms. </li>
</ul>

<h3 id="toc_4">1.4 Dispatcher</h3>

<p>The <strong>dispatcher</strong>(分派程序) is the module that gives control of the CPU&#39;s core to the process selected by the CPU scheduler. This function involves the following:</p>

<ul>
<li>Switching context from one process to another</li>
<li>Switching to user mode</li>
<li>Jumping to the proper location in the user program to resume that program</li>
</ul>

<p><strong>Dispatch latency</strong> (分派延迟) is the time it takes for the dispatcher to stop one process and start another running.</p>

<p><img src="media/15326899337167/the%20role%20of%20dispatcher.png" alt="the role of dispatcher"/></p>

<h2 id="toc_5">2 Scheduling Criteria</h2>

<p>Scheduling criteria（调度准则) include the following:</p>

<ul>
<li><strong>CPU utilization</strong> (CPU利用率)</li>
<li><strong>Throughput</strong> (吞吐量)： the number of processes that are completed per time unit.</li>
<li><strong>Turnaround time</strong> (周转时间): the interval from the time of submission of a process to the time of completion.</li>
<li><strong>Waiting time</strong> (等待时间): the sum of time spent waiting in the ready queue.</li>
<li><strong>Response time</strong> (响应时间): the time from the submission of a request until the first response is produced.</li>
</ul>

<h2 id="toc_6">3 Scheduling Algorithms</h2>

<h3 id="toc_7">3.1 First-Come,First-Served scheduling, FCFS</h3>

<p>By far the simplest CPU-scheduling algorithm is the <strong>first-come first serve scheduling</strong> (先到先服务调度, FCFS) algorithm.</p>

<ul>
<li>The implementation of FCFS policy is easily managed with a <strong>FIFO queue</strong>.</li>
<li>The average <strong>waiting time</strong> under the FCFS policy is often quite <strong>long</strong>.</li>
<li><strong>Convoy effect</strong>(护航效果) occurs when all the other processes wait for the one big process to get off the CPU. 所有其他进程都等待一个大进程释放CPU，这称之为护航效果。</li>
<li>The FCFS scheduling algorithm is <strong>nonpreemptive</strong>. FCFS调度算法是非抢占的。</li>
</ul>

<h3 id="toc_8">3.2 Shortest-job-first scheduling, SJF</h3>

<p>The <strong>shortest-job-first scheduling</strong> (最短作业优先调度, SJF) algorithm associates with each process the length of the process&#39;s next CPU burst.</p>

<ul>
<li>When the CPU is available, it is assigned to the process that has the smallest <strong>next</strong> CPU burst.</li>
<li>It gives the <strong>minimum</strong> average waiting time for a given set of processes.</li>
<li>The SJF algorithm can be either preemptive or nonpreemptive.
<ul>
<li>Preempt the currently executing process: when a new process arrives at the ready queue while a previous process is still executing. The next CPU burst of the newly arrived process may be shorter than what is left of the currently executing process. </li>
</ul></li>
</ul>

<p>The next CPU burst is generally predicted as an <strong>exponential average</strong> of the measured lengths of previous CPU bursts. Let \(t_n\) be the length of the \(n\)th CPU burst, and let \(\tau_{n+1}\) be predicted value for the next CPU burst:</p>

<p>\[\tau_{n+1}= \alpha \tau_n + (1-\alpha) \tau_n\]</p>

<p>where \(0\le\alpha \le 1\), commonly \(\alpha = 1/2\).</p>

<h3 id="toc_9">3.3 Round-Robin scheduling, RR</h3>

<p>The <strong>round-robin scheduling</strong>(轮转调度) algorithm is similar to FCFS scheduling, but switch occurs after 1 <strong>time quantum</strong> (时间片).</p>

<ul>
<li>Time quantum is a small unit of time, generally from 10 to 100 milliseconds in length.</li>
<li>The ready queue is treated as a circular queue.</li>
<li>If the process have a CPU burst of less than 1 time quantum, the  process itself will release the CPU voluntarily.</li>
<li>otherwise, a context switch will be executed, and the process will be put at the tail of the ready queue.</li>
</ul>

<p>The performance of the RR algorithm depends heavily on the size of the time quantum.</p>

<ul>
<li>If extremely large, the RR policy is the same as the FCFS policy.</li>
<li>If extremely small, it&#39;ll result in a large number of context switches.</li>
</ul>

<h3 id="toc_10">3.4 Priority scheduling algorithm</h3>

<p>The <strong>priority-scheduling</strong>(优先级调度) algorithm associate each process a priority, and the CPU allocated to the process with the highest priority.</p>

<ul>
<li>FCFS: equal-priority</li>
<li>SJF: the priority is the inverse of the next CPU burst.</li>
</ul>

<p>ISSUE: <strong>Indefinite blocking</strong>(无限阻塞), or <strong>starvation</strong>(饥饿) occurs when some low-priority processes waiting indefinitely.</p>

<p>SOLUTION: <strong>Aging</strong>(老化) involves gradually increasing the priority of processes that wait in the system for a long time.</p>

<h3 id="toc_11">3.5 Multilevel Queue Scheduling</h3>

<p>For <strong>multilevel queue scheduling</strong>(多级队列调度), there are separate queues for each distinct priority, and priority scheduling simply schedules the process in the highest-priority queue.</p>

<p>A multilevel queue scheduling algorithm can be used to partition processes into several separate queuse based on the process type.<br/>
<img src="media/15326899337167/multilevel-queue-scheduling.png" alt="multilevel-queue-scheduling"/></p>

<p>In addition, there must be scheduling <u><em>among the queues</em></u> :</p>

<ul>
<li><strong>Fixed-priority preemptive scheduling</strong>(固定优先级抢占调度): Each queue has absolute priority over lower-priority queues
<ul>
<li>eg. no process in the batch queue, could run unless the queues for real-time processes, system processes, and interactive processes were all empty. </li>
</ul></li>
<li><strong>Time-slice among queues</strong>(队列之间划分时间片): each queue gets a certain portion of the CPU time.
<ul>
<li>eg. the foreground queue can be given 80 percent of the CPU time for RR scheduling among its processes, while the background queue receives 20 percent of the CPU to give to its processes on an FCFS basis.</li>
</ul></li>
</ul>

<h3 id="toc_12">3.6 Multilevel Feedback-Queue Scheduling</h3>

<p>The <strong>multilevel feedback queue scheduling</strong>(多级反馈队列调度) algorithm allows a process to move between queues.</p>

<ul>
<li>If a process uses too much CPU time, it will be moved to a lower-priority queue.
<ul>
<li>It leaves I/O-bound and interactive processes—which are typically characterized by short CPU bursts —in the higher-priority queues. </li>
</ul></li>
<li>A process that waits too long in a lower-priority queue may be moved to a higher-priority queue.
<ul>
<li>This form of aging prevent starvation.</li>
</ul></li>
</ul>

<p>In general, a multilevel feedback queue scheduler is defined by the following parameters:</p>

<ul>
<li>The number of queues</li>
<li>The scheduling algorithm for each queue</li>
<li>The method used to determine when to upgrade a process to a higher priority queue</li>
<li>The method used to determine when to demote a process to a lower priority queue</li>
<li>The method used to determine which queue a process will enter when that process needs service</li>
</ul>

<h2 id="toc_13">4 Thread Scheduling</h2>

<h3 id="toc_14">4.1 Contention Scope</h3>

<p><strong>Process contention scope</strong> (PCS，进程竞争范围), occurs when competition for the CPU takes place among threads belonging to the same process.</p>

<ul>
<li>the thread library schedules user-level threads to run on an available LWP, on systems implementing the many-to-one and many-to-many models.</li>
</ul>

<p>To decide which kernel-level thread to schedule onto a CPU, the kernel uses <strong>system-contention scope</strong> (SCS, 系统竞争范围).</p>

<ul>
<li>Systems using the one-to-one model, such as Windows and Linux schedule threads using only SCS.</li>
</ul>

<h3 id="toc_15">4.2 Pthread Scheduling</h3>

<p><strong>Pthreads</strong> identifies the following contention scope values:</p>

<ul>
<li><code>PTHREAD_SCOPE_PROCESS</code> schedules threads using PCS scheduling.</li>
<li><code>PTHREAD_SCOPE_SYSTEM</code> schedules threads using SCS scheduling.</li>
</ul>

<p>The Pthread IPC (Interprocess Communication) provides two functions for setting—and getting—the contention scope policy:</p>

<ul>
<li><code>pthread_attr_setscope(pthread_attr_t *attr, int scope)</code></li>
<li><code>pthread_attr_getscope(pthread_attr_t *attr, int *scope)</code></li>
</ul>

<pre><code class="language-c">#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;
#define NUM_THREADS 5

/* the thread runs in this function */
void *runner(void *param); 

int main(int argc, char *argv[])
{
    int i, scope;
    pthread_t tid[NUM_THREADS];     /* the thread identifier */
    pthread_attr_t attr;        /* set of attributes for the thread */

    /* get the default attributes */
    pthread_attr_init(&amp;attr);

    /* first inquire on the current scope */
    if (pthread_attr_getscope(&amp;attr,&amp;scope) != 0)
        fprintf(stderr, &quot;Unable to get scheduling scope.\n&quot;);
    else {
        if (scope == PTHREAD_SCOPE_PROCESS)
            printf(&quot;PTHREAD_SCOPE_PROCESS\n&quot;);
        else if (scope == PTHREAD_SCOPE_SYSTEM)
            printf(&quot;PTHREAD_SCOPE_SYSTEM\n&quot;);
        else 
            fprintf(stderr,&quot;Illegal scope value.\n&quot;);
    }
    
    /* set the scheduling algorithm to PCS or SCS */
    if (pthread_attr_setscope(&amp;attr, PTHREAD_SCOPE_SYSTEM) != 0)
        printf(&quot;unable to set scheduling policy.\n&quot;);

    /* create the threads */
    for (i = 0; i &lt; NUM_THREADS; i++) 
        pthread_create(&amp;tid[i],&amp;attr,runner,NULL); 

    /**
     * Now join on each thread
     */
    for (i = 0; i &lt; NUM_THREADS; i++) 
        pthread_join(tid[i], NULL);
}

/**
 * The thread will begin control in this function.
 */
void *runner(void *param) 
{
    /* do some work ... */

    pthread_exit(0);
}
</code></pre>

<h2 id="toc_16">5 Multi-Processor Scheduling</h2>

<h3 id="toc_17">5.1 Approaches to Multiple-Processor Scheduling</h3>

<p><strong>Asymmetric multiprocessing</strong> (AMP，非对称多处理)</p>

<ul>
<li>all scheduling decisions, I/O processing, and other system activities handled by a single processor -- the master server; the other processors execute only user code.  让一个处理器（主服务器）处理所有的调度决定、I/O处理以及其他系统活动，其他的处理器只执行用户代码。</li>
<li>it is simple because only one core accesses the system data structures, reducing the need for data sharing. 简单，因为只有一个处理器访问系统数据结构，减轻了数据共享的需要。</li>
<li>the master server becomes a potential bottleneck where overall system performance may be reduced.</li>
</ul>

<p><strong>Symmetric multiprocessing</strong> (SMP， 对称多处理)</p>

<ul>
<li>each processor is self-scheduling</li>
<li>it provides two possible strategies for organizing the threads eligible to be scheduled:
<ul>
<li>All threads may be in a _common ready queue_.
<ul>
<li>use some form of locking to protect the common ready queue from race condition</li>
<li>all accesses to the queue would require lock ownership, it would be a performance bottleneck.</li>
</ul></li>
<li>Each processor may have its own <u>private queue</u> of threads.
<ul>
<li>most common approach on systems supporting SMP</li>
<li>more efficient use of cache memory.</li>
</ul></li>
</ul></li>
</ul>

<p><img src="media/15326899337167/organization%20of%20ready%20queues.png" alt="organization of ready queues"/></p>

<h3 id="toc_18">5.2 Multicore Processors</h3>

<p><u>Issue</u> : memory stalls occurs when a processor accesses memory, it spends a significant amount of time waiting for the data to become available.</p>

<ul>
<li>occurs primarily because modern processors operate at much faster speeds than memory</li>
<li>occur because of a cache miss</li>
</ul>

<p><img src="media/15326899337167/memory%20stall.png" alt="memory stall"/><br/>
<u>Solution</u> : many recent hardware designs have implemented multithreaded processing cores in which two (or more) <strong>hardware threads</strong>(硬件线程) are assigned to each core.</p>

<ul>
<li>If one hardware thread stalls while waiting for memory, the core can switch to another thread.</li>
<li>From an operating system perspective, each hardware thread maintains its architectural state, such as instruction pointer and register set, and thus appears as a logical CPU that is available to run a software thread. This technique is known as <strong>chip multithreading</strong> (CMT, 芯片多线程). Intel use the term <strong>hyper-threading</strong>(超线程).</li>
<li><strong>NOTE</strong>: the resources of the physical core (such as caches and pipelines) are shared among its hardware threads, and a processing core can only execute one hardware thread at a time.</li>
</ul>

<p><img src="media/15326899337167/Chip%20multithreading.png" alt="Chip multithreading"/></p>

<p>Two levels of scheduling needed:</p>

<ul>
<li>It chooses which software thread to run on each hardware thread.
<ul>
<li>It may choose any scheduling algorithm. </li>
</ul></li>
<li>It chooses which hardware thread to run on CPU.
<ul>
<li>Use a simple round-robin algorithm</li>
<li>assigned to each hardware thread a dynamic urgency value ranging from 0 to 7, with 0 representing the lowest urgency and 7 the highest. </li>
</ul></li>
</ul>

<p><img src="media/15326899337167/two%20levels%20of%20scheduling.png" alt="two levels of scheduling"/></p>

<h3 id="toc_19">5.3 Load Balancing</h3>

<p><strong>Load balancing</strong>(负载均衡) attempts to keep the workload evenly distributed across all processors in an SMP system.</p>

<p>Two general approaches to load balancing:</p>

<ul>
<li><strong>Push migration</strong>: a specific task periodically checks the load on each processor and -- if it finds an imbalance -- evenly distributes the load by moving (or pushing) threads from overloaded to idle or less-busy processors.</li>
<li><strong>Pull migration</strong>: an idle processor pulls a waiting task from a busy processor.</li>
<li>They are not mutually exclusive and are, in fact, often implemented in parallel on load-balancing systems.</li>
</ul>

<h3 id="toc_20">5.4 Processor Afﬁnity</h3>

<p>Because of the high cost of invalidating and repopulating caches, most operating systems with SMP support try to <u>avoid migrating</u> a thread from one processor to another and instead attempt to keep a thread running on the same processor and take advantage of a warm cache. This is known as <strong>processor affinity</strong>(处理器亲和性)。</p>

<p>Common ready queue and per-processor ready queue(section 5.1):</p>

<ul>
<li>If we adopt the approach of a common ready queue, a thread may be selected for execution by any processor. Thus, if a thread is scheduled on a new processor, that processor’s cache must be repopulated.</li>
<li>With private, per-processor ready queues, a thread is always scheduled on the same processor and can therefore benefit from the contents of a warm cache.</li>
</ul>

<p>The main-memory architecture of a system can affect processor affinity issues as well. <strong>Non-uniform memory access</strong>(NUMA, 非一致性内存访问) where there are two physical processor chips each with their own CPU and local memory. A CPU has faster access to its local memory than to memory local to another CPU.</p>

<p><img src="media/15326899337167/numa%20and%20CPU%20scheduling.png" alt="numa and CPU scheduling"/></p>

<p>Interestingly, load balancing often <strong>counteracts</strong> the benefits of processor affinity.</p>

<h2 id="toc_21">6 Real-Time CPU Scheduling</h2>

<p>[to be continued]</p>

<h2 id="toc_22">7 Linux Scheduling</h2>

<p>The <strong><em>Completely Fair Scheduler</em></strong>（CFS，完全公平调度算法) is the default Linux scheduling algorithm.</p>

<ul>
<li>Each task has a <strong>virtual runtime</strong> value, which is its actual runtime normalized to the number of ready tasks.</li>
<li>Task priority is incorporated as a <strong>decay factor</strong> into this<br/>
formula. 
<ul>
<li>Lower-priority tasks have higher rates of decay than higher-priority tasks.</li>
</ul></li>
<li>The CPU is allocated to the task with the smallest virtual<br/>
runtime value.</li>
</ul>

<p>Standard Linux kernels implement two <strong>scheduling classes</strong>(调度类): </p>

<ul>
<li>a default scheduling class using the CFS scheduling algorithm </li>
<li>a real-time scheduling class.</li>
</ul>

<p>Each runnable task is placed in a <strong>red-black tree</strong> - a balanced binary search tree whose key is based on the value of virtual runtime <code>vruntime</code>.</p>

<ul>
<li>discover the leftmost node will require \(O(\log N)\) operations.</li>
<li>Linux scheduler caches the leftmost node in the variable <code>rb_leftmost</code>, and requires only retrieving the cached value.</li>
</ul>

<p><img src="media/15326899337167/15327413379278.gif" alt=""/></p>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="os_concepts_synchronization_tools.html" 
          title="Next Post: Operating System Concepts 6 - Synchronization Tools">Operating System Concepts 6 - Synchronization Tools &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          <div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://techlarry-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                                

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="programming_language.html"><strong>编程语言</strong></a>
        
            <a href="data_structure_and_algorithm.html"><strong>数据结构和算法</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>Python科学计算三维可视化</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>文献阅读</strong></a>
        
            <a href="Tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="os_concepts_CPU_scheduling.html">Operating System Concepts 5 - CPU Scheduling</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os_concepts_synchronization_tools.html">Operating System Concepts 6 - Synchronization Tools</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os_concepts_synchronization_examples.html">Operating System Concepts 7 - Synchronization Examples</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concets-processes.html">Operating System Concepts 3 - Processes</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="diagrammatize_TCP_IP.html">图解TCP/IP</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
