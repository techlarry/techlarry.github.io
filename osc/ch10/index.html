<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Zhenhua Wang">
        <link rel="canonical" href="http://larryim.cc/note/osc/ch10/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Chapter 10: Virtual Memory - Zhenhua's Notes</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../extra_css/custom.css" rel="stylesheet">
        <link href="../../extra_css/custom.js" rel="stylesheet">
        <link href="../../extra_css/friendly.css" rel="stylesheet">
        <link href="../../extra_css/theme.css" rel="stylesheet">
        <link href="../../extra_css/mkdocs/js/lunr-0.5.7.min.js" rel="stylesheet">
        <link href="../../extra_css/mkdocs/js/mustache.min.js" rel="stylesheet">
        <link href="../../extra_css/mkdocs/js/require.js" rel="stylesheet">
        <link href="../../extra_css/mkdocs/js/search.js" rel="stylesheet">
        <link href="../../extra_css/mkdocs/js/text.js" rel="stylesheet">
        <link href="../../extra_css/code-tab.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../..">Zhenhua's Notes</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="../..">Home</a>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">OSC <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../">Contents</a>
</li>
                            
<li >
    <a href="../ch1/">Chapter 1: Introduction </a>
</li>
                            
<li >
    <a href="../ch2/">Chapter 2: Operating System structures</a>
</li>
                            
<li >
    <a href="../ch3/">Chapter 3: Processes</a>
</li>
                            
<li >
    <a href="../ch4/">Chapter 4: Threads and Concurrency</a>
</li>
                            
<li >
    <a href="../ch5/">Chapter 5: CPU Scheduling</a>
</li>
                            
<li >
    <a href="../ch6/">Chapter 6: Synchronization Tools</a>
</li>
                            
<li >
    <a href="../ch7/">Chapter 7: Synchronization Examples</a>
</li>
                            
<li >
    <a href="../ch8/">Chapter 8: Deadlocks</a>
</li>
                            
<li >
    <a href="../ch9/">Chapter 9: Main Memory</a>
</li>
                            
<li class="active">
    <a href="./">Chapter 10: Virtual Memory</a>
</li>
                            
<li >
    <a href="../ch11/">Chapter 11: Mass-Storage Structure</a>
</li>
                            
<li >
    <a href="../ch13/">Chapter 13: File-System Interfaces</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">CSAPP <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../csapp/">Contents</a>
</li>
                            
<li >
    <a href="../../csapp/ch1/">Chapter 1: 计算机系统漫游</a>
</li>
                            
<li >
    <a href="../../csapp/ch2/">Chapter 2: 信息的表示和处理</a>
</li>
                            
<li >
    <a href="../../csapp/ch3/">Chapter 3: 程序的机器级表示</a>
</li>
                            
<li >
    <a href="../../csapp/ch4/">Chapter 4: 处理器体系结构</a>
</li>
                            
<li >
    <a href="../../csapp/ch5/">Chapter 5: 优化程序性能</a>
</li>
                            
<li >
    <a href="../../csapp/ch6/">Chapter 6: 存储器层次结构</a>
</li>
                            
<li >
    <a href="../../csapp/ch7/">Chapter 7: 链接</a>
</li>
                            
<li >
    <a href="../../csapp/ch8/">Chapter 8: 异常控制流</a>
</li>
                            
<li >
    <a href="../../csapp/ch9/">Chapter 9: 虚拟内存</a>
</li>
                            
<li >
    <a href="../../csapp/ch10/">Chapter 10: 系统级I/O</a>
</li>
                            
<li >
    <a href="../../csapp/ch11/">Chapter 11: 网络编程</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">HFJ <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../hfj/">Contents</a>
</li>
                            
<li >
    <a href="../../hfj/ch1/">Chapter 1: Dive in A Quick Dip</a>
</li>
                            
<li >
    <a href="../../hfj/ch2/">Chapter 2: Classes and Objects</a>
</li>
                            
<li >
    <a href="../../hfj/ch3/">Chapter 3: Primitives and References</a>
</li>
                            
<li >
    <a href="../../hfj/ch4/">Chapter 4: Methods use Instance Variables</a>
</li>
                            
<li >
    <a href="../../hfj/ch5/">Chapter 5: Writing a Program</a>
</li>
                            
<li >
    <a href="../../hfj/ch6/">Chapter 6: Get to Know the Java API</a>
</li>
                            
<li >
    <a href="../../hfj/ch7/">Chapter 7: Inheritance and Polymorphism</a>
</li>
                            
<li >
    <a href="../../hfj/ch8/">Chapter 8: Interfaces and Abstract Classes</a>
</li>
                            
<li >
    <a href="../../hfj/ch9/">Chapter 9: Constructors and Garbage Collection</a>
</li>
                            
<li >
    <a href="../../hfj/ch10/">Chapter 10: Numbers and Statics</a>
</li>
                            
<li >
    <a href="../../hfj/ch11/">Chapter 11: Exception Handling</a>
</li>
                            
<li >
    <a href="../../hfj/ch12/">Chapter 12: Getting GUI</a>
</li>
                            
<li >
    <a href="../../hfj/ch13/">Chapter 13: Using Swing</a>
</li>
                            
<li >
    <a href="../../hfj/ch14/">Chapter 14: Serialization and File I/O</a>
</li>
                            
<li >
    <a href="../../hfj/ch15/">Chapter 15: Networking and Threads</a>
</li>
                            
<li >
    <a href="../../hfj/ch16/">Chapter 16: Collections and Generics</a>
</li>
                            
<li >
    <a href="../../hfj/ch17/">Chapter 17: Packages, Jars and Deployment</a>
</li>
                            
<li >
    <a href="../../hfj/ch18/">Chapter 18: Remote deploy with RMI</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">CPJ <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../cpj/">Contents</a>
</li>
                            
<li >
    <a href="../../cpj/ch1/">Concurrent Programming in Java 1: Threads and Locks</a>
</li>
                            
<li >
    <a href="../../cpj/ch2/">Concurrent Programming in Java 2: Critical Sections and Isolation</a>
</li>
                            
<li >
    <a href="../../cpj/ch3/">Concurrent Programming in Java 3: Actors</a>
</li>
                            
<li >
    <a href="../../cpj/ch4/">Concurrent Programming in Java 4: Concurrent Data Structures</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">LKD <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../lkd/">Contents</a>
</li>
                            
<li >
    <a href="../../lkd/ch1/">Chapter 1 : Introduction to Linux Kernel</a>
</li>
                            
<li >
    <a href="../../lkd/ch2/">Chapter 2</a>
</li>
                            
<li >
    <a href="../../lkd/ch3/">Chapter 3</a>
</li>
                            
<li >
    <a href="../../lkd/ch4/">Chapter 4</a>
</li>
                            
<li >
    <a href="../../lkd/ch5/">Chapter 5</a>
</li>
                            
<li >
    <a href="../../lkd/ch6/">Chapter 6</a>
</li>
                            
<li >
    <a href="../../lkd/ch7/">Chapter 7</a>
</li>
                            
<li >
    <a href="../../lkd/ch8/">Chapter 8</a>
</li>
                            
<li >
    <a href="../../lkd/ch9/">Chapter 9</a>
</li>
                            
<li >
    <a href="../../lkd/ch10/">Chapter 10</a>
</li>
                            
<li >
    <a href="../../lkd/ch11/">Chapter 11</a>
</li>
                            
<li >
    <a href="../../lkd/ch12/">Chapter 12: Memory management</a>
</li>
                            
<li >
    <a href="../../lkd/ch13/">Chapter 13</a>
</li>
                            
<li >
    <a href="../../lkd/ch14/">Chapter 14</a>
</li>
                            
<li >
    <a href="../../lkd/ch15/">Chapter 15</a>
</li>
                            
<li >
    <a href="../../lkd/ch16/">Chapter 16</a>
</li>
                            
<li >
    <a href="../../lkd/ch17/">Chapter 17</a>
</li>
                            
<li >
    <a href="../../lkd/ch18/">Chapter 18</a>
</li>
                            
<li >
    <a href="../../lkd/ch19/">Chapter 19</a>
</li>
                            
<li >
    <a href="../../lkd/ch20/">Chapter 20</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">UJVM <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../ujvm/">Contents</a>
</li>
                            
<li >
    <a href="../../ujvm/ch1/">Chapter 1 : 走进Java</a>
</li>
                            
<li >
    <a href="../../ujvm/ch2/">Chapter 2 : Java内存区域与内存溢出正常</a>
</li>
                            
<li >
    <a href="../../ujvm/ch3/">Chapter 3 : 垃圾收集器与内存分配策略</a>
</li>
                            
<li >
    <a href="../../ujvm/ch4/">Chapter 4 : 虚拟机性能监控与故障处理工具</a>
</li>
                            
<li >
    <a href="../../ujvm/ch5/">Chapter 5 : 调优案例分析与实战</a>
</li>
                            
<li >
    <a href="../../ujvm/ch6/">Chapter 6 : 类文件结构</a>
</li>
                            
<li >
    <a href="../../ujvm/ch7/">Chapter 7 : 虚拟机类加载机制</a>
</li>
                            
<li >
    <a href="../../ujvm/ch8/">Chapter 8 : 虚拟机字节码执行引擎</a>
</li>
                            
<li >
    <a href="../../ujvm/ch9/">Chapter 9 : 类加载及执行子系统的案例与实战</a>
</li>
                            
<li >
    <a href="../../ujvm/ch10/">Chapter 10 : 早期(编译期)优化</a>
</li>
                            
<li >
    <a href="../../ujvm/ch11/">Chapter 11 : 晚期(运行期)优化</a>
</li>
                            
<li >
    <a href="../../ujvm/ch12/">Chapter 12 : Java内存模型与线程</a>
</li>
                            
<li >
    <a href="../../ujvm/ch13/">Chapter 13 : 线程安全与锁优化</a>
</li>
                            
<li >
    <a href="../../ujvm/AppendixC/">Appendix HotSpot虚拟机主要参数列表</a>
</li>
                        </ul>
                    </li>
                    <li >
                        <a href="../../books/">Books</a>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../ch9/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../ch11/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#operating-system-concepts-10-virtual-memory">Operating System Concepts 10 - Virtual Memory</a></li>
        <li class="main "><a href="#1-background">1 Background</a></li>
        <li class="main "><a href="#2-demand-paging">2 Demand Paging</a></li>
            <li><a href="#basic-concepts">Basic Concepts</a></li>
            <li><a href="#free-frame-list">Free-Frame List</a></li>
            <li><a href="#performance-of-demand-paging">Performance of Demand Paging</a></li>
        <li class="main "><a href="#3-copy-on-write">3 Copy-on-Write</a></li>
        <li class="main "><a href="#4-page-replacement">4 Page Replacement</a></li>
            <li><a href="#basic-page-replacement">Basic Page Replacement</a></li>
            <li><a href="#fifo-page-replacement">FIFO Page Replacement</a></li>
            <li><a href="#optimal-page-replacement-opt">Optimal Page Replacement, OPT</a></li>
            <li><a href="#lru-page-replacement-lru">LRU Page Replacement, LRU</a></li>
            <li><a href="#lru-approximation-page-replacement">LRU-Approximation Page Replacement</a></li>
        <li class="main "><a href="#5-allocation-of-frames">5 Allocation of Frames</a></li>
            <li><a href="#minimum-number-of-frames">Minimum Number of Frames</a></li>
            <li><a href="#allocation-algorithms">Allocation Algorithms</a></li>
            <li><a href="#global-versus-local-allocation">Global versus Local Allocation</a></li>
        <li class="main "><a href="#6-thrashing">6 Thrashing</a></li>
            <li><a href="#cause-of-thrashing">Cause of Thrashing</a></li>
            <li><a href="#working-set-model">Working-Set Model</a></li>
            <li><a href="#page-fault-frequency">Page-Fault Frequency</a></li>
        <li class="main "><a href="#7-memory-compression">7 Memory Compression</a></li>
        <li class="main "><a href="#8-allocating-kernel-memory">8 Allocating Kernel Memory</a></li>
            <li><a href="#buddy-system">Buddy System</a></li>
            <li><a href="#slab-allocations">Slab Allocations</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h3 id="operating-system-concepts-10-virtual-memory"><strong>Operating System Concepts 10 - Virtual Memory</strong><a class="headerlink" href="#operating-system-concepts-10-virtual-memory" title="Permanent link">&para;</a></h3>
<h3 id="1-background">1 Background<a class="headerlink" href="#1-background" title="Permanent link">&para;</a></h3>
<p>Various memory-management strategies discussed in <a href="../ch9/">Chapter 9</a> have the same goal to keep many processes in memory  simultaneously to allow multiprogramming.</p>
<p>PROBLEM: However, they tend to require that an entire process be in memory before it can execute.  In many cases, the entire program is not needed:</p>
<ul>
<li>Programs often have code to handle unusual error conditions. This code is almost never executed.</li>
<li>Arrays, lists, and tables are often allocated more memory than they actually needed.</li>
<li>Certain options and features of a program may be used rarely.</li>
</ul>
<p>SOLUTION: Virtual memory allows the execution of processes that are not completely in memory.</p>
<p>ADVANTAGE:</p>
<ul>
<li>Programs can be larger than physical memory.</li>
<li>Virtual memory abstracts main memory as viewed by the programmer from physical memory. It frees programmers from the concerns of memory-storage limitations.</li>
<li>Virtual memory allows processes to share files and memory through <a href="../ch9/#shared-pages">page sharing</a>.</li>
</ul>
<p><img alt="Diagram showing virtual memory that is larger than physical memory" src="../figures/Diagram%20showing%20virtual%20memory%20that%20is%20larger%20than%20physical%20memory.png" /></p>
<h3 id="2-demand-paging">2 Demand Paging<a class="headerlink" href="#2-demand-paging" title="Permanent link">&para;</a></h3>
<p>QUESTION: How an executable program might be loaded from secondary storage into memory?</p>
<p>OPTION: One option is to load the <em>entire</em> program in physical memory at program execution time.</p>
<p>PROBLEM: We may not initially <strong><em>need</em></strong> the entire program in memory. (e.g. a program starts with a list of available options from which the user is to select).</p>
<p>SOLUTION: <strong>Demand paging</strong>(按需调页) loads pages in memory only when they are needed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A demand-paging system is similar to a paging system with <a href="../ch9/#swapping-with-paging">swapping</a> where processes reside in secondary memory.</p>
</div>
<h4 id="basic-concepts">Basic Concepts<a class="headerlink" href="#basic-concepts" title="Permanent link">&para;</a></h4>
<p>Since demand paging loads pages in memory only when they are needed, some pages will be in memory and some will be in secondary storage. 
Thus, we need some form of hardware support to distinguish between the two.</p>
<p>The valid bit is set to ensure that the page is in the logical address space of the process and is currently in secondary storage. Access to a page marked invalid causes a <strong>page fault</strong>(缺页).</p>
<p>The procedure for handling this page fault is straightforward:</p>
<ol>
<li>We check page tables (usually kept with the process control block) for this process to determine whether the reference was a valid or an invalid memory access.</li>
<li>If the reference was invalid, we terminate the process. If it was valid but we have not yet brought in that page, we now page it in.</li>
<li>We find a free frame (by taking one from the free-frame list, for example).</li>
<li>We schedule a secondary storage operation to read the desired page into the newly allocated frame.</li>
<li>When the storage read is complete, we modify the internal table kept with the process and the page table to indicate that the page is now in memory.</li>
<li>We restart the instruction that was interrupted by the trap. The process can now access the page as though it had always been in memory.</li>
</ol>
<p><img alt="Steps in handling a page fault" src="../figures/Steps%20in%20handling%20a%20page%20fault.png" /></p>
<p>In the extreme case, we can start executing a process with <em>no</em> pages in memory. This scheme is <strong>pure demand paging</strong>: <em>never bring a page into memory until it is required</em> .</p>
<h4 id="free-frame-list">Free-Frame List<a class="headerlink" href="#free-frame-list" title="Permanent link">&para;</a></h4>
<p>Most operating system maintain a <strong>free-frame list</strong>, a pool of free frames for satisfying requests, that bring the desired pages from secondary storage into main memory.</p>
<p><img alt="List of free frames" src="../figures/List%20of%20free%20frames.png" /></p>
<p>Operating system typically allocate free frames using a technique known as <strong>zero-fill-on-demand</strong>, which "zero-out" frames before it is allocated (i.e. <em>erasing</em> previous contents). </p>
<h4 id="performance-of-demand-paging">Performance of Demand Paging<a class="headerlink" href="#performance-of-demand-paging" title="Permanent link">&para;</a></h4>
<p>Let <span><span class="MathJax_Preview">p(0\le p \le 1)</span><script type="math/tex">p(0\le p \le 1)</script></span> be <strong>page-fault rage</strong>(缺页率), the probability of a page fault. We would expect <span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span> to be close to zero. The effective access time, is </p>
<div>
<div class="MathJax_Preview">\text{effective access time} = (1-p)\times ma + p\times \text{page fault time}</div>
<script type="math/tex; mode=display">\text{effective access time} = (1-p)\times ma + p\times \text{page fault time}</script>
</div>
<p>where <span><span class="MathJax_Preview">ma</span><script type="math/tex">ma</script></span> denotes the memory-access time.</p>
<p>With an average page-fault service time of 8 milliseconds and a memory access time of 200 nanoseconds, the effective access time in nanoseconds is <span><span class="MathJax_Preview">200+7,999,800\times p</span><script type="math/tex">200+7,999,800\times p</script></span>. The effective access time is <em>directly proportional</em> to the page-fault rate <span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>, so it is important to keep the page-fault rate <em>low</em> in a demand-paging system.</p>
<p>An additional aspect of demand paging is the handling and overall use of swap space. </p>
<ul>
<li>I/O to swap space is generally faster than that to the file system, because swap space is allocated in much larger blocks, and file lookups an indirect allocation methods are not used (<a href="../ch11/6-swap-space-management">see details in Chapter 11</a>).</li>
<li>One OPTION: copying an entire file image into the swap space at process startup and then performing demand paging from the swap space.</li>
<li>Second OPTION: practiced by several operating system, including Linux and Windows ——— to demand-page from the file system initially but to write the pages to swap space as they are replaced.</li>
</ul>
<p>Mobile operating system typically do not support swapping [<a href="../ch9/#swapping-on-mobile-systems">Chapter 9</a>]. Instead, these systems demand-page from the file system and reclaim read-only pages (such as code) from applications if memory becomes constrained.</p>
<h3 id="3-copy-on-write">3 Copy-on-Write<a class="headerlink" href="#3-copy-on-write" title="Permanent link">&para;</a></h3>
<p><strong>Copy-on-write</strong>(写时复制) works by allowing the parent and child processes initially to share the same pages, and if either process writes to a shared page, a copy of the shared page is created.</p>
<p><img alt="copy_on_write" src="../figures/copy_on_write.png" /></p>
<h3 id="4-page-replacement">4 Page Replacement<a class="headerlink" href="#4-page-replacement" title="Permanent link">&para;</a></h3>
<p>When we increase degree of multiprogramming, over-allocating of memory results in page faults. The operating system determines where the desired page is residing on secondary storage but to find that there are <em>no</em> free frames on the free-frame list (i.e. all memory is in use).</p>
<p>Most operating systems now combine swapping pages with <strong>page replacement</strong>(页面置换).</p>
<h4 id="basic-page-replacement">Basic Page Replacement<a class="headerlink" href="#basic-page-replacement" title="Permanent link">&para;</a></h4>
<p>If no frame is free, we find one that is not currently being used and free it. When we select a page for replacement, We examine its <strong>modify bit</strong> (or <strong>dirty bit</strong>, see <a href="../../csapp/ch9/#core-i7_1">Example of Core i7</a>).</p>
<ul>
<li>The modify bit for a page is set by the hardware whenever any byte in the page is written into, indicating that the page has been modified.</li>
<li>If the bit is set, we must write the page to storage. Otherwise, we need not write the memory page to storage: it is already there.</li>
</ul>
<p>We must solve two major problems to implement demand paging:</p>
<ul>
<li><strong>frame-allocation algorithm</strong>: decide how many frames allocate to each process</li>
<li><strong>page-replacement algorithm</strong>: select the frames that are to be replaced. In general, we want the one with the lowest page-fault rate.</li>
</ul>
<h4 id="fifo-page-replacement">FIFO Page Replacement<a class="headerlink" href="#fifo-page-replacement" title="Permanent link">&para;</a></h4>
<p>The simplest page-replacement algorithm is a first-in, first-out(FIFO) algorithm. </p>
<ul>
<li>We can create a FIFO queue to hold all pages in memory. </li>
<li>We replace the page at the head of the queue. </li>
<li>When a page is brought into memory, we insert it at the tail of the queue.</li>
</ul>
<p><img alt="FIFO page-replacement algorith" src="../figures/FIFO%20page-replacement%20algorithm.png" /></p>
<p>DISADVANTAGE: Its performance is not <em>always</em> good.</p>
<p><strong>Belady’s anomaly</strong>: for some page-replacement algorithms, the page-fault rate may increase as the number of allocated frames increases.</p>
<p>Figure below shows the curve of page faults for the reference string <code class="codehilite">1,2,3,4,1,2,5,1,2,3,4,5</code> versus the number of available frames, with a FIFO page-replacement algorithm.</p>
<p><img alt="Page-fault curve for FIFO replacement on a reference string" src="../figures/Page-fault%20curve%20for%20FIFO%20replacement%20on%20a%20reference%20string.png" /></p>
<h4 id="optimal-page-replacement-opt">Optimal Page Replacement, OPT<a class="headerlink" href="#optimal-page-replacement-opt" title="Permanent link">&para;</a></h4>
<p><strong>Optimal page-replacement</strong>(OPT, 最佳页面置换) algorithm replaces the page that <strong>will not be used for the longest period of time</strong>.</p>
<p><img alt="Optimal page-replacement algorith" src="../figures/Optimal%20page-replacement%20algorithm.png" /></p>
<ul>
<li>It has the <strong>lowest</strong> page-fault rate of all algorithms.</li>
<li>It will never suffer from Belady's anomaly.</li>
<li>It is different to implement, because it requires future knowledge of the reference string.</li>
<li>It is used mainly for comparison studies.</li>
</ul>
<h4 id="lru-page-replacement-lru">LRU Page Replacement, LRU<a class="headerlink" href="#lru-page-replacement-lru" title="Permanent link">&para;</a></h4>
<p><strong>Least recently used</strong>(LRU, 最近最少使用) algorithm chooses the page that has not been used for the longest period of time.</p>
<p><img alt="LRU page-replacement algorithm" src="../figures/LRU%20page-replacement%20algorithm.png" /></p>
<ul>
<li>We can think of this strategy as the optimal page-replacement algorithm looking backward in time. ( If we let <span><span class="MathJax_Preview">S^R</span><script type="math/tex">S^R</script></span> be the reverse of a reference string <span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>, then the page-fault rate for the OPT algorithm on <span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span> is the same as the page-fault rate of OPT algorithm on <span><span class="MathJax_Preview">S^R</span><script type="math/tex">S^R</script></span>). </li>
<li>The LRU policy is <em>often</em> used as a page-replacement algorithm and is considered to be good.</li>
<li>Best way to implement LRU replacement with a stack of page numbers is using a doubly linked list with a head pointer and a tail pointer.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation of LRU would be not conceivable without hardware assistance beyond the standard TLB registers. The updating of stack must be done for every memory reference.</p>
<p>If we were to use an interrupt for every reference to allow software to update such data structures, it would slow every memory reference by a factor of at least ten, hence slowing every process by a factor of ten. Few systems could tolerate that level of overhead for memory management.</p>
</div>
<h4 id="lru-approximation-page-replacement">LRU-Approximation Page Replacement<a class="headerlink" href="#lru-approximation-page-replacement" title="Permanent link">&para;</a></h4>
<p>In fact, some systems provide no hardware support, using the form of a reference bit instead. The <strong>reference bit</strong> for a page is set by the hardware whenever that page is referenced(either a <em>read</em> or a <em>write</em> to any byte in the page).</p>
<p><strong>Additional-Reference-Bits Algorithm</strong></p>
<p>We can gain additional ordering information by recording the reference bits at regular intervals. </p>
<ul>
<li>We can keep an 8-bit byte for each page in a table in memory. </li>
<li>At regular intervals (say, every 100 milliseconds), a timer interrupt transfers control to the operating system. </li>
<li>The operating system shifts the reference bit for each page into the high-order bit of its 8-bit byte, shifting the other bits right by 1 bit and discarding the low-order bit.</li>
<li>These 8-bit shift registers contain the history of page use for the last eight time periods.</li>
<li>If we interpret these 8-bit bytes as unsigned integers, the page with the lowest number is the LRU page, and it can be replaced.</li>
</ul>
<p><strong>Second-Chance Algorithm</strong></p>
<p>The number of bits of history included in the shift register can be varied, the number can be reduced to zero, leaving only the reference bit itself.</p>
<ul>
<li>When a page has been selected, we inspect its reference bit. </li>
<li>If the value is 0, we proceed to replace this page; but if the reference bit is set to 1, we give the page a second chance and move on to select the next FIFO page.</li>
<li>When a page gets a second chance, its reference bit is cleared, and its arrival time is reset to the current time. </li>
<li>Thus, a page that is given a second chance will not be replaced until all other pages have been replaced (or given second chances). I</li>
<li>n addition, if a page is used often enough to keep its reference bit set, it will never be replaced.</li>
</ul>
<p>One way to implement the second-chance algorithm (sometimes referred to as the clock algorithm) is as a circular queue.</p>
<ul>
<li>A pointer (that is, a hand on the clock) indicates which page is to be replaced next. </li>
<li>When a frame is needed, the pointer advances until it finds a page with a 0 reference bit. </li>
<li>As it advances, it clears the reference bits. </li>
<li>Once a victim page is found, the page is replaced, and the new page is inserted in the circular queue in that position.</li>
</ul>
<p><img alt="Second-chance -clock- page-replacement algorith" src="../figures/Second-chance%20-clock-%20page-replacement%20algorithm.png" /></p>
<p>A simple example is illustrated by the figure below, in which small blue digits denotes the reference bit and green arrow denotes the pointer.</p>
<p><img alt="second-chance-algorithm-reference-string-demo" src="../figures/second-chance-algorithm-reference-string-demo.png" /></p>
<h3 id="5-allocation-of-frames">5 Allocation of Frames<a class="headerlink" href="#5-allocation-of-frames" title="Permanent link">&para;</a></h3>
<h4 id="minimum-number-of-frames">Minimum Number of Frames<a class="headerlink" href="#minimum-number-of-frames" title="Permanent link">&para;</a></h4>
<p>We must allocate at least a minimum  number of frames.</p>
<ul>
<li>One reason is performance. Obviously, as the number of frames allocated to each process decreases, the page-fault rate increases.</li>
<li>Another reason is that when a page fault occurs before an executing instruction complete, the instruction must be restarted. So we must have enough frames to hold all the different pages that any single instruction can reference.</li>
</ul>
<p>The minimum number of frames is defined by the computer architecture.</p>
<h4 id="allocation-algorithms">Allocation Algorithms<a class="headerlink" href="#allocation-algorithms" title="Permanent link">&para;</a></h4>
<p><strong>Equal Allocation</strong></p>
<p>The easiest way to split <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> frames among <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> processes is to give everyone an equal share, <span><span class="MathJax_Preview">m/n</span><script type="math/tex">m/n</script></span> frames (ignoring frames needed by the operating system for the moment).</p>
<p><strong>Proportional Allocation</strong></p>
<p>In proportional allocation, we allocate available memory to each process according to its size. Let the size of the virtual memory for process <span><span class="MathJax_Preview">p_i</span><script type="math/tex">p_i</script></span> be <span><span class="MathJax_Preview">s_i</span><script type="math/tex">s_i</script></span> , and define <span><span class="MathJax_Preview">S=\sum s_i</span><script type="math/tex">S=\sum s_i</script></span>. Then, if the total number of available frames is <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>, we allocate <span><span class="MathJax_Preview">a_i</span><script type="math/tex">a_i</script></span> frames to process <span><span class="MathJax_Preview">p_i</span><script type="math/tex">p_i</script></span> , where <span><span class="MathJax_Preview">a_i</span><script type="math/tex">a_i</script></span> is approximately <span><span class="MathJax_Preview">a_i=s_i/S\times m</span><script type="math/tex">a_i=s_i/S\times m</script></span>.</p>
<h4 id="global-versus-local-allocation">Global versus Local Allocation<a class="headerlink" href="#global-versus-local-allocation" title="Permanent link">&para;</a></h4>
<p><strong>Global replacement</strong> allows a process to select a replacement frame from the set of <em>all</em> frames, even if that frame is currently allocated to some other process; that is, one process can take a frame from another. </p>
<p><strong>Local replacement</strong> requires that each process select from only <em>its own</em> set of allocated frames.</p>
<p>Local replacement might <em>hinder</em> a process, however, by not making available to it other, less used pages of memory. Thus, global replacement generally results in <em>greater</em> system throughput. It is therefore the more commonly used method.</p>
<p><strong>Global Page-Replacement Policy</strong></p>
<p>Rather than waiting for the free-frame list to drop to zero before we begin selecting pages for replacement, we trigger page replacement when the list <em>falls below a certain threshold</em>.</p>
<ul>
<li>It attempts to ensure there is <em>always sufficient free</em> memory to satisfy new requests.</li>
<li>When the amount of free memory drops below minimum threshold, a kernel routine (<strong>reapers</strong>) is triggered that begins reclaiming pages from all processes in the system.</li>
<li>When the amount of free memory reaches the maximum threshold, the reaper routine is suspended.</li>
<li>The kernel reaper routine typically uses some form of LRU approximation.</li>
</ul>
<p><img alt="Reclaiming pages" src="../figures/Reclaiming%20pages.png" /></p>
<h3 id="6-thrashing">6 Thrashing<a class="headerlink" href="#6-thrashing" title="Permanent link">&para;</a></h3>
<h4 id="cause-of-thrashing">Cause of Thrashing<a class="headerlink" href="#cause-of-thrashing" title="Permanent link">&para;</a></h4>
<p>Thrashing may be caused by programs or workloads that present insufficient <strong>locality of reference</strong>(also principle of locality, 访问局部性): if the <strong>working set</strong>(工作集) of a program or a workload cannot be effectively held within physical memory, then constant data swapping, i.e., thrashing, may occur.</p>
<p>Consider the following scenario, which is based on the actual behavior of early paging systems.</p>
<ul>
<li>The operating system monitors CPU utilization. </li>
<li>If CPU utilizition is too low, we increase the degree of multiprogramming by introducing a new process to the system. </li>
<li>A global page-replacement algorithm is used; it replaces pages without regard to the process to which they belong. </li>
<li>Now suppose that a process enters a new phase in its execution and needs more frames. It starts faulting and taking frames away from other processes. </li>
<li>These processes need those pages, however, and so they also fault, taking frames from other processes. </li>
<li>These faulting processes must use the paging device to swap pages in and out. As they queue up for the paging device, the ready queue empties. As processes wait for the paging device, CPU utilization decreases.</li>
<li>The CPU scheduler sees the decreasing CPU utilization and increases the degree of multiprogramming as a result. </li>
<li>The new process tries to get started by taking frames from running processes, causing more page faults and a longer queue for the paging device. </li>
<li>As a result, CPU utilization drops even further, and the CPU scheduler tries to increase the degree of multiprogramming even more. Thrashing has occurred, and system throughput plunges. </li>
</ul>
<p><img alt="Thrashing" src="../figures/Thrashing.png" /></p>
<p>QUESTION: To prevent thrashing, we must provide a process with as many frames as it needs. But how do we know how many frames it "needs"? </p>
<p>The <strong>locality model</strong> of process execution, states that, as a process executes, it moves from locality to locality.</p>
<ul>
<li>A <strong>locality</strong> is a set of pages that are actively used together.</li>
<li>A running program is generally composed of several different localities, which may overlap.</li>
<li>If we do not allocate enough frames to accommodate the size of the current locality, the process will thrash, since it cannot keep in memory all the pages that it is actively using.</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Figure below illustrates the concept of locality and how a process’s locality changes over time. At time (a), the locality is the set of pages {18, 19, 20, 21, 22, 23, 24, 29, 30, 33}. At time (b), the locality changes to {18, 19, 20, 24, 25, 26, 27, 28, 29, 31, 32, 33}. Notice the overlap, as some pages (for example, 18, 19, and 20) are part of both localities.</p>
<p><img alt="Locality in a memory-reference pattern" src="../figures/Locality%20in%20a%20memory-reference%20pattern.png" /></p>
</div>
<h4 id="working-set-model">Working-Set Model<a class="headerlink" href="#working-set-model" title="Permanent link">&para;</a></h4>
<p>The group of physical memory pages currently dedicated to a specific process is known as the <strong>Working set</strong>(WS, 工作集) for that process. </p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>For example, the working set at time <span><span class="MathJax_Preview">t_1</span><script type="math/tex">t_1</script></span> is {1, 2, 5, 6, 7}. By time <span><span class="MathJax_Preview">t_2</span><script type="math/tex">t_2</script></span> , the working set has changed to {3, 4}.</p>
<p><img alt="Working-set mode" src="../figures/Working-set%20model.png" /></p>
</div>
<p>If we compute the working-set size <span><span class="MathJax_Preview">WSS_i</span><script type="math/tex">WSS_i</script></span> for each process in the system, the total demand for frames <span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> is <span><span class="MathJax_Preview">D=\sum WSS_i</span><script type="math/tex">D=\sum WSS_i</script></span>.</p>
<p>If the total demand <span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> is greater than the total number of available frames (<span><span class="MathJax_Preview">D\gt m</span><script type="math/tex">D\gt m</script></span>), thrashing will occur, because some processes will not have enough frames.</p>
<p>WORKING SET SOLUTION TO THRASHING: </p>
<ul>
<li>The operating system monitors the working set of each process and allocates to that working set enough frames to provide it with its working-set size. </li>
<li>If there are enough extra frames, another process can be initiated.</li>
<li>If the sum of the working-set sizes increases, exceeding the total number of available frames, the operating system selects a process to suspend. </li>
<li>The process’s pages are written out (swapped), and its frames are reallocated to other processes. The suspended process can be restarted later.</li>
</ul>
<h4 id="page-fault-frequency">Page-Fault Frequency<a class="headerlink" href="#page-fault-frequency" title="Permanent link">&para;</a></h4>
<p>The working-set model is successful but seems a clumsy way to control thrashing.</p>
<p>A strategy that uses the <strong>page-fault frequency</strong>(PFF) takes a more direct approach:</p>
<ul>
<li>Thrashing has a high page-fault rate. Thus, we control the page-fault rate.<ul>
<li>When the page fault rate is too high, we know that the process needs more frames.</li>
<li>Conversely, if it too low, then the process may have too many frames. </li>
</ul>
</li>
<li>We can establish upper and lower bounds on the desired page-fault rate.<ul>
<li>If the actual page-fault rate exceeds the upper limit, we allocate the process. another frame. </li>
<li>If the page-fault rate falls below the lower limit, we remove a frame from the process.</li>
</ul>
</li>
</ul>
<p><img alt="Page-fault frequency" src="../figures/Page-fault%20frequency.png" /></p>
<h3 id="7-memory-compression">7 Memory Compression<a class="headerlink" href="#7-memory-compression" title="Permanent link">&para;</a></h3>
<p>When the number of free frames falls below a certain threshold that would triggers page replacement, rather than paging out modified frames to swap space, we <em>compress</em> several frames into a single frame (<strong>memory compression</strong>, 内存压缩), enabling the system to reduce memory usage without resorting to swapping pages.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>For example, the free-frame list contains six frames: <code class="codehilite">7,2,9,21,27,16</code>, and the modified frame list contains four frames: <code class="codehilite">15, 3, 35, 26</code>.
In Figure below, frame 7 is removed from the free-frame list. Frames 15, 3, and 35 are compressed and stored in frame 7, which is then stored in the list of compressed frames. The frames 15, 3, and 35 can now be moved to the free-frame list. If one of the three compressed frames is later referenced, a page fault occurs, and the compressed frame is decompressed, restoring the three pages 15, 3, and 35 in memory.
<img alt="Free-frame list after compression" src="../figures/Free-frame%20list%20after%20compression.png" /></p>
</div>
<h3 id="8-allocating-kernel-memory">8 Allocating Kernel Memory<a class="headerlink" href="#8-allocating-kernel-memory" title="Permanent link">&para;</a></h3>
<p>Kernel memory is often allocated from a free-memory pool different from the list used to satisfy ordinary user-mode processes discussed before. There are two primary reasons for this:</p>
<ul>
<li>The kernel requests memory for data structures of varying sizes, some of which are less than a page in size. As a result, the kernel must use memory <em>conservatively</em> and attempt to <em>minimize waste</em> due to fragmentation.</li>
<li>Certain hardware devices interact directly with physical memory —— without the benefit of a virtual memory interface —— and consequently may require memory residing in physically <em>contiguous</em> pages.</li>
</ul>
<h4 id="buddy-system">Buddy System<a class="headerlink" href="#buddy-system" title="Permanent link">&para;</a></h4>
<p>The buddy system allocates memory from a fixed-size segment consisting of physically contiguous pages.</p>
<ul>
<li>Memory is allocated from this segment using a power-of-2 allocator, which satisfies requests in units sized as a power of 2 (4 KB, 8 KB, 16 KB, and so forth).</li>
<li>A request in units not appropriately sized is rounded up to the next highest power of 2.</li>
</ul>
<p>Pro and Cons:</p>
<ul>
<li>An advantage of the buddy system is how quickly adjacent buddies can be combined to form larger segments using a technique known as <strong>coalescing</strong>(illustrated below in the Example section).</li>
<li>Rounding up to the next highest power of 2 is very likely to cause internal fragmentation.</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Assume the size of a memory segment is initially 256 KB and the kernel requests 21 KB of memory. The segment is initially divided into two buddies—which we will call <span><span class="MathJax_Preview">A_L</span><script type="math/tex">A_L</script></span> and <span><span class="MathJax_Preview">A_R</span><script type="math/tex">A_R</script></span> —— each 128 KB in size. One of these buddies is further divided into two 64-KB buddies— <span><span class="MathJax_Preview">B_L</span><script type="math/tex">B_L</script></span> and <span><span class="MathJax_Preview">B_R</span><script type="math/tex">B_R</script></span> . However, the next-highest power of 2 from 21 KB is 32 KB so either <span><span class="MathJax_Preview">B_L</span><script type="math/tex">B_L</script></span> or <span><span class="MathJax_Preview">B_R</span><script type="math/tex">B_R</script></span> is again divided into two 32-KB buddies, <span><span class="MathJax_Preview">C_L</span><script type="math/tex">C_L</script></span> and <span><span class="MathJax_Preview">C_R</span><script type="math/tex">C_R</script></span> . One of these buddies is used to satisfy the 21-KB request. This scheme is illustrated in Figure below, where <span><span class="MathJax_Preview">C_L</span><script type="math/tex">C_L</script></span> is the segment allocated to the 21-KB request.</p>
<p><img alt="Buddy system allocation" src="../figures/Buddy%20system%20allocation.png" /></p>
<p>when the kernel releases the <span><span class="MathJax_Preview">C_L</span><script type="math/tex">C_L</script></span> unit it was allocated, the system can coalesce <span><span class="MathJax_Preview">C_L</span><script type="math/tex">C_L</script></span> and <span><span class="MathJax_Preview">C_R</span><script type="math/tex">C_R</script></span> into a 64-KB segment. This segment, <span><span class="MathJax_Preview">B_L</span><script type="math/tex">B_L</script></span> , can in turn be coalesced with its buddy <span><span class="MathJax_Preview">B_R</span><script type="math/tex">B_R</script></span> to form a 128-KB segment. Ultimately, we can end up with the original 256-KB segment.</p>
</div>
<h4 id="slab-allocations">Slab Allocations<a class="headerlink" href="#slab-allocations" title="Permanent link">&para;</a></h4>
<p>A second strategy for allocating kernel memory is known as <strong>slab allocation</strong>.</p>
<ul>
<li>A <strong>slab</strong> is made up of one or more physically contiguous pages. </li>
<li>A <strong>cache</strong> consists of one or more slabs.</li>
<li>Each of caches stores a different type of object. There is one cache per object type.(e.g.  a separate cache for the data structure representing process descriptors, a separate cache for file objects).</li>
<li>Each <strong>cache</strong> is populated with objects that are instantiations of the kernel data structure the cache represents.(e.g. the cache representing semaphores stores instances of semaphore objects).</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Linux kernel adopted the slab allocator after Version 2.2. Each slab contains some number of objects, which are the data structures being cached. </p>
<p>Each slab is in one of three states: <strong>full</strong>, <strong>partial</strong>, or <strong>empty</strong>.</p>
<ul>
<li>A full slab has no free objects. (All objects in the slab are allocated.) </li>
<li>An empty slab has no allocated objects. (All objects in the slab are free.) </li>
<li>A partial slab has some allocated objects and some free objects.</li>
</ul>
<p>When some part of the kernel requests a new object, the request is satisfied from a partial slab, if one exists. Otherwise, the request is satisfied from an empty slab.</p>
<p><img alt="linux slab" src="../figures/linuxslab.gif" /></p>
</div>
<p>The slab allocator provides two main benefits:</p>
<ul>
<li><em>No</em> memory is <em>wasted</em> due to fragmentation. Each unique kernel data structure has an associated cache, and each cache is made up of one or more slabs that are divided into chunks the size of the objects being represented.</li>
<li>Memory requests can be satisfied <em>quickly</em>. Objects are created in advance and thus can be quickly allocated from the cache. When the kernel has finished with an object and releases it, it is marked as free and returned to its cache, thus making it immediately available for subsequent requests from the kernel.</li>
</ul></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../..';</script>
        <script src="../../js/base.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script src="../../extra_javascript/tabhack.js"></script>
        <script src="../../search/require.js"></script>
        <script src="../../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
