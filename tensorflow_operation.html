<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  TensorFlow(4):TensorFlow Operation - techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">HomePage</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_blank" href="wiki">WIKI</a></li>
        
        <li id=""><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        <li id=""><a target="_blank" href="note">NOTE</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">HomePage</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_blank" href="wiki">WIKI</a></li>
        
        <li><a target="_self" href="notebook.html">NOTEBOOK</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        
        <li><a target="_blank" href="note">NOTE</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="programming_language.html">编程语言</a></li>
        
            <li><a href="data_structure_and_algorithm.html">数据结构和算法</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">文献阅读</a></li>
        
            <li><a href="Tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>TensorFlow(4):TensorFlow Operation</h1>
     
        <div class="read-more clearfix">
          <span class="date">2017/8/20</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='Tensorflow.html'>Tensorflow</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <ul>
<li>
<a href="#toc_0">1 Visualize with TensorBoard</a>
<ul>
<li>
<a href="#toc_1">Explicitly name operation, variable</a>
</li>
</ul>
</li>
<li>
<a href="#toc_2">2 Constant types</a>
<ul>
<li>
<a href="#toc_3">Tensors filled with a specific value</a>
</li>
<li>
<a href="#toc_4">Constants as sequences</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">3 Math Operations</a>
</li>
<li>
<a href="#toc_6">4 TensorFlow data types:</a>
<ul>
<li>
<a href="#toc_7">Python Native Types</a>
</li>
<li>
<a href="#toc_8">TensorFlow Native Types</a>
</li>
<li>
<a href="#toc_9">Numpy Data Types</a>
</li>
<li>
<a href="#toc_10">Constant</a>
</li>
<li>
<a href="#toc_11">Variables</a>
<ul>
<li>
<a href="#toc_12">Each session maintains its own copy of variable</a>
</li>
<li>
<a href="#toc_13">Use a variable to initialize another variables</a>
</li>
<li>
<a href="#toc_14">Session vs InteractiveSession,</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">Placeholder</a>
</li>
<li>
<a href="#toc_16">Lazy loading</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">1 Visualize with TensorBoard</h2>

<pre><code class="language-python">import tensorflow as tf
a = tf.constant(2, name=&#39;a&#39;)
b = tf.constant(3, name=&#39;b&#39;)
x = tf.add(a, b, name=&#39;add&#39;)
with tf.Session() as sess:
    writer = tf.summary.FileWriter(&#39;./graphs&#39;, sess.graph)
    print(sess.run(x))media/15033836099887
writer.close() # close the writer when you&#39;re done using it.
</code></pre>

<pre><code class="language-text">5
</code></pre>

<p>Bash command (to view TensorBoard):</p>

<pre><code class="language-bash"> tensorboard --logdir=&#39;./graphs&#39; --port 6006
 # open http://localhost:6006/#graphs in your browser
</code></pre>

<h3 id="toc_1">Explicitly name operation, variable</h3>

<pre><code class="language-python">a = tf.constant(2, name=&#39;a&#39;)
b = tf.constant(3, name=&#39;b&#39;)
x = tf.add(a,b,name=&#39;add&#39;)
with tf.Session() as sess:
    writer = tf.summary.FileWriter(&#39;./graphs&#39;, sess.graph)
    print(sess.run(x))
writer.close() # close the writer when you&#39;re done using it.
</code></pre>

<pre><code class="language-text">5
</code></pre>

<p>The figure produced by TensorBoard is as follows:</p>

<p><img src="media/15033836099887/explicit_name.png" alt=""/></p>

<p><strong>Note</strong>:  Learn to use TensorBoard well and often. It will help a lot when you build complicated models.</p>

<h2 id="toc_2">2 Constant types</h2>

<h3 id="toc_3">Tensors filled with a specific value</h3>

<p>Using <code>tensorflow.zeros</code> to fill tensor with zeros, which is similar to <code>Numpy</code>:</p>

<pre><code class="language-python">tf.zeros(shape, dtype=tf.float32, name=None)
</code></pre>

<p>For example,</p>

<pre><code class="language-python">x = tf.zeros([2,3], tf.int32)
with tf.Session() as sess:
    print(sess.run(x))
</code></pre>

<pre><code class="language-text">[[0 0 0]
 [0 0 0]]
</code></pre>

<p><code>tensorflow.zeros_like</code> return an tensor of zeros with the same shape and type as a given tensor. For example, we may want to have a tensor filled with zeros, with the same shape as <code>x</code>:</p>

<pre><code class="language-python">y = tf.zeros_like(x)
with tf.Session() as sess:
    print(sess.run(y))
</code></pre>

<pre><code class="language-text">[[0 0 0]
 [0 0 0]]
</code></pre>

<p>There are other command to fill tensor with a specific value, such as <code>tensorflow.ones</code>, <code>tensorflow.ones_like</code>, which of usage is similar to <code>tensorflow.zeros</code>, <code>tensorflow.zeros_like</code>.</p>

<p><code>tensorflow.fill</code> creates a tensor filled with a scalar value:</p>

<pre><code class="language-python">tf.fill(dims, value, name=None)
</code></pre>

<pre><code class="language-python">z = tf.fill([3,4],3)
with tf.Session() as sess:
    print(sess.run(z))
</code></pre>

<pre><code class="language-text">[[3 3 3 3]
 [3 3 3 3]
 [3 3 3 3]]
</code></pre>

<h3 id="toc_4">Constants as sequences</h3>

<p>You can create constants that are sequences, using <code>tf.linspace</code>, <code>tf.range</code>:</p>

<pre><code class="language-python">tf.linspace(start, stop, num, name=None)

# create a sequence of num evenly-spaced values are generated beginning at  start. If num &gt; 1, the values in the sequence increase by stop - start / num - 1, so that the last one is exactly stop.
# start, stop, num must be scalars
# comparable to but slightly different from numpy.linspace
# numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)

tf.range(start, limit=None, delta=1, dtype=None, name=&#39;range&#39;)
# create a sequence of numbers that begins at start and extends by increments of delta up to but not including limit
# slight different from range in Python
</code></pre>

<pre><code class="language-python">x = tf.linspace(10.0, 13.0, 4, name=&#39;linspace&#39;)
y = tf.range(3, 18)
z= tf.range(3, 18, 3)
with tf.Session() as sess:
    print(sess.run(x))
    print(sess.run(y))
    print(sess.run(z))
</code></pre>

<pre><code class="language-text">[ 10.  11.  12.  13.]
[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]
[ 3  6  9 12 15]
</code></pre>

<h2 id="toc_5">3 Math Operations</h2>

<p><img src="media/15033836099887/math_operations.png" alt=""/></p>

<pre><code class="language-python">a = tf.constant([[3,6],[0,0]])
b = tf.constant([[0,0],[2,2]])
x1 = tf.add(a, b)
x2 = tf.add_n([a,b,b]) # &gt;&gt; [7 10]. Equivalent to a + b + b
x3 = tf.multiply(a, b) # &gt;&gt; [6 12] because mul is element wise
x4 = tf.matmul(a, b) # &gt;&gt; ValueError
x5 = tf.matmul(tf.reshape(a, [4, 1]), tf.reshape(b, [1, 4])) # &gt;&gt; [[18]]

with tf.Session() as sess:
    sess.run(a)
    sess.run(b)
    print(&#39;x1:\n&#39;, sess.run(x1))
    print(&#39;x2:\n&#39;, sess.run(x2))
    print(&#39;x3:\n&#39;, sess.run(x3))
    print(&#39;x4:\n&#39;, sess.run(x4))
    print(&#39;x5:\n&#39;, sess.run(x5))
</code></pre>

<pre><code class="language-text">x1:
 [[3 6]
 [2 2]]
x2:
 [[3 6]
 [4 4]]
x3:
 [[0 0]
 [0 0]]
x4:
 [[12 12]
 [ 0  0]]
x5:
 [[ 0  0  6  6]
 [ 0  0 12 12]
 [ 0  0  0  0]
 [ 0  0  0  0]]
</code></pre>

<h2 id="toc_6">4 TensorFlow data types:</h2>

<h3 id="toc_7">Python Native Types</h3>

<p>TensorFlow takes Python natives types: <code>boolean</code>, <code>numeric</code> (<code>int</code>, <code>float</code>), <code>strings</code></p>

<p>TensorFlow takes in Python native types such as Python boolean values, numeric values (integers, floats), and strings. Single values will be converted to 0-d tensors (or scalars), lists of values will be converted to 1-d tensors (vectors), lists of lists of values will be converted to 2-d tensors (matrices), and so on.</p>

<pre><code class="language-python">tf.InteractiveSession() # open tensorflow interactivesession
t_0 = 19   # Treated as a 0-d tensor, or &quot;scalar&quot; 
print(&#39;t_0:&#39;,t_0)
print(tf.zeros_like(t_0))   # ==&gt; 0
print(tf.ones_like(t_0))   # ==&gt; 1
t_1 = [b&quot;apple&quot; ,  b&quot;peach&quot; ,  b&quot;grape&quot;]   # treated as a 1-d tensor, or &quot;vector&quot; 
print(&#39;t_1:&#39;,t_1)
print(tf.zeros_like(t_1))   # ==&gt; [&#39;&#39; &#39;&#39; &#39;&#39;]
t_2= [[ True, False, False],  [False, False, True], [False, True ,   False ]]   # treated as a 2-d tensor, or &quot;matrix&quot;
print(&#39;t_2:&#39;,t_2)
print(tf.zeros_like(t_2))   # ==&gt; 2x2 tensor, all elements are False 
print(tf.ones_like(t_2))   # ==&gt; 2x2 tensor, all elements are True
</code></pre>

<pre><code class="language-text">t_0: 19
Tensor(&quot;zeros_like_32:0&quot;, shape=(), dtype=int32)
Tensor(&quot;ones_like_20:0&quot;, shape=(), dtype=int32)
t_1: [b&#39;apple&#39;, b&#39;peach&#39;, b&#39;grape&#39;]
Tensor(&quot;zeros_like_33:0&quot;, shape=(3,), dtype=string)
t_2: [[True, False, False], [False, False, True], [False, True, False]]
Tensor(&quot;zeros_like_34:0&quot;, shape=(3, 3), dtype=bool)
Tensor(&quot;ones_like_21:0&quot;, shape=(3, 3), dtype=bool)
</code></pre>

<p><strong>Note: Do not use Python native types for tensors because TensorFlow has to infer Python type.</strong></p>

<h3 id="toc_8">TensorFlow Native Types</h3>

<p>Like <code>NumPy</code>, <code>TensorFlow</code> also its own data types such as <code>tf.int32</code>, <code>tf.float32</code>. Below is a list of current TensorFlow data types.</p>

<p><img src="media/15033836099887/tensorflow_data_types.png" alt=""/></p>

<h3 id="toc_9">Numpy Data Types</h3>

<p>By now, you’ve probably noticed the similarity between <code>NumPy</code> and <code>TensorFlow</code>. <code>TensorFlow</code> was designed to integrate seamlessly with <code>Numpy</code>, the package that has become the  lingua franca of data science.</p>

<p>TensorFlow’s data types are based on those of NumPy; in fact, <code>np.int32 == tf.int32</code> returns <code>True</code>. You can pass <code>NumPy</code> types to <code>TensorFlow</code> ops.</p>

<p>Example:</p>

<pre><code class="language-python">import numpy as np
tf.ones([2, 2],  np.float32)
</code></pre>

<pre><code class="language-text">&lt;tf.Tensor &#39;ones:0&#39; shape=(2, 2) dtype=float32&gt;
</code></pre>

<pre><code class="language-python">x = np.zeros((2,2))
tf.ones_like(x)
</code></pre>

<pre><code class="language-text">&lt;tf.Tensor &#39;ones_like_22:0&#39; shape=(2, 2) dtype=float64&gt;
</code></pre>

<h3 id="toc_10">Constant</h3>

<p>Constants are stored in the graph definition. This makes loading graphs expensive when constants are big. <strong>Only use constants for primitive types, use variables or readers for more data that requires more memory</strong>.</p>

<pre><code class="language-python">g = tf.Graph() # to add operators to a graph, set it as default:
with g.as_default():
    my_const = tf.constant([1.0, 2.0], name=&quot;my_const&quot;)
    with tf.Session() as sess:
        print(sess.graph.as_graph_def())
</code></pre>

<pre><code class="language-text">node {
  name: &quot;my_const&quot;
  op: &quot;Const&quot;
  attr {
    key: &quot;dtype&quot;
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: &quot;value&quot;
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: &quot;\000\000\200?\000\000\000@&quot;
      }
    }
  }
}
versions {
  producer: 24
}
</code></pre>

<h3 id="toc_11">Variables</h3>

<p><code>tf.constant</code> is an operation, but <code>tf.Variable</code> is a class. <code>tf.Variables</code> holds several operations:</p>

<pre><code class="language-python">tf.InteractiveSession()
xx = tf.Variable(23, name=&#39;scalar&#39;)
xx.initializer # init op
xx.value() # read op
assign_op = xx.assign(5)

</code></pre>

<p>You have to initialize <code>variables</code>, The easiest way is initializing all variables at once:</p>

<pre><code class="language-python">init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    print(xx.eval())
    sess.run(assign_op)
    print(xx.eval())
</code></pre>

<pre><code class="language-text">23
5
</code></pre>

<h4 id="toc_12">Each session maintains its own copy of variable</h4>

<pre><code class="language-python">W = tf.Variable(10, name=&#39;W&#39;)
sess1 = tf.Session()
sess2 = tf.Session()
sess1.run(W.initializer)
sess2.run(W.initializer)
print(sess1.run(W.assign_add(10)))
print(sess2.run(W.assign_sub(2))) # not 18!

sess1.close()
sess2.close()
</code></pre>

<pre><code class="language-text">20
8
</code></pre>

<h4 id="toc_13">Use a variable to initialize another variables</h4>

<pre><code class="language-python"># want to declare U = 2*W
# W is random tensor
W = tf.Variable(tf.truncated_normal([4, 2]))
U = tf.Variable(2*W.initialized_value())
with tf.Session() as sess:
    sess.run(U.initializer)
    print(U.eval())
</code></pre>

<pre><code class="language-text">[[ 1.11442947 -3.1675539 ]
 [ 3.02267933 -0.81786388]
 [ 2.57613969 -0.98440802]
 [ 0.6298722  -0.38194153]]
</code></pre>

<h4 id="toc_14">Session vs InteractiveSession,</h4>

<p>You sometimes see InteractiveSession instead of Session. The only difference is an InteractiveSession makes itself the default.</p>

<pre><code class="language-python">sess = tf.InteractiveSession()
a = tf.constant(5.0)
b = tf.constant(6.0)
c = a*b
# We can just use `c.eval()` with out specifying the context `sess`
print(c.eval())
sess.close()
</code></pre>

<pre><code class="language-text">30.0
</code></pre>

<h3 id="toc_15">Placeholder</h3>

<p>A TensorFlow program often has 2 phases:</p>

<ol>
<li>Assemble a graph</li>
<li>Use a session to execute operations in the graph</li>
</ol>

<p>\(\rightarrow\) can assemble the graph without knowing the values needed for computation</p>

<p><strong>Analogy</strong>: Can define the function \(f(x,y) = x*2+y\) without knowing value of \(x\) or \(y\).</p>

<p>So using <code>placeholders</code>, we can later supply their data when they needed to execute the computation.</p>

<pre><code class="language-text">tf.placeholder(dtype, shape=None, name=None)
</code></pre>

<p><code>shape=None</code> means that tensor of nay shape will be accepted as value for placeholder. Note: <strong><code>shape=None</code> is easy to construct graphs, but nightmarish for debugging</strong>.</p>

<p>To make <code>shape</code>  flexible, <code>None</code> can be used in the <code>shape</code> argument:</p>

<pre><code class="language-text">    X = tf.placeholder(dtype=tf.float32, shape=[n_x, None], name=&#39;X&#39;)
</code></pre>

<h3 id="toc_16">Lazy loading</h3>

<p><code>Lazy loading</code> means defer creating/initializing an object until it is needed. In the context of TensorFlow, it means you defer creating an op until you need to compute it. </p>

<p>Normal loading:</p>

<pre><code class="language-python">g = tf.Graph()
with g.as_default():
    x = tf.Variable(10, name=&#39;x&#39;)
    y = tf.Variable(20, name=&#39;y&#39;)
    z = tf.add(x,y) # you create the node for add node before executing the graph

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for _ in range(10):
            sess.run(z)

</code></pre>

<p>Lazy loading:</p>

<pre><code class="language-python">g = tf.Graph()
with g.as_default():
    x = tf.Variable(10, name=&#39;x&#39;)
    y = tf.Variable(20, name=&#39;y&#39;)

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        writer = tf.summary.FileWriter(&#39;./my_graph/12&#39;, sess.graph)
        for _ in range(10):
            sess.run(tf.add(x,y)) # someone decides to be clever to save one line of code
        writer.close()
</code></pre>

<p>Note: In Lazy loading, Node <code>ADD</code> added 10 times to the graph definition. Image you want to compute an operations thousands of times, you graph gets bloated slow to load, and expensive to pass around.</p>

<p><strong>Solution</strong>: </p>

<ol>
<li>Separate definition of ops from computing/running ops</li>
<li>Use Python property to ensure function is also loaded once the first time it is called.</li>
</ol>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="batch_normalization.html" 
          title="Previous Post: Batch Normalization">&laquo; Batch Normalization</a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="what_is_a_tensorflow_session.html" 
          title="Next Post: TensorFlow(3):What is a tensorflow session?">TensorFlow(3):What is a tensorflow session? &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          <div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://techlarry-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                                

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="programming_language.html"><strong>编程语言</strong></a>
        
            <a href="data_structure_and_algorithm.html"><strong>数据结构和算法</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>文献阅读</strong></a>
        
            <a href="Tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15046649572570.html">Pandas</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="exceptional_control_flow.html">CSAPP - 异常控制流</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="introduction_to_computer_system_CMU.html">CMU 15-213 Introduction to Computer Systems</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concepts-os-structures.html">Operating System Concepts 2 - Operating System structures</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="os-concets-processes.html">Operating System Concepts 3 - Processes</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
